# WhisperJAV Requirements
# ========================================

# Git-based dependencies (from main branches)
openai-whisper @ git+https://github.com/openai/whisper@main
stable-ts @ git+https://github.com/meizhong986/stable-ts-fix-setup.git@main

# Whisper variants
faster-whisper>=1.1.0


# Audio and signal processing
# NOTE: ffmpeg-python must be installed from GitHub (PyPI tarball fails due to setup.py calling `git rev-parse HEAD`)
ffmpeg-python @ git+https://github.com/kkroening/ffmpeg-python.git
soundfile
auditok
silero-vad>=6.0
pydub

# Speech segmentation backends (v1.7.2)
ten-vad
# NOTE: nemo_toolkit removed - available as optional install for NeMo VAD users

# Speech enhancement backends (v1.7.3)
modelscope>=1.20                # ZipEnhancer 16kHz (recommended, lightweight SOTA)
addict                          # ModelScope dependency (dict with attribute access)
datasets>=2.14.0,<4.0           # 4.x breaks modelscope
simplejson                      # ModelScope dependency (JSON parsing)
sortedcontainers                # ModelScope dependency (sorted collections)
packaging                       # ModelScope dependency (version parsing)
clearvoice @ git+https://github.com/meizhong986/ClearerVoice-Studio.git#subdirectory=clearvoice  # Fork with NumPy 2.x support
bs-roformer-infer               # BS-RoFormer vocal isolation (44.1kHz)
onnxruntime>=1.16.0             # ONNX inference for ZipEnhancer ONNX mode

# Utilities
numpy>=2.0                      # NumPy 2.x (modelscope/zipenhancer compatible)
scipy>=1.14.0                   # Required for NumPy 2.0 compatibility
tqdm
pysrt
srt
aiofiles
jsonschema
colorama
librosa>=0.11.0                     # v0.11.0+ supports NumPy 2.0
pyloudnorm
requests
regex

# Configuration system
pydantic>=2.0,<3.0

# Optional: speed-up
numba>=0.60.0                   # NumPy 2.0 compatible
hf_xet                          # Faster HuggingFace downloads (Xet Storage)

# GUI Framework (PyWebView)
pywebview>=5.0.0
pythonnet>=3.0; platform_system=="Windows"
pywin32>=305; platform_system=="Windows"

# Translation dependencies (requires Python 3.10+)
pysubtrans>=1.5.0
openai>=1.35.0
google-genai>=1.39.0
huggingface-hub>=0.25.0

# Local LLM translation (JamePeng's fork with CUDA support)
# [server] extra includes uvicorn for local LLM server
llama-cpp-python[server] @ git+https://github.com/JamePeng/llama-cpp-python.git
