from IPython.display import display, HTML
import time
import subprocess
import shlex
from pathlib import Path
from google.colab import drive
from tqdm.notebook import tqdm
import sys

# Your configuration settings
mode = "balanced"
sensitivity = "balanced"
subs_language = "japanese"
opening_prologue = "Subtitles by yourname"
closing_credits_text = "Subs by WhisperJAV Colab"
auto_disconnect = True

# Sanitize subtitle text
def sanitize_subtitle_text(text):
    if not text:
        return ""
    return text.replace('\n', ' ').replace('\r', '')

print("--- STEP 1: PRE-FLIGHT CHECKS ---")
!nvidia-smi
print("‚úÖ GPU check complete.\n")

print("--- STEP 2: CONNECTING GOOGLE DRIVE ---")
try:
    drive.mount('/content/drive', force_remount=True)
    drive_folder = Path('/content/drive/MyDrive/WhisperJAV')
    drive_folder.mkdir(exist_ok=True)
    print(f"‚úÖ Google Drive connected. Using folder: {drive_folder}\n")
except Exception as e:
    display(HTML(f'<div style="background-color: #f8d7da; border: 1px solid #f5c6cb; border-radius: 8px; padding: 20px;"><h3 style="color: #721c24;">‚ùå ERROR: Failed to connect Google Drive.</h3><p style="color: #721c24;">Please re-run the cell and ensure you accept the authorization pop-up.</p></div>'))
    sys.exit()

# Function to display a collapsible section
def display_collapsible(title, content):
    display(HTML(f"""
    <details>
        <summary style="font-weight: bold; color: #1f77b4; cursor: pointer;">{title}</summary>
        <div style="margin-left: 20px; margin-top: 10px; margin-bottom: 10px;">
            {content}
        </div>
    </details>
    """))

# Function to display a progress bar
def display_progress_bar(current, total, message):
    progress = current / total
    bar_length = 30
    filled_length = int(bar_length * progress)
    bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)
    display(HTML(f"""
    <div style="margin-top: 10px; margin-bottom: 10px;">
        <div style="font-weight: bold;">{message}</div>
        <div style="width: 100%; background-color: #d0d0d0; border-radius: 5px;">
            <div style="width: {progress*100}%; background-color: #2ecc71; border-radius: 5px; padding: 5px; color: white; text-align: center;">
                {bar} {int(progress*100)}%
            </div>
        </div>
    </div>
    """))

# Function to display a status message
def display_status_message(message, is_success=True):
    color = "green" if is_success else "red"
    icon = "‚úÖ" if is_success else "‚ùå"
    display(HTML(f"""
    <div style="margin-top: 10px; margin-bottom: 10px; color: {color}; font-weight: bold;">
        {icon} {message}
    </div>
    """))

# Function to run the command and display the output in a collapsible section
def run_command_with_output(command, title):
    display_collapsible(title, f"<pre>Executing command: {command}</pre>")
    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)
    output_lines = []
    for line in process.stdout:
        output_lines.append(line)
        print(line, end='')
    return output_lines

print("--- STEP 3: INSTALLING DEPENDENCIES ---")

# Install system libraries
display_status_message("Installing system libraries...")
!apt-get update -qq > /dev/null
!apt-get install -y -qq ffmpeg > /dev/null

# Install WhisperJAV without dependencies (latest commit)
display_status_message("Installing WhisperJAV without dependencies...")
!pip install --no-deps -q git+https://github.com/meizhong986/WhisperJAV.git

# Define core dependencies with version constraints
core_requirements = [
    "openai-whisper@git+https://github.com/openai/whisper@v20250625",
    "stable-ts@git+https://github.com/meizhong986/stable-ts-fix-setup.git@main",
    "faster-whisper>=1.1.1",
    "ffmpeg-python",
    "soundfile",
    "auditok",
    "numpy",
    "scipy",
    "tqdm",
    "pysrt",
    "srt",
    "numba"
]

# Check existing PyTorch installations
display_status_message("Checking PyTorch installations...")
try:
    import torch
    TORCH_AVAILABLE = True
    TORCH_VERSION = torch.__version__
    CUDA_AVAILABLE = torch.cuda.is_available()

    # Check for torchvision
    try:
        import torchvision
        TORCHVISION_AVAILABLE = True
        TORCHVISION_VERSION = torchvision.__version__
    except ImportError:
        TORCHVISION_AVAILABLE = False

    # Check for torchaudio
    try:
        import torchaudio
        TORCHAUDIO_AVAILABLE = True
        TORCHAUDIO_VERSION = torchaudio.__version__
    except ImportError:
        TORCHAUDIO_AVAILABLE = False

except ImportError:
    TORCH_AVAILABLE = False
    TORCHVISION_AVAILABLE = False
    TORCHAUDIO_AVAILABLE = False

# Install only if needed
install_torch = False
torch_message = "‚úÖ Using existing: "
if not TORCH_AVAILABLE:
    install_torch = True
    torch_message += "Torch missing. "
elif not CUDA_AVAILABLE:
    install_torch = True
    torch_message += f"Torch CUDA unavailable ({TORCH_VERSION}). "
else:
    torch_message += f"Torch {TORCH_VERSION} with CUDA. "

if not TORCHVISION_AVAILABLE:
    install_torch = True
    torch_message += "TorchVision missing. "
elif TORCHVISION_AVAILABLE:
    torch_message += f"TorchVision {TORCHVISION_VERSION}. "

if not TORCHAUDIO_AVAILABLE:
    install_torch = True
    torch_message += "TorchAudio missing. "
elif TORCHAUDIO_AVAILABLE:
    torch_message += f"TorchAudio {TORCHAUDIO_VERSION}. "

if install_torch:
    display_status_message(torch_message, is_success=False)
    display_status_message("Installing PyTorch stack with CUDA support...")
    !pip install -q torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124
else:
    display_status_message(torch_message)

# Verify secondary dependencies
display_status_message("Checking secondary dependencies...")
dependencies = [
    "ffmpeg-python", "soundfile", "auditok", "numpy", "scipy",
    "tqdm", "pysrt", "srt", "numba", "faster-whisper"
]
missing_deps = []
for dep in dependencies:
    try:
        __import__(dep)
        # Special check for faster-whisper
        if dep == "faster-whisper":
            import faster_whisper
            if not hasattr(faster_whisper, "__version__") or faster_whisper.__version__ < "1.1.1":
                missing_deps.append(f"faster-whisper<1.1.1")
    except ImportError:
        missing_deps.append(dep)

if missing_deps:
    display_status_message(f"‚ö†Ô∏è Missing/outdated dependencies: {', '.join(missing_deps)}", is_success=False)
    display_status_message("Installing required dependencies...")
    # Install core dependencies including any missing ones
    !pip install -q {' '.join(core_requirements)}
else:
    display_status_message("‚úÖ All secondary dependencies are satisfied")

display_status_message("‚úÖ Dependencies installed.\n", is_success=True)

# If user doesn't change the example, treat it as empty
if opening_prologue == "Subtitles by yourname":
    opening_prologue = ""

print("--- STEP 4: RUNNING WHISPERJAV TRANSCRIPTION ---")

# Build the command robustly as a list of arguments
command_list = [
    'whisperjav',
    str(drive_folder)
]

options = {
    '--mode': mode,
    '--sensitivity': sensitivity,
    '--subs-language': subs_language,
    '--output-dir': str(drive_folder),
    '--adaptive-classification': adaptive_classification,
    '--adaptive-audio-enhancement': adaptive_audio_enhancement,
    '--smart-postprocessing': smart_postprocessing
}

for flag, value in options.items():
    if isinstance(value, bool):
        if value:
            command_list.append(flag)
    elif value:
        command_list.append(flag)
        command_list.append(str(value))

# Join the list into a shell-safe string to be used with Popen(shell=True)
full_command = shlex.join(command_list)
display_status_message(f"Executing command: {full_command}")

# Execute with live output and robust error handling
try:
    output_lines = run_command_with_output(full_command, "WhisperJAV Transcription Output")
    if "Command failed" in "".join(output_lines):
        raise subprocess.CalledProcessError(1, full_command)
except subprocess.CalledProcessError as e:
    error_message = f"The main process failed with exit code {e.returncode}."
    display(HTML(f'''<div style="background-color: #f8d7da; border: 1px solid #f5c6cb; border-radius: 8px; padding: 20px;"><h3 style="color: #721c24;">‚ùå ERROR: Transcription Failed</h3><p style="color: #721c24;">{error_message} Please check the console output above for the specific error from the script.</p></div>'''))
    sys.exit()

print("\n--- STEP 5: POST-PROCESSING CREDITS ---")
srt_files = list(drive_folder.glob('*.srt'))

if opening_prologue:
    prologue_line = f"0\n00:00:00,000 --> 00:00:00,500\n{opening_prologue}\n\n"
    for srt_file in tqdm(srt_files, desc="Adding Opening Credits"):
        try:
            original_content = srt_file.read_text(encoding='utf-8')
            srt_file.write_text(prologue_line + original_content, encoding='utf-8')
        except Exception as e:
            print(f"  - Warning: Could not add prologue to {srt_file.name}: {e}")

if closing_credits_text:
    for srt_file in tqdm(srt_files, desc="Adding Closing Credits"):
        try:
            with open(srt_file, 'a', encoding='utf-8') as f:
                f.write(f'\n9999\n23:59:58,000 --> 23:59:59,000\n{closing_credits_text}\n')
        except Exception as e:
            print(f"  - Warning: Could not add closing credits to {srt_file.name}: {e}")

display_status_message("‚úÖ Post-processing complete.\n", is_success=True)

display(HTML("""<div style="background-color: #d4edda; border: 1px solid #c3e6cb; border-radius: 8px; padding: 20px; margin-top: 20px;"><h3 style="color: #155724; margin-top: 0;">üéâ Success! All tasks are complete.</h3><p style="color: #155724; margin-bottom: 0;">The session will now disconnect automatically if you enabled the option.</p></div>"""))

if auto_disconnect:
    print("\nüîå Auto-disconnect enabled. This session will now end to save resources.")
    time.sleep(5)
    from google.colab import runtime
    runtime.unassign()
