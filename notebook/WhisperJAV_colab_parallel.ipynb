{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# WhisperJAV Two-Pass Edition v1.8.2\n",
    "\n",
    "**Adaptive Two-Pass Processing** - Automatically optimizes for your platform.\n",
    "\n",
    "| Platform | GPUs | How it works |\n",
    "|----------|------|---------------|\n",
    "| **Kaggle** | 2x T4 (8GB each) | **Parallel** - Pass 1 on GPU 0, Pass 2 on GPU 1 simultaneously |\n",
    "| **Colab L4/A100** | 1x GPU (16-24GB) | **Sequential** - Pass 1 first, then Pass 2 (avoids memory issues) |\n",
    "\n",
    "| Option | What it controls |\n",
    "|--------|------------------|\n",
    "| **Speech Segmenter** | How to detect speech in audio (silero, ten, none) |\n",
    "| **Model** | Which AI model to use (large-v2, large-v3, turbo, kotoba) |\n",
    "\n",
    "---\n",
    "<div style=\"font-size: 8px; line-height: 1.0;\">\n",
    "1. Upload your videos to <code>Google Drive/WhisperJAV/</code><br>\n",
    "2. Select settings and Click <b>Runtime ‚Üí Run all</b> in the menu<br>\n",
    "3. <b>Connect Google Drive</b> when prompted<br>\n",
    "4. Wait for your subtitles!\n",
    "</div>\n",
    "\n",
    "<small>The notebook will automatically disconnect when finished to save your GPU credits.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 1: Settings { display-mode: \"form\" }\n",
    "\n",
    "#@markdown **Pass 1 Configuration**\n",
    "pass1_quality = \"balanced\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass1_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass1_speech_segmenter = \"automatic\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass1_model = \"automatic\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **Pass 2 Configuration**\n",
    "pass2_quality = \"transformers\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass2_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass2_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass2_model = \"kotoba-bilingual\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **Merge Strategy**\n",
    "merge_method = \"prefer first pass\" #@param [\"automatic\", \"keep all\", \"prefer first pass\", \"prefer second pass\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **Files & Output**\n",
    "folder_name = \"WhisperJAV\" #@param {type:\"string\"}\n",
    "subtitle_language = \"Japanese\" #@param [\"Japanese\", \"English (auto-translate)\", \"English (AI translate)\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **AI Translation** *(if selected \"English (AI translate)\")*\n",
    "translation_service = \"local\" #@param [\"local\", \"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\"]\n",
    "local_model = \"gemma-9b\" #@param [\"gemma-9b\", \"llama-8b\", \"llama-3b\", \"auto\"]\n",
    "#@markdown <font size=\"1\">local: Free, runs on GPU. gemma-9b (8GB+ VRAM), llama-8b (6GB+), llama-3b (3GB+). Cloud providers require API key.</font>\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "translation_style = \"standard\" #@param [\"standard\", \"explicit\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **Credits**\n",
    "opening_credit = \"\" #@param {type:\"string\"}\n",
    "closing_credit = \"Subs by WhisperJAV\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **Session**\n",
    "auto_disconnect = True #@param {type:\"boolean\"}\n",
    "#@markdown ‚òùÔ∏è Auto-disconnect when done (saves GPU credits)\n",
    "\n",
    "# Mapping dictionaries\n",
    "combine_map = {\"automatic\": \"smart_merge\", \"keep all\": \"full_merge\",\n",
    "               \"prefer first pass\": \"pass1_primary\", \"prefer second pass\": \"pass2_primary\"}\n",
    "language_map = {\"Japanese\": \"native\", \"English (auto-translate)\": \"direct-to-english\",\n",
    "                \"English (AI translate)\": \"llm\"}\n",
    "tone_map = {\"standard\": \"standard\", \"explicit\": \"pornify\"}\n",
    "\n",
    "# Speech segmenter mapping (None = use pipeline default)\n",
    "segmenter_map = {\"automatic\": None, \"silero\": \"silero\", \"ten\": \"ten\", \"none\": \"none\"}\n",
    "\n",
    "# Model mapping (None = use pipeline default)\n",
    "model_map = {\n",
    "    \"automatic\": None,\n",
    "    \"large-v2\": \"large-v2\",\n",
    "    \"large-v3\": \"large-v3\",\n",
    "    \"turbo\": \"large-v3-turbo\",\n",
    "    \"kotoba-bilingual\": \"kotoba-tech/kotoba-whisper-bilingual-v1.0\",\n",
    "    \"kotoba-v2.0\": \"kotoba-tech/kotoba-whisper-v2.0\",\n",
    "    \"kotoba-v2.1\": \"kotoba-tech/kotoba-whisper-v2.1\",\n",
    "    \"kotoba-v2.2\": \"kotoba-tech/kotoba-whisper-v2.2\"\n",
    "}\n",
    "\n",
    "# Define model compatibility:\n",
    "# - Kotoba models (HuggingFace) ONLY work with \"transformers\" pipeline\n",
    "# - Legacy models (large-v2/v3/turbo) work with ALL pipelines (faster, fast, balanced, fidelity, transformers)\n",
    "KOTOBA_MODELS = {\"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"}\n",
    "LEGACY_PIPELINES = {\"faster\", \"fast\", \"balanced\", \"fidelity\"}\n",
    "\n",
    "# Auto-correct incompatible model-pipeline combinations\n",
    "warnings_list = []\n",
    "\n",
    "# Check Pass 1 compatibility\n",
    "if pass1_model in KOTOBA_MODELS and pass1_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 1: {pass1_model} requires 'transformers' pipeline. Auto-correcting from '{pass1_quality}' to 'transformers'.\")\n",
    "    pass1_quality = \"transformers\"\n",
    "\n",
    "# Check Pass 2 compatibility\n",
    "if pass2_model in KOTOBA_MODELS and pass2_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 2: {pass2_model} requires 'transformers' pipeline. Auto-correcting from '{pass2_quality}' to 'transformers'.\")\n",
    "    pass2_quality = \"transformers\"\n",
    "\n",
    "WHISPERJAV_CONFIG = {\n",
    "    'pass1_pipeline': pass1_quality,\n",
    "    'pass1_sensitivity': pass1_sensitivity,\n",
    "    'pass1_speech_segmenter': segmenter_map[pass1_speech_segmenter],\n",
    "    'pass1_model': model_map[pass1_model],\n",
    "    'pass2_pipeline': pass2_quality,\n",
    "    'pass2_sensitivity': pass2_sensitivity,\n",
    "    'pass2_speech_segmenter': segmenter_map[pass2_speech_segmenter],\n",
    "    'pass2_model': model_map[pass2_model],\n",
    "    'merge_strategy': combine_map[merge_method],\n",
    "    'folder_name': folder_name,\n",
    "    'subtitle_language': language_map[subtitle_language],\n",
    "    'translation_service': translation_service,\n",
    "    'local_model': local_model,\n",
    "    'api_key': api_key,\n",
    "    'translation_style': tone_map[translation_style],\n",
    "    'opening_credit': opening_credit,\n",
    "    'closing_credit': closing_credit,\n",
    "    'auto_disconnect': auto_disconnect,\n",
    "    # Display values\n",
    "    '_pass1_quality': pass1_quality,\n",
    "    '_pass1_sensitivity': pass1_sensitivity,\n",
    "    '_pass1_speech_segmenter': pass1_speech_segmenter,\n",
    "    '_pass1_model': pass1_model,\n",
    "    '_pass2_quality': pass2_quality,\n",
    "    '_pass2_sensitivity': pass2_sensitivity,\n",
    "    '_pass2_speech_segmenter': pass2_speech_segmenter,\n",
    "    '_pass2_model': pass2_model,\n",
    "    '_merge_method': merge_method,\n",
    "    '_subtitle_language': subtitle_language,\n",
    "    '_translation_style': translation_style,\n",
    "}\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display any auto-correction warnings\n",
    "for warning in warnings_list:\n",
    "    display(HTML(f'<div style=\"padding:6px 10px;background:#fef9c3;border-radius:4px;font-size:10px;margin-bottom:4px\"><b>‚ö† Auto-corrected:</b> {warning}</div>'))\n",
    "\n",
    "# Build status display\n",
    "p1_info = f\"{pass1_quality}\"\n",
    "if pass1_speech_segmenter != \"automatic\":\n",
    "    p1_info += f\"/{pass1_speech_segmenter}\"\n",
    "if pass1_model != \"automatic\":\n",
    "    p1_info += f\"/{pass1_model}\"\n",
    "\n",
    "p2_info = f\"{pass2_quality}\"\n",
    "if pass2_speech_segmenter != \"automatic\":\n",
    "    p2_info += f\"/{pass2_speech_segmenter}\"\n",
    "if pass2_model != \"automatic\":\n",
    "    p2_info += f\"/{pass2_model}\"\n",
    "\n",
    "display(HTML(f'<div style=\"padding:6px 10px;background:#e0f2fe;border-radius:4px;font-size:10px\"><b>Parallel Mode:</b> Pass1({p1_info}) ‚áÜ Pass2({p2_info}) | Merge: {merge_method} | Folder: {folder_name}</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 2: Two-Pass Transcribe { display-mode: \"form\" }\n",
    "#@markdown Connect Drive ‚Üí Install ‚Üí Run passes (parallel on Kaggle, sequential on Colab) ‚Üí Merge results\n",
    "\n",
    "import os, sys, subprocess, shlex, time, re\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    icon = \"‚úì\" if ok else \"‚úó\"\n",
    "    print(f\"{icon} {msg}\")\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'‚îÄ'*50}\\n{title}\\n{'‚îÄ'*50}\")\n",
    "\n",
    "# Check config\n",
    "if 'WHISPERJAV_CONFIG' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 1 first</div>'))\n",
    "    raise SystemExit()\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# PRE-FLIGHT CHECKS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "section(\"PRE-FLIGHT CHECKS\")\n",
    "\n",
    "# Python version check - WhisperJAV requires Python 3.10-3.12\n",
    "py_version = sys.version_info\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "if py_version >= (3, 13):\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Python 3.13+ not supported. WhisperJAV requires Python 3.10-3.12 (openai-whisper incompatible)</div>'))\n",
    "    raise SystemExit(f\"Python {sys.version.split()[0]} not supported\")\n",
    "elif py_version < (3, 10):\n",
    "    raise SystemExit(f\"Python {sys.version.split()[0]} too old. Requires 3.10-3.12.\")\n",
    "status(f\"Python version OK\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CONNECT GOOGLE DRIVE\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "section(\"CONNECTING GOOGLE DRIVE\")\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    folder_path = Path(f\"/content/drive/MyDrive/{cfg['folder_name']}\")\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    status(f\"Connected: {folder_path}\")\n",
    "except Exception as e:\n",
    "    status(f\"Failed to connect: {e}\", False)\n",
    "    raise SystemExit()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CHECK GPUs AND DETERMINE MODE\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "section(\"DETECTING PLATFORM\")\n",
    "gpu_check = subprocess.run(\"nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\", shell=True, capture_output=True, text=True)\n",
    "if gpu_check.returncode != 0 or not gpu_check.stdout.strip():\n",
    "    status(\"No GPU detected. Go to Runtime ‚Üí Change runtime type ‚Üí T4 GPU\", False)\n",
    "    raise SystemExit()\n",
    "\n",
    "gpu_lines = [line.strip() for line in gpu_check.stdout.strip().split('\\n') if line.strip()]\n",
    "num_gpus = len(gpu_lines)\n",
    "\n",
    "for i, gpu_info in enumerate(gpu_lines):\n",
    "    status(f\"GPU {i}: {gpu_info}\")\n",
    "\n",
    "# Adaptive mode selection\n",
    "if num_gpus >= 2:\n",
    "    PARALLEL_MODE = True\n",
    "    gpu_assignment = {1: \"0\", 2: \"1\"}\n",
    "    print(f\"\\n  ‚ö° Kaggle Mode: PARALLEL (Pass 1 ‚Üí GPU 0, Pass 2 ‚Üí GPU 1)\")\n",
    "else:\n",
    "    PARALLEL_MODE = False\n",
    "    gpu_assignment = {1: \"0\", 2: \"0\"}\n",
    "    print(f\"\\n  üìù Colab Mode: SEQUENTIAL (avoids memory contention)\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# INSTALL WHISPERJAV\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "section(\"INSTALLING WHISPERJAV\")\n",
    "install_start = time.time()\n",
    "\n",
    "REPO_URL = \"https://github.com/meizhong986/WhisperJAV.git\"\n",
    "REPO_PATH = \"/content/WhisperJAV\"\n",
    "SCRIPT_PATH = f\"{REPO_PATH}/installer/install_colab.sh\"\n",
    "VENV_PATH = \"/content/whisperjav_env\"\n",
    "\n",
    "# Logic only needed for Colab - Kaggle installs globally\n",
    "if os.path.exists(\"/kaggle\"):\n",
    "    # Kaggle fallback (simplified manual install since root is allowed)\n",
    "    steps = [\n",
    "        (\"apt-get update -qq && apt-get install -y -qq ffmpeg portaudio19-dev libc++1 libc++abi1 libsndfile1 libgl1 > /dev/null 2>&1\", \"System tools\"),\n",
    "        (\"pip install -q whisperjav[cli,enhance,translate,huggingface,analysis,compatibility] @ git+https://github.com/meizhong986/WhisperJAV.git@main\", \"WhisperJAV + Deps\")\n",
    "    ]\n",
    "    for cmd, name in steps:\n",
    "        if subprocess.run(cmd, shell=True).returncode != 0: raise SystemExit(f\"{name} failed\")\n",
    "    \n",
    "    cfg['whisperjav_cmd'] = \"whisperjav\"\n",
    "    # Kaggle doesn't use venv, assumes path is correct\n",
    "    status(\"Installation complete (Kaggle)\")\n",
    "\n",
    "else:\n",
    "    # Colab: Use install_colab.sh for isolated environment\n",
    "    def run_installer():\n",
    "        env = {**os.environ, \"PATH\": f\"{os.environ.get('PATH', '')}:{os.path.expanduser('~/.local/bin')}\"}\n",
    "        process = subprocess.Popen([\"bash\", SCRIPT_PATH], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, bufsize=1, text=True, env=env)\n",
    "        for line in iter(process.stdout.readline, ''): print(line, end='', flush=True)\n",
    "        process.wait()\n",
    "        return process.returncode\n",
    "\n",
    "    # Check/Install\n",
    "    venv_python = f\"{VENV_PATH}/bin/python\"\n",
    "    if os.path.exists(venv_python) and subprocess.run([venv_python, \"-c\", \"import whisperjav\"], capture_output=True).returncode == 0:\n",
    "        status(\"WhisperJAV already installed (skipping)\")\n",
    "    else:\n",
    "        if os.path.exists(VENV_PATH): subprocess.run([\"rm\", \"-rf\", VENV_PATH])\n",
    "        if not os.path.exists(REPO_PATH): subprocess.run([\"git\", \"clone\", REPO_URL, REPO_PATH])\n",
    "        if run_installer() != 0: raise SystemExit(\"Installation failed\")\n",
    "\n",
    "    # Update config to use venv binary\n",
    "    cfg['whisperjav_cmd'] = f\"{VENV_PATH}/bin/whisperjav\"\n",
    "    status(f\"Installation complete ({time.time()-install_start:.0f}s)\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# FIND MEDIA FILES\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "section(\"SCANNING FILES\")\n",
    "video_types = {'.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.mp3', '.wav', '.flac', '.m4a'}\n",
    "videos = [f for f in folder_path.iterdir() if f.suffix.lower() in video_types]\n",
    "\n",
    "if not videos:\n",
    "    status(f\"No media files in {cfg['folder_name']}/\", False)\n",
    "    raise SystemExit()\n",
    "\n",
    "status(f\"Found {len(videos)} file(s)\")\n",
    "for v in videos[:5]:\n",
    "    print(f\"  ‚Ä¢ {v.name}\")\n",
    "if len(videos) > 5:\n",
    "    print(f\"  ... and {len(videos)-5} more\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# MERGE FUNCTIONS (from whisperjav/ensemble/merge.py)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "@dataclass\n",
    "class Subtitle:\n",
    "    index: int\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    text: str\n",
    "\n",
    "    @property\n",
    "    def duration(self) -> float:\n",
    "        return self.end_time - self.start_time\n",
    "\n",
    "def parse_srt(path: Path) -> List[Subtitle]:\n",
    "    subs = []\n",
    "    if not path.exists(): return []\n",
    "    \n",
    "    content = path.read_text(encoding='utf-8').strip()\n",
    "    # Simple regex parser for SRT\n",
    "    pattern = re.compile(r'(\\d+)\\n(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2},\\d{3})\\n((?:(?!\\n\\n).)*)', re.DOTALL)\n",
    "    \n",
    "    def time_to_seconds(t_str):\n",
    "        h, m, s, ms = map(int, re.split(r'[:,]', t_str))\n",
    "        return h * 3600 + m * 60 + s + ms / 1000.0\n",
    "\n",
    "    for match in pattern.finditer(content):\n",
    "        idx, start, end, text = match.groups()\n",
    "        subs.append(Subtitle(\n",
    "            index=int(idx),\n",
    "            start_time=time_to_seconds(start),\n",
    "            end_time=time_to_seconds(end),\n",
    "            text=text.strip()\n",
    "        ))\n",
    "    return subs\n",
    "\n",
    "def merge_srt(path1: Path, path2: Path, output_path: Path, strategy: str = \"smart_merge\") -> Dict:\n",
    "    \"\"\"Simplified merge implementation for the notebook context.\"\"\"\n",
    "    subs1 = parse_srt(path1)\n",
    "    subs2 = parse_srt(path2)\n",
    "    \n",
    "    # Strategy implementation\n",
    "    if strategy == \"pass1_primary\":\n",
    "        final_subs = subs1\n",
    "    elif strategy == \"pass2_primary\":\n",
    "        final_subs = subs2\n",
    "    else:\n",
    "        # Simple concatenation for smart merge fallback in this script\n",
    "        # In real library we use proper overlap detection\n",
    "        final_subs = subs1 + subs2\n",
    "        final_subs.sort(key=lambda s: s.start_time)\n",
    "        \n",
    "        # Re-index\n",
    "        for i, sub in enumerate(final_subs, 1):\n",
    "            sub.index = i\n",
    "            \n",
    "    # Write output\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for sub in final_subs:\n",
    "            start_h = int(sub.start_time // 3600)\n",
    "            start_m = int((sub.start_time % 3600) // 60)\n",
    "            start_s = int(sub.start_time % 60)\n",
    "            start_ms = int((sub.start_time * 1000) % 1000)\n",
    "            \n",
    "            end_h = int(sub.end_time // 3600)\n",
    "            end_m = int((sub.end_time % 3600) // 60)\n",
    "            end_s = int(sub.end_time % 60)\n",
    "            end_ms = int((sub.end_time * 1000) % 1000)\n",
    "            \n",
    "            f.write(f\"{sub.index}\\n\")\n",
    "            f.write(f\"{start_h:02d}:{start_m:02d}:{start_s:02d},{start_ms:03d} --> {end_h:02d}:{end_m:02d}:{end_s:02d},{end_ms:03d}\\n\")\n",
    "            f.write(f\"{sub.text}\\n\\n\")\n",
    "            \n",
    "    return {\n",
    "        'pass1_count': len(subs1),\n",
    "        'pass2_count': len(subs2),\n",
    "        'merged_count': len(final_subs)\n",
    "    }\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# EXECUTION ENGINE\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def build_pass_command(pass_num: int, video_path: Path, output_dir: Path, cfg: dict) -> Tuple[List[str], Path]:\n",
    "    \"\"\"Build whisperjav command for a single pass.\n",
    "\n",
    "    Note: WhisperJAV doesn't have --output-name, so we use separate directories\n",
    "    for each pass to avoid conflicts when running in parallel.\n",
    "    Output naming is automatic: {basename}.{lang_code}.whisperjav.srt\n",
    "    \"\"\"\n",
    "    # Use separate directory for each pass to avoid conflicts\n",
    "    pass_output_dir = output_dir / f\"pass{pass_num}\"\n",
    "    pass_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pipeline = cfg[f'pass{pass_num}_pipeline']\n",
    "    sensitivity = cfg[f'pass{pass_num}_sensitivity']\n",
    "    segmenter = cfg[f'pass{pass_num}_speech_segmenter']\n",
    "    model = cfg[f'pass{pass_num}_model']\n",
    "\n",
    "    # Use configured command (venv) or default\n",
    "    executable = cfg.get('whisperjav_cmd', 'whisperjav')\n",
    "    cmd = [executable, str(video_path), '--output-dir', str(pass_output_dir),\n",
    "           '--mode', pipeline, '--sensitivity', sensitivity]\n",
    "\n",
    "    if segmenter:\n",
    "        cmd.extend(['--speech-segmenter', segmenter])\n",
    "\n",
    "    if model:\n",
    "        cmd.extend(['--model', model])\n",
    "\n",
    "    if cfg['subtitle_language'] == 'direct-to-english':\n",
    "        cmd.extend(['--subs-language', 'direct-to-english'])\n",
    "    else:\n",
    "        cmd.extend(['--subs-language', 'native'])\n",
    "\n",
    "    # Return the pass output directory - we'll find the SRT file after processing\n",
    "    return cmd, pass_output_dir\n",
    "\n",
    "def find_output_srt(pass_output_dir: Path, video_name: str) -> Path:\n",
    "    \"\"\"Find the generated SRT file in the pass output directory.\n",
    "\n",
    "    WhisperJAV auto-generates: {basename}.{lang}.whisperjav.srt\n",
    "    e.g., video.ja.whisperjav.srt or video.en.whisperjav.srt\n",
    "    \"\"\"\n",
    "    base_name = Path(video_name).stem\n",
    "    # Look for any SRT file matching the video name\n",
    "    patterns = [\n",
    "        f\"{base_name}.*.whisperjav.srt\",  # Standard format\n",
    "        f\"{base_name}.srt\",                # Fallback\n",
    "        f\"{base_name}*.srt\",               # Any SRT with base name\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = list(pass_output_dir.glob(pattern))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    # Last resort: any SRT in directory\n",
    "    all_srts = list(pass_output_dir.glob(\"*.srt\"))\n",
    "    return all_srts[0] if all_srts else None\n",
    "\n",
    "def run_pass(pass_num: int, video: Path, output_dir: Path, cfg: dict, gpu_id: str) -> Dict:\n",
    "    \"\"\"Run a single pass on a specific GPU.\"\"\"\n",
    "    cmd, pass_output_dir = build_pass_command(pass_num, video, output_dir, cfg)\n",
    "\n",
    "    env = os.environ.copy()\n",
    "    env['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = subprocess.run(shlex.join(cmd), shell=True, capture_output=True, text=True, env=env)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Find the output SRT file\n",
    "    actual_output = find_output_srt(pass_output_dir, video.name)\n",
    "\n",
    "    return {\n",
    "        'pass': pass_num,\n",
    "        'video': video.name,\n",
    "        'success': result.returncode == 0 and actual_output and actual_output.exists(),\n",
    "        'output': actual_output,\n",
    "        'output_dir': pass_output_dir,\n",
    "        'elapsed': elapsed,\n",
    "        'gpu': gpu_id,\n",
    "        'stderr': result.stderr[-500:] if result.stderr else ''  # Last 500 chars for debugging\n",
    "    }\n",
    "\n",
    "# Process each video\n",
    "all_results = []\n",
    "merged_outputs = []\n",
    "\n",
    "for video_idx, video in enumerate(videos, 1):\n",
    "    print(f\"\\n[{video_idx}/{len(videos)}] Processing: {video.name}\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    if PARALLEL_MODE:\n",
    "        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "        # KAGGLE: Run both passes in parallel on separate GPUs\n",
    "        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "        with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "            futures = {\n",
    "                executor.submit(run_pass, 1, video, folder_path, cfg, gpu_assignment[1]): 1,\n",
    "                executor.submit(run_pass, 2, video, folder_path, cfg, gpu_assignment[2]): 2\n",
    "            }\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                pass_num = futures[future]\n",
    "                result = future.result()\n",
    "                results[pass_num] = result\n",
    "                status_icon = \"‚úì\" if result['success'] else \"‚úó\"\n",
    "                print(f\"    {status_icon} Pass {pass_num} (GPU {result['gpu']}): {result['elapsed']:.1f}s\")\n",
    "                if not result['success'] and result['stderr']:\n",
    "                    print(f\"        Error: {result['stderr'][:200]}\")\n",
    "    else:\n",
    "        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "        # COLAB: Run passes sequentially on same GPU\n",
    "        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "        for pass_num in [1, 2]:\n",
    "            result = run_pass(pass_num, video, folder_path, cfg, gpu_assignment[pass_num])\n",
    "            results[pass_num] = result\n",
    "            status_icon = \"‚úì\" if result['success'] else \"‚úó\"\n",
    "            print(f\"    {status_icon} Pass {pass_num}: {result['elapsed']:.1f}s\")\n",
    "            if not result['success'] and result['stderr']:\n",
    "                print(f\"        Error: {result['stderr'][:200]}\")\n",
    "\n",
    "    # Merge results if both passes succeeded\n",
    "    if results[1]['success'] and results[2]['success']:\n",
    "        merged_output = folder_path / f\"{video.stem}.merged.whisperjav.srt\"\n",
    "        stats = merge_srt(results[1]['output'], results[2]['output'], merged_output, cfg['merge_strategy'])\n",
    "        print(f\"    ‚úì Merged: {stats['pass1_count']} + {stats['pass2_count']} ‚Üí {stats['merged_count']} subtitles\")\n",
    "        merged_outputs.append(merged_output)\n",
    "    else:\n",
    "        # Use whichever pass succeeded\n",
    "        for p in [1, 2]:\n",
    "            if results[p]['success']:\n",
    "                # Copy to main folder with consistent naming\n",
    "                final_output = folder_path / f\"{video.stem}.whisperjav.srt\"\n",
    "                import shutil\n",
    "                shutil.copy2(results[p]['output'], final_output)\n",
    "                merged_outputs.append(final_output)\n",
    "                print(f\"    ‚ö† Using Pass {p} only (other pass failed)\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"    ‚úó Both passes failed!\")\n",
    "\n",
    "    all_results.append(results)\n",
    "\n",
    "# Store for Step 3\n",
    "WHISPERJAV_NEW_SRTS = merged_outputs\n",
    "WHISPERJAV_FOLDER_PATH = folder_path\n",
    "\n",
    "status(f\"\\nCreated {len(merged_outputs)} merged subtitle file(s)\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# ADD CREDITS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "section(\"ADDING CREDITS\")\n",
    "\n",
    "if cfg['opening_credit'] or cfg['closing_credit']:\n",
    "    credits_count = 0\n",
    "    for srt_file in merged_outputs:\n",
    "        try:\n",
    "            content = srt_file.read_text(encoding='utf-8')\n",
    "            if cfg['opening_credit']:\n",
    "                content = f\"0\\n00:00:00,000 --> 00:00:00,500\\n{cfg['opening_credit']}\\n\\n\" + content\n",
    "            if cfg['closing_credit']:\n",
    "                content += f\"\\n9999\\n23:59:58,000 --> 23:59:59,000\\n{cfg['closing_credit']}\\n\"\n",
    "            srt_file.write_text(content, encoding='utf-8')\n",
    "            credits_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not add credits to {srt_file.name}: {e}\")\n",
    "    status(f\"Credits added to {credits_count} file(s)\")\n",
    "else:\n",
    "    status(\"No credits configured\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# COMPLETE\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "section(\"TWO-PASS TRANSCRIPTION COMPLETE\")\n",
    "\n",
    "mode_text = \"parallel\" if PARALLEL_MODE else \"sequential\"\n",
    "if cfg['subtitle_language'] == 'llm' and cfg['api_key']:\n",
    "    display(HTML(f'<div style=\"padding:8px 10px;background:#fef9c3;border-radius:4px;border-left:2px solid #ca8a04;font-size:10px\"><b>‚úì Transcription done ({mode_text})!</b> {len(merged_outputs)} file(s). AI Translation will start next...</div>'))\n",
    "else:\n",
    "    display(HTML(f'<div style=\"padding:8px 10px;background:#f0fdf4;border-radius:4px;border-left:2px solid #16a34a;font-size:10px\"><b>‚úì Done ({mode_text})!</b> {len(merged_outputs)} subtitle(s) saved to Google Drive/{cfg[\"folder_name\"]}/</div>'))\n",
    "    if cfg['subtitle_language'] == 'llm' and not cfg['api_key']:\n",
    "        print(\"Note: AI translation skipped (no API key provided)\")\n",
    "\n",
    "    if cfg['auto_disconnect']:\n",
    "        print(\"\\nAuto-disconnecting in 10s to save GPU credits...\")\n",
    "        time.sleep(10)\n",
    "        try:\n",
    "            from google.colab import runtime\n",
    "            runtime.unassign()\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 3: AI Translation (if selected) { display-mode: \"form\" }\n",
    "#@markdown Translate each subtitle file using AI (only runs if \"English (AI translate)\" selected)\n",
    "\n",
    "import os, sys, subprocess, shlex, time\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    icon = \"‚úì\" if ok else \"‚úó\"\n",
    "    print(f\"{icon} {msg}\")\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'‚îÄ'*40}\\n{title}\\n{'‚îÄ'*40}\")\n",
    "\n",
    "# Check prerequisites\n",
    "if 'WHISPERJAV_CONFIG' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 1 first</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "if 'WHISPERJAV_NEW_SRTS' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 2 first</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "new_srts = WHISPERJAV_NEW_SRTS\n",
    "folder_path = WHISPERJAV_FOLDER_PATH\n",
    "\n",
    "# Check if AI translation is needed\n",
    "if cfg['subtitle_language'] != 'llm':\n",
    "    display(HTML('<div style=\"padding:8px 10px;background:#f0f9ff;border-radius:4px;border-left:2px solid #3b82f6;font-size:10px\"><b>‚Ñπ Skipped:</b> AI translation not selected</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "# Check API key requirement (not needed for local provider)\n",
    "is_local = cfg['translation_service'] == 'local'\n",
    "if not is_local and not cfg['api_key']:\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> No API key provided for cloud translation. Use \"local\" provider for free GPU translation.</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "if not new_srts:\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> No subtitle files to translate</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "# Set up API key (not needed for local)\n",
    "if not is_local:\n",
    "    env_map = {\n",
    "        \"deepseek\": \"DEEPSEEK_API_KEY\",\n",
    "        \"openrouter\": \"OPENROUTER_API_KEY\",\n",
    "        \"gemini\": \"GEMINI_API_KEY\",\n",
    "        \"claude\": \"ANTHROPIC_API_KEY\",\n",
    "        \"gpt\": \"OPENAI_API_KEY\"\n",
    "    }\n",
    "    os.environ[env_map.get(cfg['translation_service'], \"API_KEY\")] = cfg['api_key']\n",
    "\n",
    "# Translate each SRT file\n",
    "section(\"AI TRANSLATION\")\n",
    "if is_local:\n",
    "    print(f\"Provider: local ({cfg.get('local_model', 'gemma-9b')})\")\n",
    "    print(\"Note: First run downloads model (~5GB) and llama-cpp-python (~700MB)\")\n",
    "else:\n",
    "    print(f\"Provider: {cfg['translation_service']}\")\n",
    "print(f\"Style: {cfg['_translation_style']}\")\n",
    "print(f\"Files to translate: {len(new_srts)}\\n\")\n",
    "\n",
    "translated_files = []\n",
    "failed_files = []\n",
    "\n",
    "for i, srt_file in enumerate(new_srts, 1):\n",
    "    print(f\"[{i}/{len(new_srts)}] Translating: {srt_file.name}\")\n",
    "\n",
    "    translate_cmd = [\n",
    "        'whisperjav-translate',\n",
    "        '-i', str(srt_file),\n",
    "        '--provider', cfg['translation_service'],\n",
    "        '-t', 'english',\n",
    "        '--tone', cfg['translation_style'],\n",
    "        '--stream'\n",
    "    ]\n",
    "\n",
    "    # Add model for local provider\n",
    "    if is_local:\n",
    "        translate_cmd.extend(['--model', cfg.get('local_model', 'gemma-9b')])\n",
    "\n",
    "    full_cmd = shlex.join(translate_cmd)\n",
    "\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            full_cmd,\n",
    "            shell=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "\n",
    "        for line in process.stderr:\n",
    "            print(f\"    {line}\", end='')\n",
    "\n",
    "        stdout_output, _ = process.communicate()\n",
    "\n",
    "        if process.returncode == 0:\n",
    "            output_path = stdout_output.strip()\n",
    "            if output_path:\n",
    "                translated_files.append(Path(output_path))\n",
    "            status(f\"Completed: {srt_file.name}\")\n",
    "        else:\n",
    "            status(f\"Failed: {srt_file.name}\", False)\n",
    "            failed_files.append(srt_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        status(f\"Error translating {srt_file.name}: {e}\", False)\n",
    "        failed_files.append(srt_file)\n",
    "\n",
    "    print()\n",
    "\n",
    "# Complete\n",
    "section(\"COMPLETE\")\n",
    "\n",
    "if failed_files:\n",
    "    display(HTML(f'<div style=\"padding:8px 10px;background:#fef9c3;border-radius:4px;border-left:2px solid #ca8a04;font-size:10px\"><b>‚ö† Partially done!</b> {len(translated_files)}/{len(new_srts)} translated. {len(failed_files)} failed.</div>'))\n",
    "else:\n",
    "    display(HTML(f'<div style=\"padding:8px 10px;background:#f0fdf4;border-radius:4px;border-left:2px solid #16a34a;font-size:10px\"><b>‚úì All done!</b> {len(new_srts)} Japanese + {len(translated_files)} English subtitle(s) in Google Drive/{cfg[\"folder_name\"]}/</div>'))\n",
    "\n",
    "# Auto-disconnect\n",
    "if cfg['auto_disconnect']:\n",
    "    print(\"\\nAuto-disconnecting in 10s to save GPU credits...\")\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        from google.colab import runtime\n",
    "        runtime.unassign()\n",
    "    except: pass\n",
    "else:\n",
    "    print(\"\\nRemember to disconnect manually to save GPU credits.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
