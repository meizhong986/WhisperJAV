{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WhN-iiH59Ms"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_edition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# WhisperJAV\n",
        "\n",
        "**Automatically create Japanese subtitles for your videos.**\n",
        "\n",
        "| Mode | What it does | Speed |\n",
        "|------|--------------|-------|\n",
        "| **Standard** | Processes your video once | Faster |\n",
        "| **Two-Step** | Processes twice and combines for better accuracy | Slower |\n",
        "\n",
        "---\n",
        "### How to Use\n",
        "1. Upload your videos to `Google Drive/WhisperJAV/`\n",
        "2. Run **Step 1** to set up\n",
        "3. Adjust **Step 2** settings if needed\n",
        "4. Run **Step 3** to create subtitles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nftSpCec59Mw"
      },
      "outputs": [],
      "source": [
        "#@title Step 1: Set Up { display-mode: \"form\" }\n",
        "#@markdown ### Click the Play button to install (takes 2-3 minutes)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "def show_progress(msg, icon, color):\n",
        "    display(HTML(f'<div style=\"padding:10px 15px;margin:5px 0;border-radius:8px;background:linear-gradient(90deg,{color}22,transparent);border-left:4px solid {color}\"><span style=\"font-size:1.2em\">{icon}</span> <b>{msg}</b></div>'))\n",
        "\n",
        "def run_cmd(cmd, name):\n",
        "    show_progress(f\"Installing {name}...\", \"üì•\", \"#3498db\")\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    return result.returncode == 0\n",
        "\n",
        "print(\"Setting up WhisperJAV...\\n\")\n",
        "start = time.time()\n",
        "\n",
        "steps = [\n",
        "    (\"apt-get update -qq && apt-get install -y -qq ffmpeg portaudio19-dev > /dev/null 2>&1\", \"system tools\"),\n",
        "    (\"pip install -q tqdm numba tiktoken ffmpeg-python soundfile auditok numpy scipy pysrt srt aiofiles jsonschema Pillow colorama librosa matplotlib pyloudnorm requests faster-whisper transformers optimum accelerate huggingface-hub pydantic\", \"required packages\"),\n",
        "    (\"pip install -q --no-deps git+https://github.com/openai/whisper.git@main\", \"speech recognition\"),\n",
        "    (\"pip install -q --no-deps git+https://github.com/meizhong986/stable-ts-fix-setup.git@main\", \"timing tools\"),\n",
        "    (\"pip install -q git+https://github.com/meizhong986/WhisperJAV.git@main\", \"WhisperJAV\")\n",
        "]\n",
        "\n",
        "for cmd, name in steps:\n",
        "    if not run_cmd(cmd, name):\n",
        "        show_progress(f\"Failed: {name}\", \"‚ùå\", \"#e74c3c\")\n",
        "        sys.exit(1)\n",
        "\n",
        "clear_output()\n",
        "elapsed = time.time() - start\n",
        "\n",
        "import torch\n",
        "gpu_info, gpu_color = (\"Not available (will be slower)\", \"#f39c12\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_info = f\"{torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB)\"\n",
        "    gpu_color = \"#2ecc71\"\n",
        "\n",
        "WHISPERJAV_INSTALLED = True\n",
        "\n",
        "display(HTML(f'''\n",
        "<div style=\"background:linear-gradient(135deg,#1a1a2e,#16213e);padding:25px;border-radius:15px;color:white\">\n",
        "    <h2 style=\"margin:0 0 15px 0;color:#00d4aa\">Ready to Go!</h2>\n",
        "    <div style=\"display:grid;grid-template-columns:1fr 1fr;gap:15px\">\n",
        "        <div style=\"background:#ffffff15;padding:12px;border-radius:8px\">\n",
        "            <div style=\"color:#888;font-size:0.85em\">Setup Time</div>\n",
        "            <div style=\"font-size:1.3em;font-weight:bold\">{elapsed:.0f} seconds</div>\n",
        "        </div>\n",
        "        <div style=\"background:#ffffff15;padding:12px;border-radius:8px\">\n",
        "            <div style=\"color:#888;font-size:0.85em\">Graphics Card</div>\n",
        "            <div style=\"font-size:1em;font-weight:bold;color:{gpu_color}\">{gpu_info}</div>\n",
        "        </div>\n",
        "    </div>\n",
        "</div>\n",
        "'''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA_zp4NF59My"
      },
      "outputs": [],
      "source": [
        "#@title Step 2: Choose Your Settings { display-mode: \"form\" }\n",
        "#@markdown ---\n",
        "#@markdown ## Transcription Settings\n",
        "#@markdown *These control how your video is processed*\n",
        "quality = \"balanced\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
        "speech_detection = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
        "\n",
        "#@markdown ---\n",
        "use_two_step = False #@param {type:\"boolean\"}\n",
        "#@markdown ‚òùÔ∏è **Use Two-Step Processing** ‚Äî Takes longer but more accurate\n",
        "\n",
        "\n",
        "#@markdown *Only used when Two-Step Processing is enabled*\n",
        "2ndpass_quality = \"transformers\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
        "2ndpass_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
        "merge_method = \"prefer first step\" #@param [\"automatic\", \"keep all\", \"prefer first step\", \"prefer second step\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Where Are Your Files?\n",
        "folder_name = \"WhisperJAV\" #@param {type:\"string\"}\n",
        "#@markdown ‚òùÔ∏è Folder name in your Google Drive\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Subtitle Language\n",
        "subtitle_language = \"Japanese\" #@param [\"Japanese\", \"English (auto-translate)\", \"English (AI translate)\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## AI Translation Settings\n",
        "#@markdown *Only needed if you chose \"English (AI translate)\" above*\n",
        "translation_service = \"deepseek\" #@param [\"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\"]\n",
        "api_key = \"\" #@param {type:\"string\"}\n",
        "translation_style = \"standard\" #@param [\"standard\", \"explicit\"]\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "# Map user-friendly names to internal values (only for non-WhisperJAV terms)\n",
        "combine_map = {\"automatic\": \"smart_merge\", \"keep all\": \"full_merge\",\n",
        "               \"prefer first step\": \"pass1_primary\",\n",
        "               \"prefer second step\": \"pass2_primary\"}\n",
        "language_map = {\"Japanese\": \"native\", \"English (auto-translate)\": \"direct-to-english\",\n",
        "                \"English (AI translate)\": \"llm\"}\n",
        "\n",
        "WHISPERJAV_CONFIG = {\n",
        "    'use_two_step': use_two_step,\n",
        "    'pass1_pipeline': quality,\n",
        "    'pass1_sensitivity': speech_detection,\n",
        "    'pass2_pipeline': 2ndpass_quality,\n",
        "    'pass2_sensitivity': 2ndpass_sensitivity,\n",
        "    'merge_strategy': combine_map[merge_method],\n",
        "    'folder_name': folder_name,\n",
        "    'subtitle_language': language_map[subtitle_language],\n",
        "    'translation_service': translation_service,\n",
        "    'api_key': api_key,\n",
        "    'translation_style': translation_style,\n",
        "    # Keep display values for summary\n",
        "    '_quality': quality,\n",
        "    '_speech_detection': speech_detection,\n",
        "    '_2ndpass_quality': 2ndpass_quality,\n",
        "    '_2ndpass_sensitivity': 2ndpass_sensitivity,\n",
        "    '_merge_method': merge_method,\n",
        "    '_subtitle_language': subtitle_language,\n",
        "}\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "if use_two_step:\n",
        "    mode_text = \"Two-Step Processing\"\n",
        "    details = f\"{quality} ‚Üí {2ndpass_quality} ‚Üí {merge_method}\"\n",
        "    mode_color = \"#8b5cf6\"\n",
        "else:\n",
        "    mode_text = \"Standard Processing\"\n",
        "    details = f\"{quality} quality, {speech_detection} detection\"\n",
        "    mode_color = \"#3b82f6\"\n",
        "\n",
        "lang_display = subtitle_language\n",
        "if subtitle_language == \"English (AI translate)\":\n",
        "    lang_display = f\"English via {translation_service}\" if api_key else \"Japanese (no API key provided)\"\n",
        "\n",
        "display(HTML(f'''\n",
        "<div style=\"background:linear-gradient(135deg,#1e293b,#334155);padding:20px;border-radius:12px;color:white\">\n",
        "    <div style=\"display:flex;align-items:center;gap:10px;margin-bottom:15px\">\n",
        "        <span style=\"background:{mode_color};padding:4px 12px;border-radius:20px;font-size:0.85em\">{mode_text}</span>\n",
        "        <span style=\"color:#94a3b8\">Settings saved</span>\n",
        "    </div>\n",
        "    <table style=\"color:white;border-collapse:collapse;width:100%\">\n",
        "        <tr><td style=\"padding:6px 0;color:#64748b;width:100px\">Settings:</td><td>{details}</td></tr>\n",
        "        <tr><td style=\"padding:6px 0;color:#64748b\">Folder:</td><td>Google Drive/{folder_name}/</td></tr>\n",
        "        <tr><td style=\"padding:6px 0;color:#64748b\">Subtitles:</td><td>{lang_display}</td></tr>\n",
        "    </table>\n",
        "</div>\n",
        "'''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2mvFlKD59My"
      },
      "outputs": [],
      "source": [
        "#@title Step 3: Create Subtitles { display-mode: \"form\" }\n",
        "#@markdown ### Click Play to process your videos\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shlex\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Check prerequisites\n",
        "if 'WHISPERJAV_INSTALLED' not in dir():\n",
        "    display(HTML('<div style=\"padding:15px;background:#fef2f2;border-radius:8px;border-left:4px solid #ef4444;color:#991b1b\"><b>Please run Step 1 first</b></div>'))\n",
        "    raise SystemExit()\n",
        "\n",
        "if 'WHISPERJAV_CONFIG' not in dir():\n",
        "    display(HTML('<div style=\"padding:15px;background:#fef2f2;border-radius:8px;border-left:4px solid #ef4444;color:#991b1b\"><b>Please run Step 2 first</b></div>'))\n",
        "    raise SystemExit()\n",
        "\n",
        "cfg = WHISPERJAV_CONFIG\n",
        "\n",
        "# Connect to Google Drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "folder_path = Path(f\"/content/drive/MyDrive/{cfg['folder_name']}\")\n",
        "folder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Find video files\n",
        "video_types = {'.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.mp3', '.wav', '.flac', '.m4a'}\n",
        "videos = [f for f in folder_path.iterdir() if f.suffix.lower() in video_types]\n",
        "\n",
        "if not videos:\n",
        "    display(HTML(f'''\n",
        "    <div style=\"padding:15px;background:#fefce8;border-radius:8px;border-left:4px solid #eab308;color:#854d0e\">\n",
        "        <b>No videos found</b><br>\n",
        "        Please upload your videos to: <b>Google Drive/{cfg['folder_name']}/</b>\n",
        "    </div>\n",
        "    '''))\n",
        "    raise SystemExit()\n",
        "\n",
        "print(f\"Found {len(videos)} video(s) in Google Drive/{cfg['folder_name']}/\")\n",
        "\n",
        "# Build the command\n",
        "cmd = ['whisperjav', str(folder_path), '--output-dir', str(folder_path)]\n",
        "\n",
        "if cfg['use_two_step']:\n",
        "    cmd.extend([\n",
        "        '--ensemble',\n",
        "        '--pass1-pipeline', cfg['pass1_pipeline'],\n",
        "        '--pass1-sensitivity', cfg['pass1_sensitivity'],\n",
        "        '--pass2-pipeline', cfg['pass2_pipeline'],\n",
        "        '--pass2-sensitivity', cfg['pass2_sensitivity'],\n",
        "        '--merge-strategy', cfg['merge_strategy']\n",
        "    ])\n",
        "    print(f\"\\nUsing Two-Step Processing:\")\n",
        "    print(f\"  Step 1: {cfg['_quality']} quality, {cfg['_speech_detection']} detection\")\n",
        "    print(f\"  Step 2: {cfg['_2ndpass_quality']} quality, {cfg['_2ndpass_sensitivity']} detection\")\n",
        "    print(f\"  Combining: {cfg['_merge_method']}\")\n",
        "else:\n",
        "    cmd.extend(['--mode', cfg['pass1_pipeline'], '--sensitivity', cfg['pass1_sensitivity']])\n",
        "    print(f\"\\nUsing Standard Processing:\")\n",
        "    print(f\"  Quality: {cfg['_quality']}\")\n",
        "    print(f\"  Speech Detection: {cfg['_speech_detection']}\")\n",
        "\n",
        "# Handle subtitle language\n",
        "if cfg['subtitle_language'] == 'direct-to-english':\n",
        "    cmd.extend(['--subs-language', 'direct-to-english'])\n",
        "    print(f\"  Subtitles: English (auto-translate)\")\n",
        "elif cfg['subtitle_language'] == 'llm' and cfg['api_key']:\n",
        "    cmd.extend(['--subs-language', 'native', '--translate', '--translate-provider', cfg['translation_service'], '--translate-tone', cfg['translation_style']])\n",
        "    env_map = {\"deepseek\": \"DEEPSEEK_API_KEY\", \"openrouter\": \"OPENROUTER_API_KEY\", \"gemini\": \"GEMINI_API_KEY\", \"claude\": \"ANTHROPIC_API_KEY\", \"gpt\": \"OPENAI_API_KEY\"}\n",
        "    os.environ[env_map.get(cfg['translation_service'], \"API_KEY\")] = cfg['api_key']\n",
        "    print(f\"  Subtitles: Japanese + English ({cfg['translation_service']})\")\n",
        "else:\n",
        "    cmd.extend(['--subs-language', 'native'])\n",
        "    print(f\"  Subtitles: Japanese\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CREATING SUBTITLES\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "!{shlex.join(cmd)}\n",
        "\n",
        "subtitle_count = len(list(folder_path.glob(\"*.srt\")))\n",
        "display(HTML(f'''\n",
        "<div style=\"background:linear-gradient(135deg,#14532d,#166534);padding:20px;border-radius:12px;color:white;margin-top:20px\">\n",
        "    <h3 style=\"margin:0 0 8px 0\">All Done!</h3>\n",
        "    <p style=\"margin:0;color:#bbf7d0\">Your subtitles are in: <b>Google Drive/{cfg['folder_name']}/</b></p>\n",
        "    <p style=\"margin:5px 0 0 0;color:#86efac\">{subtitle_count} subtitle file(s) created</p>\n",
        "</div>\n",
        "'''))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
