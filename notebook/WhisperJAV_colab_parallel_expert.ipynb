{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>\n",
    "\n",
    "# WhisperJAV Ensemble Dual-GPU Edition (v1.8.0)\n",
    "\n",
    "**Universal Parallel Workflow**\n",
    "\n",
    "| Platform | Logic | Storage |\n",
    "|----------|-------|---------|\n",
    "| **Kaggle** | **Parallel** (2x T4) | **Input**: `/kaggle/input` (Dataset) <br> **Output**: `/kaggle/working` (Artifacts) |\n",
    "| **Colab** | **Sequential** (1x GPU) | **Input/Output**: Google Drive |\n",
    "\n",
    "---\n",
    "### **Workflow**\n",
    "1. **Configure**: Select your settings, models, and audio preferences.\n",
    "2. **Setup**: Installs dependencies and prepares the environment (**Run Once**).\n",
    "3. **Transcribe**: Processes your video files using the configured settings.\n",
    "4. **Translate**: (Optional) Uses AI to translate subtitles to English.\n",
    "\n",
    "<small><i>Tip: Select your Dataset in Kaggle, then use \"Run All\". The notebook is designed to Fail Fast if resources are missing.</i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": "#@title Step 1: Expert Configuration { display-mode: \"form\" }\n\n#@markdown ## ğŸ“ Files & Output\nfolder_name = \"WhisperJAV\" #@param {type:\"string\"}\nsubtitle_language = \"Japanese\" #@param [\"Japanese\", \"English (auto-translate)\", \"English (AI translate)\"]\nspoken_language = \"Japanese\" #@param [\"Japanese\", \"Chinese\", \"English\", \"Korean\"]\n\n#@markdown ---\n#@markdown ## 1ï¸âƒ£ Pass 1 Configuration (GPU 0)\npass1_quality = \"balanced\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\npass1_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\npass1_model = \"large-v2\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n\n#@markdown **Expert Audio Setup (Pass 1)**\npass1_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\npass1_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\npass1_speech_enhancer = \"none\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n#@markdown <font size=\"1\">auditok=energy (fast), silero=VAD, semantic=texture (complex audio) | enhancer: ffmpeg-dsp(no GPU), clearvoice(48k), bs-roformer(vocal)</font>\n\n#@markdown **FFmpeg Filters (Pass 1)** *(only if enhancer is ffmpeg-dsp)*\npass1_ffmpeg_amplify = True #@param {type:\"boolean\"}\npass1_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\npass1_ffmpeg_compress = False #@param {type:\"boolean\"}\npass1_ffmpeg_highpass = False #@param {type:\"boolean\"}\n\n#@markdown ---\n#@markdown ## 2ï¸âƒ£ Pass 2 Configuration (GPU 1)\npass2_quality = \"fidelity\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\npass2_sensitivity = \"balanced\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\npass2_model = \"turbo\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n\n#@markdown **Expert Audio Setup (Pass 2)**\npass2_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\npass2_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\npass2_speech_enhancer = \"ffmpeg-dsp\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n\n#@markdown **FFmpeg Filters (Pass 2)** *(only if enhancer is ffmpeg-dsp)*\npass2_ffmpeg_amplify = True #@param {type:\"boolean\"}\npass2_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\npass2_ffmpeg_compress = False #@param {type:\"boolean\"}\npass2_ffmpeg_highpass = False #@param {type:\"boolean\"}\n\n#@markdown ---\n#@markdown ## ğŸ”— Merge Strategy\nmerge_method = \"prefer first pass\" #@param [\"automatic\", \"keep all\", \"prefer first pass\", \"prefer second pass\"]\n\n#@markdown ---\n#@markdown ## ğŸ¤– AI Translation *(if selected)*\ntranslation_service = \"local\" #@param [\"local\", \"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\", \"glm\", \"groq\"]\nlocal_model = \"gemma-9b\" #@param [\"gemma-9b\", \"llama-8b\", \"llama-3b\", \"auto\"]\n#@markdown <font size=\"1\">local: Free, runs on GPU. gemma-9b (8GB+ VRAM), llama-8b (6GB+), llama-3b (3GB+). Cloud providers require API key.</font>\napi_key = \"\" #@param {type:\"string\"}\ntranslation_style = \"standard\" #@param [\"standard\", \"explicit\"]\n\n#@markdown ---\n#@markdown ## âš™ï¸ Session\nopening_credit = \"\" #@param {type:\"string\"}\nclosing_credit = \"Subs by WhisperJAV\" #@param {type:\"string\"}\nauto_disconnect = True #@param {type:\"boolean\"}\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# CONFIGURATION LOGIC\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nimport sys\nimport os\n\n# Detect Platform Early (needed for venv paths)\nif \"google.colab\" in sys.modules:\n    PLATFORM = \"colab\"\nelif os.path.exists(\"/kaggle\"):\n    PLATFORM = \"kaggle\"\nelse:\n    PLATFORM = \"local\"\n\n# Venv paths for Colab (isolated environment to avoid numpy conflicts)\n# Kaggle uses direct installation (no venv needed - cleaner base environment)\nif PLATFORM == \"colab\":\n    VENV_PATH = \"/content/whisperjav_env\"\n    WHISPERJAV_CMD = f\"{VENV_PATH}/bin/whisperjav\"\n    WHISPERJAV_TRANSLATE_CMD = f\"{VENV_PATH}/bin/whisperjav-translate\"\n    VENV_PYTHON = f\"{VENV_PATH}/bin/python\"\nelse:\n    VENV_PATH = None\n    WHISPERJAV_CMD = None  # Will use sys.executable -m whisperjav.main\n    WHISPERJAV_TRANSLATE_CMD = None  # Will use sys.executable -m whisperjav.translate.cli\n    VENV_PYTHON = None\n\n# Mapping dictionaries\ncombine_map = {\"automatic\": \"smart_merge\", \"keep all\": \"full_merge\",\n               \"prefer first pass\": \"pass1_primary\", \"prefer second pass\": \"pass2_primary\"}\nlanguage_map = {\"Japanese\": \"native\", \"English (auto-translate)\": \"direct-to-english\",\n                \"English (AI translate)\": \"llm\"}\ntone_map = {\"standard\": \"standard\", \"explicit\": \"pornify\"}\nspoken_language_map = {\"Japanese\": \"japanese\", \"Chinese\": \"chinese\", \"English\": \"english\", \"Korean\": \"korean\"}\n\n# Model mapping (None = use pipeline default)\nmodel_map = {\n    \"automatic\": None,\n    \"large-v2\": \"large-v2\",\n    \"large-v3\": \"large-v3\",\n    \"turbo\": \"turbo\",\n    \"kotoba-bilingual\": \"kotoba-tech/kotoba-whisper-bilingual-v1.0\",\n    \"kotoba-v2.0\": \"kotoba-tech/kotoba-whisper-v2.0\",\n    \"kotoba-v2.1\": \"kotoba-tech/kotoba-whisper-v2.1\",\n    \"kotoba-v2.2\": \"kotoba-tech/kotoba-whisper-v2.2\"\n}\n\n# Define model compatibility:\nKOTOBA_MODELS = {\"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"}\nLEGACY_PIPELINES = {\"faster\", \"fast\", \"balanced\", \"fidelity\"}\n\n# Auto-correct incompatible model-pipeline combinations\nwarnings_list = []\n\n# Check Pass 1 compatibility\nif pass1_model in KOTOBA_MODELS and pass1_quality in LEGACY_PIPELINES:\n    warnings_list.append(f\"Pass 1: {pass1_model} requires 'transformers' pipeline. Auto-correcting from '{pass1_quality}' to 'transformers'.\")\n    pass1_quality = \"transformers\"\n\n# Check Pass 2 compatibility\nif pass2_model in KOTOBA_MODELS and pass2_quality in LEGACY_PIPELINES:\n    warnings_list.append(f\"Pass 2: {pass2_model} requires 'transformers' pipeline. Auto-correcting from '{pass2_quality}' to 'transformers'.\")\n    pass2_quality = \"transformers\"\n\n# Memory warning\nheavy_enhancers = {'clearvoice', 'bs-roformer', 'zipenhancer'}\nif pass1_speech_enhancer in heavy_enhancers and pass2_speech_enhancer in heavy_enhancers:\n    warnings_list.append(\"Using GPU-based enhancement on both passes may cause OOM on T4 GPU (Sequential Mode). Suggest using ffmpeg-dsp for one pass.\")\n\n# Helpers\ndef build_ffmpeg_filters(amplify, loudnorm, compress, highpass):\n    \"\"\"Combine selected FFmpeg filters into comma-separated string.\"\"\"\n    filters = []\n    if amplify: filters.append(\"amplify\")\n    if loudnorm: filters.append(\"loudnorm\")\n    if compress: filters.append(\"compress\")\n    if highpass: filters.append(\"highpass\")\n    return \",\".join(filters) if filters else None\n\ndef map_value(val):\n    return None if val == \"automatic\" else val\n\ndef map_segmenter(val):\n    return \"none\" if val == \"none\" else map_value(val)\n\n# Unified Config Construction\nWHISPERJAV_CONFIG = {\n    'pass1_pipeline': pass1_quality,\n    'pass1_sensitivity': pass1_sensitivity,\n    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter),\n    'pass1_model': model_map[pass1_model],\n    'pass2_pipeline': pass2_quality,\n    'pass2_sensitivity': pass2_sensitivity,\n    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter),\n    'pass2_model': model_map[pass2_model],\n    'merge_strategy': combine_map[merge_method],\n    'folder_name': folder_name,\n    'subtitle_language': language_map[subtitle_language],\n    'language': spoken_language_map[spoken_language],\n    'translation_service': translation_service,\n    'local_model': local_model,\n    'api_key': api_key,\n    'translation_style': tone_map[translation_style],\n    'opening_credit': opening_credit,\n    'closing_credit': closing_credit,\n    'auto_disconnect': auto_disconnect,\n    # Platform and venv info\n    'platform': PLATFORM,\n    'venv_path': VENV_PATH,\n    'whisperjav_cmd': WHISPERJAV_CMD,\n    'whisperjav_translate_cmd': WHISPERJAV_TRANSLATE_CMD,\n    'venv_python': VENV_PYTHON,\n    # Compatibility checks for Step 2\n    '_pass1_quality': pass1_quality,\n    '_pass1_sensitivity': pass1_sensitivity,\n    '_pass1_speech_segmenter': pass1_speech_segmenter,\n    '_pass1_model': pass1_model,\n    '_pass2_quality': pass2_quality,\n    '_pass2_sensitivity': pass2_sensitivity,\n    '_pass2_speech_segmenter': pass2_speech_segmenter,\n    '_pass2_model': pass2_model,\n    '_merge_method': merge_method,\n    '_subtitle_language': subtitle_language,\n    '_translation_style': translation_style,\n}\n\nWHISPERJAV_EXPERT_CONFIG = {\n    # Pass 1 Expert\n    'pass1_scene_detector': map_value(pass1_scene_detector),\n    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter), # Now unified\n    'pass1_speech_enhancer': None if pass1_speech_enhancer == \"none\" else pass1_speech_enhancer,\n    'pass1_ffmpeg_filters': build_ffmpeg_filters(pass1_ffmpeg_amplify, pass1_ffmpeg_loudnorm, pass1_ffmpeg_compress, pass1_ffmpeg_highpass) if pass1_speech_enhancer == \"ffmpeg-dsp\" else None,\n    # Pass 2 Expert\n    'pass2_scene_detector': map_value(pass2_scene_detector),\n    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter), # Now unified\n    'pass2_speech_enhancer': None if pass2_speech_enhancer == \"none\" else pass2_speech_enhancer,\n    'pass2_ffmpeg_filters': build_ffmpeg_filters(pass2_ffmpeg_amplify, pass2_ffmpeg_loudnorm, pass2_ffmpeg_compress, pass2_ffmpeg_highpass) if pass2_speech_enhancer == \"ffmpeg-dsp\" else None,\n    # Display helpers\n    '_pass1_scene_detector': pass1_scene_detector,\n    '_pass1_speech_enhancer': pass1_speech_enhancer,\n    '_pass2_scene_detector': pass2_scene_detector,\n    '_pass2_speech_enhancer': pass2_speech_enhancer,\n}\n\nfrom IPython.display import display, HTML\n\n# Display warnings\nfor warning in warnings_list:\n    display(HTML(f'<div style=\"padding:6px 10px;background:#fef9c3;border-radius:4px;font-size:10px;margin-bottom:4px\"><b>âš ï¸ Auto-corrected:</b> {warning}</div>'))\n\n# Build status display\np1_info = f\"{pass1_quality}\"\nif pass1_speech_segmenter != \"automatic\":\n    p1_info += f\"/{pass1_speech_segmenter}\"\nif pass1_model != \"automatic\":\n    p1_info += f\"/{pass1_model}\"\n\np2_info = f\"{pass2_quality}\"\nif pass2_speech_segmenter != \"automatic\":\n    p2_info += f\"/{pass2_speech_segmenter}\"\nif pass2_model != \"automatic\":\n    p2_info += f\"/{pass2_model}\"\n\ndisplay(HTML(f'<div style=\"padding:10px;background:#e0f2fe;border-radius:4px;font-size:11px\">'\n             f'<b>Parallel Configuration Loaded</b><br>'\n             f'Platform: {PLATFORM.upper()} | Pass 1: {p1_info} | Pass 2: {p2_info}<br>'\n             f'Merge: {merge_method} | Folder: {folder_name} | Language: {spoken_language}'\n             f'</div>'))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbcce2",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": "#@title Step 2: Setup & Environment (Run Once) { display-mode: \"form\" }\n#@markdown - **Fails Fast** if GPU or Internet is missing.\n#@markdown - **Colab**: Uses isolated venv via `install_colab.sh` (avoids numpy conflicts)\n#@markdown - **Kaggle**: Direct pip install with pinned versions (auto-fixes numpy 2.x conflict)\n\nimport os\nimport shutil\nimport subprocess\nimport sys\nimport time\nimport socket\n\n# Fix matplotlib backend conflict\nos.environ['MPLBACKEND'] = 'Agg'\n\ndef section(title):\n    print(f\"\\n{'â”€'*40}\\n{title}\\n{'â”€'*40}\")\n\ndef status(msg, ok=True):\n    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n\ndef must(condition, msg):\n    if not condition:\n        raise RuntimeError(f\"SETUP FAILED: {msg}\")\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 1. PRE-FLIGHT CHECKS (Fail Fast)\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nsection(\"PRE-FLIGHT CHECKS\")\n\n# Get config from Step 1\nif \"WHISPERJAV_CONFIG\" not in globals():\n    from IPython.display import display, HTML\n    display(HTML('<div style=\"background:#fee2e2;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Run Step 1 First</b></div>'))\n    raise RuntimeError(\"Step 1 required\")\n\ncfg = WHISPERJAV_CONFIG\nPLATFORM = cfg['platform']\nprint(f\"Platform: {PLATFORM.upper()}\")\nprint(f\"Python:   {sys.executable} ({sys.version.split()[0]})\")\n\n# Check GPU\ngpu_check = subprocess.run(\"nvidia-smi --query-gpu=name --format=csv,noheader\", shell=True, capture_output=True, text=True)\nmust(gpu_check.returncode == 0 and bool(gpu_check.stdout.strip()), \"No GPU detected. Switch runtime to GPU.\")\ngpus = [line.strip() for line in gpu_check.stdout.splitlines() if line.strip()]\nstatus(f\"GPU(s) Detected: {len(gpus)} ({', '.join(gpus)})\")\n\n# Check Internet\ndef check_internet():\n    endpoints = [(\"www.baidu.com\", 80), (\"www.google.com\", 80), (\"1.1.1.1\", 53)]\n    for host, port in endpoints:\n        try:\n            socket.create_connection((host, port), timeout=3.0).close()\n            return True\n        except OSError:\n            continue\n    return False\n\nmust(check_internet(), \"Internet disabled/unreachable. Cannot install dependencies.\")\nstatus(\"Internet reachable\")\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 2. INSTALLATION (Platform-specific)\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nsection(\"INSTALLING DEPENDENCIES\")\ninstall_start = time.time()\n\nif PLATFORM == \"colab\":\n    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    # COLAB: Use install_colab.sh for isolated venv\n    # This avoids numpy 2.x conflicts with Colab's base environment\n    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    REPO_URL = \"https://github.com/meizhong986/WhisperJAV.git\"\n    REPO_PATH = \"/content/WhisperJAV\"\n    SCRIPT_PATH = f\"{REPO_PATH}/installer/install_colab.sh\"\n    VENV_PATH = cfg['venv_path']\n    \n    def run_installer():\n        \"\"\"Run install script with real-time output streaming.\"\"\"\n        env = {**os.environ, \"PATH\": f\"{os.environ.get('PATH', '')}:{os.path.expanduser('~/.local/bin')}\"}\n        process = subprocess.Popen(\n            [\"bash\", SCRIPT_PATH],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            bufsize=1,\n            text=True,\n            env=env\n        )\n        for line in iter(process.stdout.readline, ''):\n            print(line, end='', flush=True)\n        process.wait()\n        return process.returncode\n    \n    # Check if already installed\n    venv_python = cfg['venv_python']\n    if os.path.exists(venv_python):\n        check = subprocess.run([venv_python, \"-c\", \"import whisperjav\"], capture_output=True)\n        if check.returncode == 0:\n            status(\"WhisperJAV already installed (skipping)\")\n        else:\n            status(\"Existing venv corrupt, reinstalling...\")\n            subprocess.run([\"rm\", \"-rf\", VENV_PATH], capture_output=True)\n            if not os.path.exists(REPO_PATH):\n                subprocess.run([\"git\", \"clone\", REPO_URL, REPO_PATH], capture_output=True)\n            returncode = run_installer()\n            must(returncode == 0, \"Installation failed\")\n    else:\n        # Fresh install\n        print(\"Installing WhisperJAV (uv-accelerated)...\\n\")\n        sys.stdout.flush()\n        if not os.path.exists(REPO_PATH):\n            print(f\"Cloning {REPO_URL}...\")\n            result = subprocess.run([\"git\", \"clone\", REPO_URL, REPO_PATH], capture_output=True, text=True)\n            must(result.returncode == 0, f\"Clone failed: {result.stderr}\")\n\n        must(os.path.exists(SCRIPT_PATH), f\"Install script not found at {SCRIPT_PATH}\")\n        returncode = run_installer()\n        must(returncode == 0, \"Installation failed\")\n    \n    status(f\"Installation Complete ({time.time() - install_start:.0f}s)\")\n\nelse:\n    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    # KAGGLE: Direct pip install with fixed versions\n    # Kaggle has a cleaner base environment, so direct install works\n    # BUT: Kaggle pre-loads numpy 2.x into memory, requiring special handling\n    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    \n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    # KAGGLE NUMPY 2.X CONFLICT DETECTION & FIX\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    # Kaggle pre-loads numpy 2.x into memory at kernel start.\n    # Even if we pip install numpy<2.0, the OLD version stays in memory.\n    # Solution: Detect, fix packages, then require kernel restart.\n    \n    import numpy as np\n    NUMPY_MAJOR = int(np.__version__.split('.')[0])\n    \n    if NUMPY_MAJOR >= 2:\n        from IPython.display import display, HTML\n        \n        print(\"âš ï¸  Kaggle has numpy 2.x pre-loaded in memory.\")\n        print(\"    This conflicts with numba which requires numpy<2.0.\")\n        print(\"\")\n        print(\"Fixing package versions...\")\n        \n        # Uninstall conflicting packages (they'll be reinstalled with correct versions)\n        conflict_pkgs = [\"numpy\", \"numba\", \"llvmlite\", \"scipy\"]\n        for pkg in conflict_pkgs:\n            subprocess.run(\n                [sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg],\n                capture_output=True\n            )\n        print(\"  âœ“ Removed conflicting packages\")\n        \n        # Install correct versions with --no-deps to avoid pulling in numpy 2.x\n        # These versions match our setup.py constraints\n        subprocess.run([\n            sys.executable, \"-m\", \"pip\", \"install\",\n            \"numpy>=1.26.0,<2.0\",\n            \"numba>=0.58.0,<0.60.0\",\n            \"llvmlite>=0.41.0,<0.43.0\",\n            \"scipy>=1.10.1,<1.14\",\n            \"--no-deps\", \"--force-reinstall\", \"-q\"\n        ], check=True)\n        print(\"  âœ“ Installed compatible versions\")\n        \n        # Display restart instructions\n        print(\"\")\n        display(HTML('''\n        <div style=\"background:#fef3c7;border:2px solid #f59e0b;border-radius:8px;padding:16px;margin:10px 0;\">\n            <h3 style=\"margin:0 0 10px 0;color:#92400e;\">ğŸ”„ Kernel Restart Required</h3>\n            <p style=\"margin:0 0 10px 0;\">Package versions have been fixed on disk, but the old numpy 2.x is still loaded in memory.</p>\n            <p style=\"margin:0 0 10px 0;\"><b>To complete the fix:</b></p>\n            <ol style=\"margin:0 0 10px 0;\">\n                <li>Right-click this cell â†’ <b>\"Restart Session\"</b> (or use Session menu)</li>\n                <li>After restart, run <b>Step 1</b> again, then <b>Step 2</b></li>\n                <li>Step 2 will detect numpy 1.x and proceed normally</li>\n            </ol>\n            <p style=\"margin:0;color:#92400e;\"><b>This is a one-time fix. After restart, \"Run All\" will work.</b></p>\n        </div>\n        '''))\n        \n        raise RuntimeError(\"Kernel restart required - see instructions above\")\n    else:\n        status(f\"NumPy {np.__version__} (compatible - no restart needed)\")\n    \n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    # NORMAL KAGGLE INSTALLATION (numpy 1.x)\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    \n    def run_shell(name, cmd):\n        \"\"\"Run a shell command with timeout.\"\"\"\n        print(f\"... installing {name}\")\n        try:\n            r = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=600)\n        except subprocess.TimeoutExpired:\n            raise RuntimeError(f\"Install timed out (10m): {name}\")\n        if r.returncode != 0:\n            print((r.stderr or r.stdout or \"\")[-2000:])\n            raise RuntimeError(f\"Install failed: {name}\")\n        status(f\"Installed {name}\")\n\n    def run_pip(name, packages, no_deps=False):\n        \"\"\"Run pip install with timeout.\"\"\"\n        print(f\"... installing {name}\")\n        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"]\n        if no_deps:\n            cmd.append(\"--no-deps\")\n        cmd.extend(packages)\n        try:\n            r = subprocess.run(cmd, check=False, text=True, capture_output=True, timeout=600)\n        except subprocess.TimeoutExpired:\n            raise RuntimeError(f\"Pip Install timed out (10m): {name}\")\n        if r.returncode != 0:\n            print(f\"--- pip stderr for {name} ---\")\n            print((r.stderr or r.stdout or \"\")[-2000:])\n            raise RuntimeError(f\"Pip Install failed: {name}\")\n        status(f\"Installed {name}\")\n\n    # Determine sudo usage\n    prefix = \"\"\n    if shutil.which(\"sudo\") and not (hasattr(os, \"geteuid\") and os.geteuid() == 0):\n        prefix = \"sudo \"\n\n    # A. System Layer (APT)\n    sys_pkgs = \"ffmpeg portaudio19-dev libc++1 libc++abi1\"\n    run_shell(\"System Tools (apt)\", f\"{prefix}apt-get update -qq && {prefix}apt-get install -y -qq {sys_pkgs}\")\n    must(shutil.which(\"ffmpeg\"), \"FFmpeg installation verified\")\n\n    # B. Core Acceleration Layer (Pip)\n    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\"], check=False)\n\n    # CRITICAL: Pin numba<0.60 to work with numpy<2.0\n    # numba 0.60+ requires numpy 2.0, numba 0.58-0.59 requires numpy<2.0\n    core_libs = [\n        \"tqdm\", \"numba>=0.58.0,<0.60.0\", \"tiktoken\", \"soundfile\", \"auditok\", \"requests\", \"colorama\", \"regex\",\n        \"numpy>=1.26.0,<2.0\", \"scipy>=1.10.1,<1.14\", \"librosa>=0.10.0,<0.11\",\n        \"pysrt\", \"srt\", \"aiofiles\", \"jsonschema\", \"Pillow\", \"pyloudnorm\", \"pydantic>=2,<3\",\n        \"faster-whisper>=1.1.0\", \"transformers\", \"optimum\", \"accelerate\", \"huggingface-hub>=0.25.0\",\n        \"ten-vad\", \"silero-vad>=6.0\", \"pydub\",\n        \"modelscope>=1.20\", \"onnxruntime>=1.16.0\", \"addict\", \"simplejson\", \"sortedcontainers\", \"packaging\"\n    ]\n    run_pip(\"Core Acceleration Libs\", core_libs)\n\n    # C. Application Layer (Git)\n    git_pkgs = [\n        (\"ffmpeg-python\", \"git+https://github.com/kkroening/ffmpeg-python.git\"),\n        (\"Whisper\", \"git+https://github.com/openai/whisper.git@main\"),\n        (\"Stable-TS\", \"git+https://github.com/meizhong986/stable-ts-fix-setup.git@main\"),\n        (\"ClearVoice\", \"git+https://github.com/modelscope/ClearerVoice-Studio.git#subdirectory=clearvoice\"),\n        (\"WhisperJAV\", \"git+https://github.com/meizhong986/WhisperJAV.git@main\"),\n    ]\n\n    for name, url in git_pkgs:\n        run_pip(name, [url], no_deps=False)\n\n    # D. Force reinstall pinned versions (ensure consistency after git installs)\n    run_pip(\"Ensure Core Consistency\", [\n        \"--force-reinstall\", \"--upgrade\",\n        \"numpy>=1.26.0,<2.0\", \"scipy>=1.10.1,<1.14\", \"librosa>=0.10.0,<0.11\",\n        \"numba>=0.58.0,<0.60.0\", \"scikit-learn>=1.3.0\"\n    ], no_deps=True)\n\n    status(f\"Installation Complete ({time.time() - install_start:.0f}s)\")\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 3. VERIFICATION\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nsection(\"VERIFICATION\")\n\n# Determine which python to use for verification\nif PLATFORM == \"colab\":\n    verify_python = cfg['venv_python']\nelse:\n    verify_python = sys.executable\n\n# Verify Import\nresult = subprocess.run([verify_python, \"-c\", \"import whisperjav; print(whisperjav.__version__)\"], capture_output=True, text=True)\nif result.returncode == 0:\n    status(f\"WhisperJAV {result.stdout.strip()} Ready\")\nelse:\n    raise RuntimeError(f\"Installation successful but import failed: {result.stderr}\")\n\n# Verify TEN VAD\nresult = subprocess.run([verify_python, \"-c\", \"import ten_vad\"], capture_output=True, text=True)\nif result.returncode == 0:\n    status(\"TEN VAD Ready\")\nelse:\n    status(\"TEN VAD Warning (Import failed - Silero fallback)\", False)\n\n# Verify numpy version (critical check)\nresult = subprocess.run([verify_python, \"-c\", \"import numpy; print(numpy.__version__)\"], capture_output=True, text=True)\nif result.returncode == 0:\n    numpy_version = result.stdout.strip()\n    if numpy_version.startswith(\"2.\"):\n        status(f\"WARNING: NumPy {numpy_version} detected - may cause numba issues\", False)\n    else:\n        status(f\"NumPy {numpy_version} (compatible)\")\n\n# Stamp Success\nWHISPERJAV_SETUP_COMPLETE = {\n    \"timestamp\": time.time(),\n    \"platform\": PLATFORM,\n    \"gpu_count\": len(gpus)\n}\nprint(\"\\nâœ“ Environment Ready. Go to Step 3.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": "#@title Step 3: Execution (Transcribe) { display-mode: \"form\" }\n#@markdown - Auto-detects **Files** (Kaggle Dataset or Colab Drive).\n#@markdown - Auto-detects **Parallel** (2x GPU) or **Sequential** mode.\n#@markdown - Runs the configured WhisperJAV pipeline.\n\nimport os\nimport shutil\nimport sys\nimport time\nimport subprocess\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom IPython.display import HTML, FileLink, display\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# CHECKS & PREP\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nif \"WHISPERJAV_SETUP_COMPLETE\" not in globals():\n    display(HTML('<div style=\"background:#fee2e2;color:#991b1b;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Setup Incomplete</b><br>Please run <b>Step 2: Setup</b> first.</div>'))\n    raise RuntimeError(\"Step 2 required\")\n\nif \"WHISPERJAV_CONFIG\" not in globals():\n    display(HTML('<div style=\"background:#fee2e2;color:#991b1b;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Config Missing</b><br>Please run <b>Step 1: Configuration</b> first.</div>'))\n    raise RuntimeError(\"Step 1 required\")\n\ncfg = WHISPERJAV_CONFIG\nexpert = globals().get(\"WHISPERJAV_EXPERT_CONFIG\", {})\nPLATFORM = WHISPERJAV_SETUP_COMPLETE[\"platform\"]\nPARALLEL_MODE = WHISPERJAV_SETUP_COMPLETE[\"gpu_count\"] >= 2\n\ndef status(msg, ok=True):\n    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n\ndef check_progress(targets):\n    \"\"\"Prints tail of logs for active processes.\"\"\"\n    print(f\"\\n--- Status {time.strftime('%H:%M:%S')} ---\")\n    for path, label in targets:\n        if not path.exists(): continue\n        try:\n            with open(path, \"r\", errors=\"ignore\") as f:\n                f.seek(0, 2) # Go to end\n                size = f.tell()\n                # Read last 2KB to ensure we get 4 lines\n                f.seek(max(0, size - 2048), 0)\n                lines = f.readlines()\n                # If we seeked, drop the first partial line\n                if size > 2048 and len(lines) > 1:\n                    lines = lines[1:]\n                \n                valid_lines = [l.strip() for l in lines if l.strip()]\n                if valid_lines:\n                    print(f\"[{label}]:\")\n                    for l in valid_lines[-4:]:\n                        print(f\"  {l}\")\n        except Exception: \n            pass\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# I/O SETUP\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nprint(f\"Mode: {'PARALLEL (2x GPU)' if PARALLEL_MODE else 'SEQUENTIAL (Ensemble)'}\")\n\nif PLATFORM == \"colab\":\n    from google.colab import drive\n    drive.mount(\"/content/drive\", force_remount=False)\n    input_dir = Path(\"/content/drive/MyDrive\") / cfg[\"folder_name\"]\n    output_dir = input_dir\n    input_dir.mkdir(parents=True, exist_ok=True)\nelif PLATFORM == \"kaggle\":\n    # Search for video inputs\n    video_types = {\".mp4\", \".mkv\", \".avi\", \".mov\", \".wmv\", \".webm\"}\n    input_dir = None\n    for p in [Path(f\"/kaggle/input/{cfg['folder_name']}\"), Path(\"/kaggle/input\")]:\n        if p.exists() and any(f.suffix.lower() in video_types for f in p.rglob(\"*\")):\n            input_dir = p\n            break\n    if not input_dir:\n        input_dir = Path(\"/kaggle/input\")\n        print(\"WARN: No specific input folder found. Scanning root /kaggle/input.\")\n    \n    output_dir = Path(f\"/kaggle/working/{cfg['folder_name']}\")\n    output_dir.mkdir(parents=True, exist_ok=True)\n    os.environ[\"TMPDIR\"] = \"/kaggle/working/temp\" # Avoid RAM disk overflow\nelse:\n    input_dir = Path(cfg[\"folder_name\"]).absolute()\n    output_dir = Path(f\"{cfg['folder_name']}_output\").absolute()\n    output_dir.mkdir(parents=True, exist_ok=True)\n\nstatus(f\"Input: {input_dir}\")\nstatus(f\"Output: {output_dir}\")\nWHISPERJAV_OUTPUT_DIR = output_dir # Export for Step 4\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# EXECUTION LOGIC\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nmedia_files = sorted([p for p in input_dir.rglob(\"*\") if p.suffix.lower() in {\".mp4\", \".mkv\", \".avi\",\".mov\",\".wmv\",\".flv\",\".webm\",\".m3v\",\".mp3\",\".wav\",\".flac\"}])\nif not media_files:\n    raise RuntimeError(f\"No media files found in {input_dir}\")\n\nlogs_dir = output_dir / \"logs\"\nlogs_dir.mkdir(parents=True, exist_ok=True)\nfinal_outputs = []\n\ndef build_cmd(video_path, out_path, pass_cfg_num=None):\n    \"\"\"Builds the CLI command. If pass_cfg_num is set, builds a single-pass command (for parallel).\"\"\"\n    # Use venv binary for Colab, sys.executable for Kaggle/local\n    if cfg.get('whisperjav_cmd'):\n        cmd = [cfg['whisperjav_cmd'], str(video_path), \"--output-dir\", str(out_path)]\n    else:\n        cmd = [sys.executable, \"-m\", \"whisperjav.main\", str(video_path), \"--output-dir\", str(out_path)]\n    cmd += [\"--subs-language\", \"direct-to-english\" if cfg[\"subtitle_language\"] == \"direct-to-english\" else \"native\"]\n    if cfg.get(\"language\"): cmd += [\"--language\", cfg[\"language\"]]\n    \n    # Helper to clean args\n    def add_arg(name, val):\n        if val and val != \"none\": cmd.extend([name, str(val)])\n\n    if pass_cfg_num:\n        # Single Pass Mode (Parallel Worker)\n        p = f\"pass{pass_cfg_num}\"\n        cmd += [\"--mode\", cfg[f\"{p}_pipeline\"], \"--sensitivity\", cfg[f\"{p}_sensitivity\"]]\n        add_arg(\"--model\", cfg.get(f\"{p}_model\"))\n        add_arg(\"--speech-segmenter\", cfg.get(f\"{p}_speech_segmenter\"))\n        # Single pass expert args (enhancers/scene) would be mapped here if supported by main CLI in single mode\n    else:\n        # Ensemble Mode (Sequential/Full)\n        cmd += [\"--ensemble\", \"--merge-strategy\", cfg[\"merge_strategy\"]]\n        for p in [\"pass1\", \"pass2\"]:\n            cmd += [f\"--{p}-pipeline\", cfg[f\"{p}_pipeline\"], f\"--{p}-sensitivity\", cfg[f\"{p}_sensitivity\"]]\n            add_arg(f\"--{p}-model\", cfg.get(f\"{p}_model\"))\n            add_arg(f\"--{p}-speech-segmenter\", cfg.get(f\"{p}_speech_segmenter\"))\n            # Expert\n            add_arg(f\"--{p}-scene-detector\", expert.get(f\"{p}_scene_detector\"))\n            enh = expert.get(f\"{p}_speech_enhancer\")\n            if enh == \"ffmpeg-dsp\": enh = f\"ffmpeg-dsp:{expert.get(f'{p}_ffmpeg_filters', 'amplify')}\"\n            add_arg(f\"--{p}-speech-enhancer\", enh)\n            \n    return cmd\n\nstart_time = time.time()\nprint(f\"\\nProcessing {len(media_files)} files...\")\n\nif PARALLEL_MODE:\n    # 2-GPU Parallel Execution: Split Passes, Then Merge\n    from whisperjav.ensemble.merge import MergeEngine\n    merger = MergeEngine()\n    \n    for vid in media_files:\n        print(f\"\\n[Parallel] Processing: {vid.name}\")\n        base = output_dir / vid.stem\n        p1_dir, p2_dir = base / \"pass1\", base / \"pass2\"\n        p1_dir.mkdir(parents=True, exist_ok=True)\n        p2_dir.mkdir(parents=True, exist_ok=True)\n\n        log1 = logs_dir / f\"{vid.stem}_pass1.log\"\n        log2 = logs_dir / f\"{vid.stem}_pass2.log\"\n\n        def run_pass(num, gpu, out, log_file):\n            env = os.environ.copy()\n            env[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n            with log_file.open(\"w\") as f:\n                c = build_cmd(vid, out, pass_cfg_num=num)\n                r = subprocess.run(c, env=env, stdout=f, stderr=subprocess.STDOUT, text=True)\n            return r.returncode == 0, list(out.glob(\"*.srt\"))[0] if list(out.glob(\"*.srt\")) else None\n\n        with ThreadPoolExecutor(max_workers=2) as exc:\n            f1 = exc.submit(run_pass, 1, 0, p1_dir, log1)\n            f2 = exc.submit(run_pass, 2, 1, p2_dir, log2)\n            \n            # Monitoring Loop\n            while not (f1.done() and f2.done()):\n                time.sleep(8)\n                check_progress([(log1, \"GPU 0 (Pass 1)\"), (log2, \"GPU 1 (Pass 2)\")])\n            \n            ok1, srt1 = f1.result()\n            ok2, srt2 = f2.result()\n\n        if ok1 and srt1 and ok2 and srt2:\n            merged = output_dir / srt1.name\n            merger.merge(srt1, srt2, merged, strategy=cfg[\"merge_strategy\"])\n            status(f\"Merged: {merged.name}\")\n            final_outputs.append(merged)\n        elif (ok1 and srt1) or (ok2 and srt2):\n            winner = srt1 if (ok1 and srt1) else srt2\n            dest = output_dir / winner.name\n            shutil.copy(winner, dest)\n            status(f\"Partial Success (One pass failed): {dest.name}\")\n            final_outputs.append(dest)\n        else:\n            status(f\"Failed: {vid.name}\", False)\n\nelse:\n    # Sequential Execution (Colab/Single-GPU)\n    # Uses Popen to allow monitoring loop\n    cmd = build_cmd(input_dir, output_dir)\n    log_path = logs_dir / \"whisperjav_exec.log\"\n    print(\"Running sequential ensemble...\")\n    \n    with log_path.open(\"w\") as f:\n        process = subprocess.Popen(cmd, stdout=f, stderr=subprocess.STDOUT)\n        \n        while process.poll() is None:\n            time.sleep(8)\n            check_progress([(log_path, \"Sequential\")])\n            \n    if process.returncode == 0:\n        new_srts = list(output_dir.glob(\"*.srt\"))\n        if new_srts:\n            status(f\"Processed {len(new_srts)} files\")\n            final_outputs = new_srts\n        else:\n            status(\"No SRTs generated. Check logs.\", False)\n    else:\n        status(\"Execution failed. See logs.\", False)\n\nWHISPERJAV_NEW_SRTS = final_outputs\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PACKAGING\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nif final_outputs:\n    zip_path = output_dir / f\"{cfg['folder_name']}_results.zip\"\n    import zipfile\n    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n        for f in output_dir.rglob(\"*\"):\n            if f.suffix in {\".srt\", \".json\", \".log\"}:\n                zf.write(f, f.relative_to(output_dir))\n    \n    print(f\"\\nğŸ“¦ Bundle created: {zip_path.name}\")\n    if PLATFORM == \"kaggle\":\n        display(FileLink(str(zip_path.relative_to(Path.cwd())), result_html_prefix=\"<b>â¬‡ Download Results: </b>\"))\n    elif PLATFORM == \"colab\":\n        try:\n            from google.colab import files\n            files.download(str(zip_path))\n        except: pass\n\nprint(f\"\\nTime: {(time.time()-start_time)/60:.1f} min\")\nprint(\"Done. Run Step 4 for Translation if needed.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": "#@title Step 4: AI Translation (Optional) { display-mode: \"form\" }\n#@markdown ## ğŸ¤– Provider Settings\ntranslation_provider = \"local\" #@param [\"local\", \"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\", \"glm\", \"groq\"]\nlocal_model = \"gemma-9b\" #@param [\"gemma-9b\", \"llama-8b\", \"llama-3b\", \"auto\"]\n#@markdown <font size=\"1\">local: Free, runs on GPU. gemma-9b (8GB+ VRAM), llama-8b (6GB+), llama-3b (3GB+). Cloud providers require API key.</font>\napi_key = \"\" #@param {type:\"string\"}\nmodel_override = \"\" #@param {type:\"string\"}\n\n#@markdown ## ğŸ¯ Translation Settings\ntarget_language = \"english\" #@param [\"english\", \"chinese\", \"spanish\", \"indonesian\"]\nsource_language = \"japanese\" #@param [\"japanese\", \"korean\", \"chinese\"]\ntone = \"pornify\" #@param [\"standard\", \"pornify\"]\n\n#@markdown ## ğŸ¬ Context (Optional)\n#@markdown *Leave blank for batch processing of different movies.*\nmovie_title = \"\" #@param {type:\"string\"}\nactress = \"\" #@param {type:\"string\"}\nmovie_plot = \"\" #@param {type:\"string\"}\n\n#@markdown ## âš™ï¸ Advanced\nscene_threshold = 60 #@param {type:\"integer\"}\nbatch_size = 30 #@param {type:\"integer\"}\n\nimport os\nimport sys\nimport subprocess\nimport time\nfrom pathlib import Path\nfrom IPython.display import HTML, display, FileLink\n\ndef status(msg, ok=True):\n    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 1. INPUT VALIDATION & DISCOVERY\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# Get config from Step 1 for venv paths\ncfg = globals().get(\"WHISPERJAV_CONFIG\", {})\n\n# Reconstruct Output Dir if missing (Support for Session Restart/CPU Mode)\nif \"WHISPERJAV_OUTPUT_DIR\" not in globals():\n    if cfg:\n        fname = cfg[\"folder_name\"]\n        if \"google.colab\" in sys.modules:\n            from google.colab import drive\n            drive.mount(\"/content/drive\", force_remount=False)\n            WHISPERJAV_OUTPUT_DIR = Path(f\"/content/drive/MyDrive/{fname}\")\n        elif os.path.exists(\"/kaggle\"):\n            # Note: Kaggle non-persistent unless same session\n            WHISPERJAV_OUTPUT_DIR = Path(f\"/kaggle/working/{fname}\")\n        else:\n            WHISPERJAV_OUTPUT_DIR = Path(f\"{fname}_output\").absolute()\n    else:\n        # Fallback for manual run without Step 1\n        WHISPERJAV_OUTPUT_DIR = Path(\".\").resolve()\n\n# Recover SRTS\ntargets = []\nif \"WHISPERJAV_NEW_SRTS\" in globals() and WHISPERJAV_NEW_SRTS:\n    targets = WHISPERJAV_NEW_SRTS\nelif WHISPERJAV_OUTPUT_DIR.exists():\n    print(f\"Scanning for SRTs in: {WHISPERJAV_OUTPUT_DIR}\")\n    # Find all source SRTs (excluding existing translations)\n    candidates = sorted(list(WHISPERJAV_OUTPUT_DIR.glob(\"*.srt\")))\n    targets = [t for t in candidates if not t.name.endswith(f\".{target_language}.srt\")]\n\nif not targets:\n    display(HTML('<div style=\"background:#fee2e2;padding:10px;border-radius:4px;\"><b>âš ï¸ No Subtitles Found</b><br>Run Step 3, or ensure Output directory has SRTs.</div>'))\n    raise RuntimeError(\"No inputs\")\n\n# Check Metadata safety\nif len(targets) > 1 and (movie_title or actress or movie_plot):\n    display(HTML(f'<div style=\"background:#fff7ed;padding:10px;border-radius:4px;border:1px solid #fdba74\"><b>âš ï¸ Metadata Warning</b><br>'\n                 f'You are applying the same Movie Title/Plot/Actress to <b>{len(targets)} different files</b>.<br>'\n                 f'If these are different movies, please clear the Context fields above.</div>'))\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 2. CREDENTIALS\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nis_local = translation_provider == 'local'\nfinal_key = api_key\n\nif not is_local:\n    if not final_key:\n        # Try Step 1 Config (if matches provider)\n        if cfg.get(\"api_key\") and cfg.get(\"translation_service\") == translation_provider:\n            final_key = cfg[\"api_key\"]\n        # Try Kaggle Secrets\n        elif os.path.exists(\"/kaggle\"):\n            from kaggle_secrets import UserSecretsClient\n            try:\n                final_key = UserSecretsClient().get_secret(f\"{translation_provider.upper()}_API_KEY\")\n            except: pass\n\n    if not final_key:\n        raise RuntimeError(f\"Missing API Key for {translation_provider}. Enter it in the form or use 'local' provider for free GPU translation.\")\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 3. INTERACTIVE CONFIRMATION\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nprint(f\"Ready to translate {len(targets)} files.\")\nif is_local:\n    print(f\"Provider: local ({local_model})\")\n    print(\"Note: First run downloads model (~5GB) and llama-cpp-python (~700MB)\")\nelse:\n    print(f\"Provider: {translation_provider}\")\nprint(f\"Target: {target_language} | Tone: {tone}\")\nif model_override:\n    print(f\"Model: {model_override}\")\n\nif not os.path.exists(\"/kaggle\"): # Kaggle batch mode cannot accept input\n    try:\n        input(\"\\nPress [Enter] to start translation (or Stop cell to cancel)...\")\n    except (EOFError, KeyboardInterrupt):\n        print(\"Cancelled by user.\")\n        sys.exit(0)\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 4. EXECUTION\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nprint(f\"\\nğŸš€ Starting Translation Service...\")\ntranslated_files = []\nstart_time = time.time()\n\n# Determine which command to use: venv binary for Colab, sys.executable for Kaggle/local\ntranslate_cmd = cfg.get('whisperjav_translate_cmd')\n\nfor srt in targets:\n    print(f\"\\nProcessing: {srt.name}\")\n    \n    # Use venv binary for Colab, sys.executable for Kaggle/local\n    if translate_cmd:\n        cmd = [translate_cmd]\n    else:\n        cmd = [sys.executable, \"-m\", \"whisperjav.translate.cli\"]\n    \n    cmd.extend([\n        \"-i\", str(srt),\n        \"--provider\", translation_provider,\n        \"--source\", source_language,\n        \"--target\", target_language,\n        \"--tone\", tone,\n        \"--scene-threshold\", str(scene_threshold),\n        \"--max-batch-size\", str(batch_size),\n        \"--stream\" # Stream progress to stderr\n    ])\n    \n    # Add API key for cloud providers\n    if not is_local:\n        cmd.extend([\"--api-key\", final_key])\n    \n    # Model selection\n    if is_local:\n        cmd.extend([\"--model\", local_model])\n    elif model_override:\n        cmd.extend([\"--model\", model_override])\n    \n    # Optional Args\n    if movie_title: cmd.extend([\"--movie-title\", movie_title])\n    if actress: cmd.extend([\"--actress\", actress])\n    if movie_plot: cmd.extend([\"--movie-plot\", movie_plot])\n    \n    # Run with real-time streaming\n    try:\n        process = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            bufsize=1, # Line buffered\n            encoding='utf-8',\n            errors='replace' # Prevent decoding errors\n        )\n        \n        # Read stderr (progress) and stdout (result path)\n        output_path = None\n        while True:\n            # Check stderr for progress updates\n            err_line = process.stderr.readline()\n            if err_line:\n                print(err_line.strip(), file=sys.stderr) # Print to notebook stderr\n            \n            # Check stdout for final filename\n            out_line = process.stdout.readline()\n            if out_line:\n                line = out_line.strip()\n                if line and line.endswith('.srt'):\n                    output_path = line\n                # Also print purely informational stdout\n                print(line)\n\n            # Break safely\n            if not err_line and not out_line and process.poll() is not None:\n                break\n                \n        if process.returncode == 0 and output_path:\n            out_file = Path(output_path)\n            if out_file.exists():\n                status(f\"Completed: {out_file.name}\")\n                translated_files.append(out_file)\n            else:\n                 status(f\"Error: Output file not found: {output_path}\", False)\n        else:\n            status(\"Translation failed (check logs above)\", False)\n\n    except Exception as e:\n        status(f\"Exception: {e}\", False)\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 5. PACKAGING & DOWNLOAD\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nif translated_files:\n    # Use output dir from Step 3 if available, else srt parent\n    base_out = WHISPERJAV_OUTPUT_DIR if \"WHISPERJAV_OUTPUT_DIR\" in globals() else translated_files[0].parent\n    zip_path = base_out / f\"translated_{translation_provider}_{int(time.time())}.zip\"\n    \n    import zipfile\n    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n        for t in translated_files:\n            zf.write(t, t.name)\n            \n    print(f\"\\nğŸ“¦ Translations Bundle: {zip_path.name}\")\n    \n    if os.path.exists(\"/kaggle\"):\n         display(FileLink(str(zip_path.relative_to(Path.cwd())), result_html_prefix=\"<b>â¬‡ Download Translations: </b>\"))\n    elif \"google.colab\" in sys.modules:\n        try:\n            from google.colab import files\n            files.download(str(zip_path))\n        except: pass\nelse:\n    print(\"\\nNo translations produced.\")\n\nprint(f\"\\nTotal Time: {(time.time() - start_time)/60:.1f} min\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4x2",
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}