{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>\n",
    "\n",
    "# WhisperJAV Two-Pass Edition (Universal) v1.7.5\n",
    "\n",
    "**Adaptive GPU Processing** - Automatically optimizes for Colab & Kaggle.\n",
    "\n",
    "| Platform | Logic | Storage |\n",
    "|----------|-------|---------|\n",
    "| **Kaggle** | **Parallel** (2x T4) | **Input**: `/kaggle/input` (Dataset) <br> **Output**: `/kaggle/working` (Artifacts) |\n",
    "| **Colab** | **Sequential** (1x GPU) | **Input/Output**: Google Drive |\n",
    "\n",
    "| Option | What it controls |\n",
    "|--------|------------------|\n",
    "| **Scene Detection** | How to split audio into chunks (auditok, silero, semantic) |\n",
    "| **Speech Segmenter** | How to detect speech in audio (silero, ten) |\n",
    "| **Speech Enhancer** | Audio cleanup for noisy sources (ffmpeg-dsp, clearvoice, etc.) |\n",
    "| **Model** | Which AI model to use (large-v2, large-v3, turbo, kotoba) |\n",
    "\n",
    "---\n",
    "<div style=\"font-size: 11px; line-height: 1.4;\">\n",
    "1. <b>Setup Files:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;â€¢ <b>Colab:</b> Upload videos to <code>Google Drive/WhisperJAV/</code><br>\n",
    "&nbsp;&nbsp;&nbsp;â€¢ <b>Kaggle:</b> Add your videos as a Dataset (recommended) or upload to Input.<br>\n",
    "2. Run <b>Step 1: Expert Configuration</b> (required)<br>\n",
    "3. Run <b>Step 2: Two-Pass Transcribe</b> (auto-detects platform)<br>\n",
    "4. Run <b>Step 3: AI Translation</b> (supports Kaggle Secrets/Env/Keys)\n",
    "</div>\n",
    "\n",
    "<small>The notebook will automatically disconnect (Colab) or finish session (Kaggle) when done.</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 1: Expert Configuration { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ## ğŸ“ Files & Output\n",
    "folder_name = \"WhisperJAV\" #@param {type:\"string\"}\n",
    "subtitle_language = \"Japanese\" #@param [\"Japanese\", \"English (auto-translate)\", \"English (AI translate)\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 1ï¸âƒ£ Pass 1 Configuration (GPU 0)\n",
    "pass1_quality = \"balanced\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass1_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass1_model = \"automatic\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 1)**\n",
    "pass1_scene_detector = \"automatic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass1_speech_segmenter = \"automatic\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass1_speech_enhancer = \"none\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "#@markdown <font size=\"1\">auditok=energy (fast), silero=VAD, semantic=texture (complex audio) | enhancer: ffmpeg-dsp(no GPU), clearvoice(48k), bs-roformer(vocal)</font>\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 1)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass1_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 2ï¸âƒ£ Pass 2 Configuration (GPU 1)\n",
    "pass2_quality = \"transformers\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass2_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass2_model = \"kotoba-bilingual\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 2)**\n",
    "pass2_scene_detector = \"automatic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass2_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass2_speech_enhancer = \"none\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 2)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass2_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ”— Merge Strategy\n",
    "merge_method = \"prefer first pass\" #@param [\"automatic\", \"keep all\", \"prefer first pass\", \"prefer second pass\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ¤– AI Translation *(if selected)*\n",
    "translation_service = \"deepseek\" #@param [\"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\"]\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "translation_style = \"standard\" #@param [\"standard\", \"explicit\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## âš™ï¸ Session\n",
    "opening_credit = \"\" #@param {type:\"string\"}\n",
    "closing_credit = \"Subs by WhisperJAV\" #@param {type:\"string\"}\n",
    "auto_disconnect = True #@param {type:\"boolean\"}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION LOGIC\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Mapping dictionaries\n",
    "combine_map = {\"automatic\": \"smart_merge\", \"keep all\": \"full_merge\",\n",
    "               \"prefer first pass\": \"pass1_primary\", \"prefer second pass\": \"pass2_primary\"}\n",
    "language_map = {\"Japanese\": \"native\", \"English (auto-translate)\": \"direct-to-english\",\n",
    "                \"English (AI translate)\": \"llm\"}\n",
    "tone_map = {\"standard\": \"standard\", \"explicit\": \"pornify\"}\n",
    "\n",
    "# Model mapping (None = use pipeline default)\n",
    "model_map = {\n",
    "    \"automatic\": None,\n",
    "    \"large-v2\": \"large-v2\",\n",
    "    \"large-v3\": \"large-v3\",\n",
    "    \"turbo\": \"large-v3-turbo\",\n",
    "    \"kotoba-bilingual\": \"kotoba-tech/kotoba-whisper-bilingual-v1.0\",\n",
    "    \"kotoba-v2.0\": \"kotoba-tech/kotoba-whisper-v2.0\",\n",
    "    \"kotoba-v2.1\": \"kotoba-tech/kotoba-whisper-v2.1\",\n",
    "    \"kotoba-v2.2\": \"kotoba-tech/kotoba-whisper-v2.2\"\n",
    "}\n",
    "\n",
    "# Define model compatibility:\n",
    "KOTOBA_MODELS = {\"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"}\n",
    "LEGACY_PIPELINES = {\"faster\", \"fast\", \"balanced\", \"fidelity\"}\n",
    "\n",
    "# Auto-correct incompatible model-pipeline combinations\n",
    "warnings_list = []\n",
    "\n",
    "# Check Pass 1 compatibility\n",
    "if pass1_model in KOTOBA_MODELS and pass1_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 1: {pass1_model} requires 'transformers' pipeline. Auto-correcting from '{pass1_quality}' to 'transformers'.\")\n",
    "    pass1_quality = \"transformers\"\n",
    "\n",
    "# Check Pass 2 compatibility\n",
    "if pass2_model in KOTOBA_MODELS and pass2_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 2: {pass2_model} requires 'transformers' pipeline. Auto-correcting from '{pass2_quality}' to 'transformers'.\")\n",
    "    pass2_quality = \"transformers\"\n",
    "\n",
    "# Memory warning\n",
    "heavy_enhancers = {'clearvoice', 'bs-roformer', 'zipenhancer'}\n",
    "if pass1_speech_enhancer in heavy_enhancers and pass2_speech_enhancer in heavy_enhancers:\n",
    "    warnings_list.append(\"Using GPU-based enhancement on both passes may cause OOM on T4 GPU (Sequential Mode). Suggest using ffmpeg-dsp for one pass.\")\n",
    "\n",
    "# Helpers\n",
    "def build_ffmpeg_filters(amplify, loudnorm, compress, highpass):\n",
    "    \"\"\"Combine selected FFmpeg filters into comma-separated string.\"\"\"\n",
    "    filters = []\n",
    "    if amplify: filters.append(\"amplify\")\n",
    "    if loudnorm: filters.append(\"loudnorm\")\n",
    "    if compress: filters.append(\"compress\")\n",
    "    if highpass: filters.append(\"highpass\")\n",
    "    return \",\".join(filters) if filters else None\n",
    "\n",
    "def map_value(val):\n",
    "    return None if val == \"automatic\" else val\n",
    "\n",
    "def map_segmenter(val):\n",
    "    return \"none\" if val == \"none\" else map_value(val)\n",
    "\n",
    "# Unified Config Construction\n",
    "WHISPERJAV_CONFIG = {\n",
    "    'pass1_pipeline': pass1_quality,\n",
    "    'pass1_sensitivity': pass1_sensitivity,\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter),\n",
    "    'pass1_model': model_map[pass1_model],\n",
    "    'pass2_pipeline': pass2_quality,\n",
    "    'pass2_sensitivity': pass2_sensitivity,\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter),\n",
    "    'pass2_model': model_map[pass2_model],\n",
    "    'merge_strategy': combine_map[merge_method],\n",
    "    'folder_name': folder_name,\n",
    "    'subtitle_language': language_map[subtitle_language],\n",
    "    'translation_service': translation_service,\n",
    "    'api_key': api_key,\n",
    "    'translation_style': tone_map[translation_style],\n",
    "    'opening_credit': opening_credit,\n",
    "    'closing_credit': closing_credit,\n",
    "    'auto_disconnect': auto_disconnect,\n",
    "    # Compatibility checks for Step 2\n",
    "    '_pass1_quality': pass1_quality,\n",
    "    '_pass1_sensitivity': pass1_sensitivity,\n",
    "    '_pass1_speech_segmenter': pass1_speech_segmenter,\n",
    "    '_pass1_model': pass1_model,\n",
    "    '_pass2_quality': pass2_quality,\n",
    "    '_pass2_sensitivity': pass2_sensitivity,\n",
    "    '_pass2_speech_segmenter': pass2_speech_segmenter,\n",
    "    '_pass2_model': pass2_model,\n",
    "    '_merge_method': merge_method,\n",
    "    '_subtitle_language': subtitle_language,\n",
    "    '_translation_style': translation_style,\n",
    "}\n",
    "\n",
    "WHISPERJAV_EXPERT_CONFIG = {\n",
    "    # Pass 1 Expert\n",
    "    'pass1_scene_detector': map_value(pass1_scene_detector),\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter), # Now unified\n",
    "    'pass1_speech_enhancer': None if pass1_speech_enhancer == \"none\" else pass1_speech_enhancer,\n",
    "    'pass1_ffmpeg_filters': build_ffmpeg_filters(pass1_ffmpeg_amplify, pass1_ffmpeg_loudnorm, pass1_ffmpeg_compress, pass1_ffmpeg_highpass) if pass1_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    # Pass 2 Expert\n",
    "    'pass2_scene_detector': map_value(pass2_scene_detector),\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter), # Now unified\n",
    "    'pass2_speech_enhancer': None if pass2_speech_enhancer == \"none\" else pass2_speech_enhancer,\n",
    "    'pass2_ffmpeg_filters': build_ffmpeg_filters(pass2_ffmpeg_amplify, pass2_ffmpeg_loudnorm, pass2_ffmpeg_compress, pass2_ffmpeg_highpass) if pass2_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    # Display helpers\n",
    "    '_pass1_scene_detector': pass1_scene_detector,\n",
    "    '_pass1_speech_enhancer': pass1_speech_enhancer,\n",
    "    '_pass2_scene_detector': pass2_scene_detector,\n",
    "    '_pass2_speech_enhancer': pass2_speech_enhancer,\n",
    "}\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display warnings\n",
    "for warning in warnings_list:\n",
    "    display(HTML(f'<div style=\"padding:6px 10px;background:#fef9c3;border-radius:4px;font-size:10px;margin-bottom:4px\"><b>âš ï¸ Auto-corrected:</b> {warning}</div>'))\n",
    "\n",
    "# Build status display\n",
    "p1_info = f\"{pass1_quality}\"\n",
    "if pass1_speech_segmenter != \"automatic\":\n",
    "    p1_info += f\"/{pass1_speech_segmenter}\"\n",
    "if pass1_model != \"automatic\":\n",
    "    p1_info += f\"/{pass1_model}\"\n",
    "\n",
    "p2_info = f\"{pass2_quality}\"\n",
    "if pass2_speech_segmenter != \"automatic\":\n",
    "    p2_info += f\"/{pass2_speech_segmenter}\"\n",
    "if pass2_model != \"automatic\":\n",
    "    p2_info += f\"/{pass2_model}\"\n",
    "\n",
    "display(HTML(f'<div style=\"padding:10px;background:#e0f2fe;border-radius:4px;font-size:11px\">'\n",
    "             f'<b>Parallel Configuration Loaded</b><br>'\n",
    "             f'Pass 1: {p1_info} | Pass 2: {p2_info}<br>'\n",
    "             f'Merge: {merge_method} | Folder: {folder_name}'\n",
    "             f'</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 2: Two-Pass Transcribe { display-mode: \"form\" }\n",
    "#@markdown Connect Drive (Colab) or Setup Paths (Kaggle) â†’ Install â†’ Run passes â†’ Merge results\n",
    "\n",
    "import os, sys, subprocess, shlex, time, re, shutil\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    icon = \"âœ“\" if ok else \"âœ—\"\n",
    "    print(f\"{icon} {msg}\")\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'â”€'*50}\\n{title}\\n{'â”€'*50}\")\n",
    "\n",
    "# Check config\n",
    "if 'WHISPERJAV_CONFIG' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 1 first</div>'))\n",
    "    raise SystemExit()\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "\n",
    "# Check for expert config (always present now)\n",
    "expert = WHISPERJAV_EXPERT_CONFIG if 'WHISPERJAV_EXPERT_CONFIG' in dir() else None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PLATFORM DETECTION & FILE SYSTEM SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"DETECTING PLATFORM & PATHS\")\n",
    "\n",
    "def detect_platform():\n",
    "    if 'google.colab' in sys.modules:\n",
    "        return 'colab'\n",
    "    elif os.path.exists('/kaggle'):\n",
    "        return 'kaggle'\n",
    "    else:\n",
    "        return 'local'\n",
    "\n",
    "PLATFORM = detect_platform()\n",
    "print(f\"Platform: {PLATFORM.upper()}\")\n",
    "\n",
    "if PLATFORM == 'colab':\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        base_dir = Path(f\"/content/drive/MyDrive\")\n",
    "        input_dir = base_dir / cfg['folder_name']\n",
    "        output_dir = input_dir # Colab writes back to same folder\n",
    "        input_dir.mkdir(parents=True, exist_ok=True)\n",
    "        status(f\"Drive Connected: {input_dir}\")\n",
    "    except Exception as e:\n",
    "        status(f\"Failed to connect Drive: {e}\", False)\n",
    "        raise SystemExit()\n",
    "\n",
    "elif PLATFORM == 'kaggle':\n",
    "    # Kaggle: Read-only Input, specific Output\n",
    "    # Search for input dataset matching folder_name or standard locations\n",
    "    potential_inputs = [\n",
    "        Path(f\"/kaggle/input/{cfg['folder_name']}\"), # Named dataset\n",
    "        Path(f\"/kaggle/input/whisperjav-media\"),    # Common dataset name\n",
    "        Path(f\"/kaggle/input\"),                     # Root input\n",
    "        Path(f\"/kaggle/working/input\")              # Manual upload location\n",
    "    ]\n",
    "    \n",
    "    input_dir = None\n",
    "    for p in potential_inputs:\n",
    "        if p.exists() and any(f for f in p.rglob('*') if f.suffix.lower() in {'.mp4', '.mkv', '.avi', '.mp3', '.wav', '.flac'}):\n",
    "            input_dir = p\n",
    "            break\n",
    "            \n",
    "    if not input_dir:\n",
    "        input_dir = Path(f\"/kaggle/input\")\n",
    "        print(\"  âš  Could not auto-detect specific input folder. Scanning /kaggle/input root.\")\n",
    "\n",
    "    output_dir = Path(f\"/kaggle/working/{cfg['folder_name']}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # KAGGLE FIX 1: Fix Temp Storage Overflow\n",
    "    # Redirect all temp files to writable working dir to avoid /tmp (ramdisk) filling up\n",
    "    kaggle_temp = Path(f\"/kaggle/working/temp\")\n",
    "    kaggle_temp.mkdir(parents=True, exist_ok=True)\n",
    "    os.environ['TMPDIR'] = str(kaggle_temp)\n",
    "    os.environ['TEMP'] = str(kaggle_temp)\n",
    "    os.environ['TMP'] = str(kaggle_temp)\n",
    "    print(f\"  ğŸ”§ Redirected temp storage to {kaggle_temp}\")\n",
    "\n",
    "    status(f\"Input: {input_dir}\")\n",
    "    status(f\"Output: {output_dir}\")\n",
    "\n",
    "else:\n",
    "    # Local fallback\n",
    "    input_dir = Path(cfg['folder_name'])\n",
    "    output_dir = Path(f\"{cfg['folder_name']}_output\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    status(f\"Local Mode: {input_dir} â†’ {output_dir}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CHECK GPUs AND DETERMINE MODE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"GPU RESOURCE CHECK\")\n",
    "gpu_check = subprocess.run(\"nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\", shell=True, capture_output=True, text=True)\n",
    "if gpu_check.returncode != 0 or not gpu_check.stdout.strip():\n",
    "    status(\"No GPU detected. Switch runtime to GPU (T4 x2 or L4/A100).\", False)\n",
    "    # Don't exit, might be testing installation\n",
    "else:\n",
    "    gpu_lines = [line.strip() for line in gpu_check.stdout.strip().split('\\n') if line.strip()]\n",
    "    num_gpus = len(gpu_lines)\n",
    "\n",
    "    for i, gpu_info in enumerate(gpu_lines):\n",
    "        status(f\"GPU {i}: {gpu_info}\")\n",
    "\n",
    "    # Adaptive mode selection\n",
    "    if num_gpus >= 2:\n",
    "        PARALLEL_MODE = True\n",
    "        gpu_assignment = {1: \"0\", 2: \"1\"}\n",
    "        print(f\"\\n  âš¡ Parallel Mode: Pass 1 (GPU 0) | Pass 2 (GPU 1)\")\n",
    "    else:\n",
    "        PARALLEL_MODE = False\n",
    "        gpu_assignment = {1: \"0\", 2: \"0\"}\n",
    "        print(f\"\\n  ğŸ“ Sequential Mode: Pass 1 â†’ Pass 2 (Single GPU)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INSTALL WHISPERJAV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"INSTALLING (2-3 min)\")\n",
    "install_start = time.time()\n",
    "\n",
    "# Platform specific prereqs\n",
    "if PLATFORM == 'colab':\n",
    "    pre_cmds = \"apt-get update -qq && apt-get install -y -qq ffmpeg portaudio19-dev libc++1 libc++abi1 > /dev/null 2>&1\"\n",
    "else:\n",
    "    # Kaggle usually has ffmpeg, but good to ensure\n",
    "    pre_cmds = \"apt-get update -qq && apt-get install -y -qq ffmpeg portaudio19-dev > /dev/null 2>&1\"\n",
    "\n",
    "# ARCHITECTURE NOTE:\n",
    "# WhisperJAV requires NumPy>=2.0. Standard Kaggle/Colab environments use NumPy 1.x.\n",
    "# To satisfy the requirement without breaking the ecosystem (matplotlib/torch ABI mismatches),\n",
    "# we must perform a synchronized upgrade of the core stack (numpy, matplotlib, torch).\n",
    "# We rely on 'configure_cuda_runtime_paths()' (below) to fix any CUDA version mismatches \n",
    "# caused by replacing the system PyTorch.\n",
    "\n",
    "req_packages = [\n",
    "    # Core Audio/Video\n",
    "    \"ffmpeg-python\", \"auditok\", \"pysrt\", \"srt\", \"aiofiles\", \"pyloudnorm\", \"pydub\",\n",
    "    # AI/ML Stack (Synchronized Upgrade)\n",
    "    \"numpy\", \"matplotlib\", \"scipy\", \"torch\", \"torchaudio\", \"torchvision\",\n",
    "    \"faster-whisper\", \"transformers\", \"optimum\", \"accelerate\", \"huggingface-hub\", \n",
    "    \"pydantic\", \"ten-vad\", \"silero-vad\", \"modelscope\", \"addict\", \"tiktoken\"\n",
    "]\n",
    "req_str = \" \".join(req_packages)\n",
    "\n",
    "steps = [\n",
    "    (pre_cmds, \"System tools\"),\n",
    "    # Install dependencies allowing upgrades to ensure consistency (Numpy 2.0 compatible stack)\n",
    "    (f\"pip install -q {req_str}\", \"Python packages (Core Stack)\"),\n",
    "    (\"pip install -q --no-deps git+https://github.com/openai/whisper.git@main\", \"Whisper\"),\n",
    "    (\"pip install -q --no-deps git+https://github.com/meizhong986/stable-ts-fix-setup.git@main\", \"Stable-TS\"),\n",
    "    (\"pip install -q --no-deps git+https://github.com/meizhong986/WhisperJAV.git@main\", \"WhisperJAV\")\n",
    "]\n",
    "\n",
    "for cmd, name in steps:\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        status(f\"{name} failed\", False)\n",
    "        # On Kaggle, some apt-get might fail but environment is often usable\n",
    "        if PLATFORM != 'kaggle': \n",
    "            raise SystemExit()\n",
    "    else:\n",
    "        status(name)\n",
    "\n",
    "# Conditional installation of speech enhancer dependencies\n",
    "if expert:\n",
    "    extra_packages = set()\n",
    "    for enhancer in [expert.get('pass1_speech_enhancer'), expert.get('pass2_speech_enhancer')]:\n",
    "        if enhancer == 'clearvoice':\n",
    "            extra_packages.add('clearvoice')\n",
    "        elif enhancer == 'zipenhancer':\n",
    "            # zipenhancer uses modelscope which is already installed above\n",
    "            pass\n",
    "        elif enhancer == 'bs-roformer':\n",
    "            extra_packages.add('bs-roformer-infer')\n",
    "    \n",
    "    if extra_packages:\n",
    "        pkg_list = ' '.join(extra_packages)\n",
    "        result = subprocess.run(f\"pip install -q {pkg_list}\", shell=True, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            status(f\"Speech enhancer packages failed (continuing anyway)\", False)\n",
    "        else:\n",
    "            status(f\"Speech enhancer packages ({', '.join(extra_packages)})\")\n",
    "\n",
    "status(f\"Installation complete ({time.time()-install_start:.0f}s)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RUNTIME CONFIGURATION (Fixing CUDA conflicts)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def configure_cuda_runtime_paths():\n",
    "    \"\"\"\n",
    "    Kaggle/Colab Fix: Link pip-installed NVIDIA libraries to LD_LIBRARY_PATH.\n",
    "    This prevents ctranslate2 (faster-whisper) from using incompatible system CUDA 11.8.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import site\n",
    "        nvidia_paths = []\n",
    "        for site_pkg in site.getsitepackages():\n",
    "            nvidia_root = Path(site_pkg) / 'nvidia'\n",
    "            if nvidia_root.exists():\n",
    "                nvidia_paths.extend([str(p / 'lib') for p in nvidia_root.iterdir() if (p / 'lib').exists()])\n",
    "        \n",
    "        if nvidia_paths:\n",
    "            current_ld = os.environ.get('LD_LIBRARY_PATH', '')\n",
    "            new_ld = os.pathsep.join(nvidia_paths + [current_ld] if current_ld else nvidia_paths)\n",
    "            os.environ['LD_LIBRARY_PATH'] = new_ld\n",
    "            print(f\"  ğŸ”§ Runtime: Linked {len(nvidia_paths)} NVIDIA library paths for ctranslate2\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Runtime Warning: {e}\")\n",
    "\n",
    "configure_cuda_runtime_paths()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FIND MEDIA FILES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"SCANNING INPUT FILES\")\n",
    "video_types = {'.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.mp3', '.wav', '.flac', '.m4a'}\n",
    "\n",
    "# Recursive scan for Kaggle datasets structure\n",
    "if PLATFORM == 'kaggle':\n",
    "    videos = []\n",
    "    for f in input_dir.rglob('*'):\n",
    "        if f.suffix.lower() in video_types:\n",
    "            videos.append(f)\n",
    "else:\n",
    "    videos = [f for f in input_dir.iterdir() if f.suffix.lower() in video_types]\n",
    "\n",
    "if not videos:\n",
    "    status(f\"No media files found in {input_dir}\", False)\n",
    "    if PLATFORM == 'kaggle':\n",
    "         print(\"  Hint: Did you add your dataset via '+ Add Data'?\")\n",
    "    raise SystemExit()\n",
    "\n",
    "status(f\"Found {len(videos)} file(s)\")\n",
    "for v in videos[:5]:\n",
    "    print(f\"  â€¢ {v.name}\")\n",
    "if len(videos) > 5:\n",
    "    print(f\"  ... and {len(videos)-5} more\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MERGE FUNCTIONS (from whisperjav/ensemble/merge.py)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@dataclass\n",
    "class Subtitle:\n",
    "    index: int\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    text: str\n",
    "\n",
    "    @property\n",
    "    def duration(self) -> float:\n",
    "        return self.end_time - self.start_time\n",
    "\n",
    "def parse_srt(path: Path) -> List[Subtitle]:\n",
    "    if not path.exists():\n",
    "        return []\n",
    "    subtitles = []\n",
    "    content = path.read_text(encoding='utf-8')\n",
    "    blocks = re.split(r'\\\\n\\\\s*\\\\n', content.strip())\n",
    "    for block in blocks:\n",
    "        if not block.strip():\n",
    "            continue\n",
    "        lines = block.strip().split('\\\\n')\n",
    "        if len(lines) < 3:\n",
    "            continue\n",
    "        try:\n",
    "            index = int(lines[0].strip())\n",
    "            ts_match = re.match(r'(\\\\d{2}):(\\\\d{2}):(\\\\d{2}),(\\\\d{3})\\\\s*-->\\\\s*(\\\\d{2}):(\\\\d{2}):(\\\\d{2}),(\\\\d{3})', lines[1].strip())\n",
    "            if not ts_match:\n",
    "                continue\n",
    "            g = ts_match.groups()\n",
    "            start = int(g[0])*3600 + int(g[1])*60 + int(g[2]) + int(g[3])/1000\n",
    "            end = int(g[4])*3600 + int(g[5])*60 + int(g[6]) + int(g[7])/1000\n",
    "            text = '\\\\n'.join(lines[2:]).strip()\n",
    "            subtitles.append(Subtitle(index, start, end, text))\n",
    "        except:\n",
    "            continue\n",
    "    return subtitles\n",
    "\n",
    "def write_srt(subtitles: List[Subtitle], path: Path):\n",
    "    def ts(seconds):\n",
    "        h, m = int(seconds // 3600), int((seconds % 3600) // 60)\n",
    "        s, ms = int(seconds % 60), int((seconds % 1) * 1000)\n",
    "        return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n",
    "    lines = []\n",
    "    for i, sub in enumerate(subtitles, 1):\n",
    "        lines.extend([str(i), f\"{ts(sub.start_time)} --> {ts(sub.end_time)}\", sub.text, ''])\n",
    "    path.write_text('\\\\n'.join(lines), encoding='utf-8')\n",
    "\n",
    "def merge_srt(srt1: Path, srt2: Path, output: Path, strategy: str) -> Dict[str, Any]:\n",
    "    subs1, subs2 = parse_srt(srt1), parse_srt(srt2)\n",
    "    \n",
    "    if strategy == 'full_merge':\n",
    "        merged = [Subtitle(0, s.start_time, s.end_time, s.text) for s in subs1 + subs2]\n",
    "    elif strategy == 'pass1_primary':\n",
    "        merged = [Subtitle(0, s.start_time, s.end_time, s.text) for s in subs1]\n",
    "        for s2 in subs2:\n",
    "            if not any(max(s1.start_time, s2.start_time) < min(s1.end_time, s2.end_time) for s1 in subs1):\n",
    "                merged.append(Subtitle(0, s2.start_time, s2.end_time, s2.text))\n",
    "    elif strategy == 'pass2_primary':\n",
    "        merged = [Subtitle(0, s.start_time, s.end_time, s.text) for s in subs2]\n",
    "        for s1 in subs1:\n",
    "            if not any(max(s1.start_time, s2.start_time) < min(s1.end_time, s2.end_time) for s2 in subs2):\n",
    "                merged.append(Subtitle(0, s1.start_time, s1.end_time, s1.text))\n",
    "    else:  # smart_merge\n",
    "        merged, used = [], set()\n",
    "        for s1 in subs1:\n",
    "            best_i, best_overlap = None, 0\n",
    "            for i, s2 in enumerate(subs2):\n",
    "                if i in used: continue\n",
    "                overlap = max(0, min(s1.end_time, s2.end_time) - max(s1.start_time, s2.start_time))\n",
    "                if overlap > best_overlap:\n",
    "                    best_overlap, best_i = overlap, i\n",
    "            if best_i is not None and best_overlap > 0.3 * min(s1.duration, subs2[best_i].duration):\n",
    "                used.add(best_i)\n",
    "                chosen = s1 if s1.duration <= subs2[best_i].duration else subs2[best_i]\n",
    "                merged.append(Subtitle(0, chosen.start_time, chosen.end_time, chosen.text))\n",
    "            else:\n",
    "                merged.append(Subtitle(0, s1.start_time, s1.end_time, s1.text))\n",
    "        for i, s2 in enumerate(subs2):\n",
    "            if i not in used:\n",
    "                merged.append(Subtitle(0, s2.start_time, s2.end_time, s2.text))\n",
    "    \n",
    "    merged.sort(key=lambda s: s.start_time)\n",
    "    write_srt(merged, output)\n",
    "    return {'pass1_count': len(subs1), 'pass2_count': len(subs2), 'merged_count': len(merged)}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TWO-PASS TRANSCRIPTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"EXECUTION\")\n",
    "\n",
    "def build_pass_command(pass_num: int, video_path: Path, work_dir: Path, cfg: dict, expert: Optional[dict] = None) -> Tuple[List[str], Path]:\n",
    "    \"\"\"Build whisperjav command for a single pass.\"\"\"\n",
    "    \n",
    "    # Separate directory for each pass to avoid conflicts\n",
    "    # On Kaggle we must write to /kaggle/working (passed as work_dir)\n",
    "    pass_output_dir = work_dir / f\"pass{pass_num}\"\n",
    "    pass_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Use unique local temp directory inside the working directory to ensure space\n",
    "    pass_temp_dir = work_dir / f\"temp_pass{pass_num}\"\n",
    "    pass_temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pipeline = cfg[f'pass{pass_num}_pipeline']\n",
    "    sensitivity = cfg[f'pass{pass_num}_sensitivity']\n",
    "    segmenter = cfg[f'pass{pass_num}_speech_segmenter']\n",
    "    model = cfg[f'pass{pass_num}_model']\n",
    "\n",
    "    cmd = [\n",
    "        'whisperjav', str(video_path),\n",
    "        '--output-dir', str(pass_output_dir),\n",
    "        '--temp-dir', str(pass_temp_dir),\n",
    "        '--ensemble',\n",
    "        '--pass1-pipeline', pipeline,\n",
    "        '--pass1-sensitivity', sensitivity,\n",
    "    ]\n",
    "\n",
    "    if segmenter:\n",
    "        cmd.extend(['--pass1-speech-segmenter', segmenter])\n",
    "\n",
    "    if model:\n",
    "        cmd.extend(['--pass1-model', model])\n",
    "\n",
    "    if expert:\n",
    "        scene_detector = expert.get(f'pass{pass_num}_scene_detector')\n",
    "        if scene_detector:\n",
    "            cmd.extend(['--pass1-scene-detector', scene_detector])\n",
    "        \n",
    "        speech_enhancer = expert.get(f'pass{pass_num}_speech_enhancer')\n",
    "        if speech_enhancer:\n",
    "            if speech_enhancer == 'ffmpeg-dsp':\n",
    "                effects = expert.get(f'pass{pass_num}_ffmpeg_filters')\n",
    "                effects_str = effects if effects else 'loudnorm'\n",
    "                cmd.extend(['--pass1-speech-enhancer', f'ffmpeg-dsp:{effects_str}'])\n",
    "            else:\n",
    "                cmd.extend(['--pass1-speech-enhancer', speech_enhancer])\n",
    "\n",
    "    if cfg['subtitle_language'] == 'direct-to-english':\n",
    "        cmd.extend(['--subs-language', 'direct-to-english'])\n",
    "    else:\n",
    "        cmd.extend(['--subs-language', 'native'])\n",
    "\n",
    "    return cmd, pass_output_dir\n",
    "\n",
    "def find_output_srt(pass_output_dir: Path, video_name: str) -> Path:\n",
    "    \"\"\"Find the generated SRT file.\"\"\"\n",
    "    base_name = Path(video_name).stem\n",
    "    patterns = [\n",
    "        f\"{base_name}.*.whisperjav.srt\",\n",
    "        f\"{base_name}.srt\",\n",
    "        f\"{base_name}*.srt\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = list(pass_output_dir.glob(pattern))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    all_srts = list(pass_output_dir.glob(\"*.srt\"))\n",
    "    return all_srts[0] if all_srts else None\n",
    "\n",
    "def run_pass(pass_num: int, video: Path, work_dir: Path, cfg: dict, expert: Optional[dict], gpu_id: str) -> Dict:\n",
    "    \"\"\"Run a single pass on a specific GPU.\"\"\"\n",
    "    cmd, pass_output_dir = build_pass_command(pass_num, video, work_dir, cfg, expert)\n",
    "\n",
    "    env = os.environ.copy()\n",
    "    env['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Popen usage is safer for capturing complex output but run is fine here\n",
    "    result = subprocess.run(shlex.join(cmd), shell=True, capture_output=True, text=True, env=env)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    actual_output = find_output_srt(pass_output_dir, video.name)\n",
    "\n",
    "    return {\n",
    "        'pass': pass_num,\n",
    "        'video': video.name,\n",
    "        'success': result.returncode == 0 and actual_output and actual_output.exists(),\n",
    "        'output': actual_output,\n",
    "        'output_dir': pass_output_dir,\n",
    "        'elapsed': elapsed,\n",
    "        'gpu': gpu_id,\n",
    "        'stderr': result.stderr[-500:] if result.stderr else ''\n",
    "    }\n",
    "\n",
    "# Info display\n",
    "p1_info = cfg['_pass1_quality']\n",
    "if cfg['_pass1_speech_segmenter'] != 'automatic': p1_info += f\"/{cfg['_pass1_speech_segmenter']}\"\n",
    "p2_info = cfg['_pass2_quality']\n",
    "if cfg['_pass2_speech_segmenter'] != 'automatic': p2_info += f\"/{cfg['_pass2_speech_segmenter']}\"\n",
    "\n",
    "print(f\"Pass 1: {p1_info}\")\n",
    "print(f\"Pass 2: {p2_info}\")\n",
    "print(f\"Merge: {cfg['_merge_method']}\\\\n\")\n",
    "\n",
    "# Process each video\n",
    "all_results = []\n",
    "merged_outputs = []\n",
    "\n",
    "for video_idx, video in enumerate(videos, 1):\n",
    "    print(f\"\\\\n[{video_idx}/{len(videos)}] Processing: {video.name}\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    if PARALLEL_MODE:\n",
    "        with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "            # Important: pass output_dir here, not input_dir/folder_path\n",
    "            futures = {\n",
    "                executor.submit(run_pass, 1, video, output_dir, cfg, expert, gpu_assignment[1]): 1,\n",
    "                executor.submit(run_pass, 2, video, output_dir, cfg, expert, gpu_assignment[2]): 2\n",
    "            }\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                pass_num = futures[future]\n",
    "                result = future.result()\n",
    "                results[pass_num] = result\n",
    "                status_icon = \"âœ“\" if result['success'] else \"âœ—\"\n",
    "                print(f\"    {status_icon} Pass {pass_num} (GPU {result['gpu']}): {result['elapsed']:.1f}s\")\n",
    "                if not result['success'] and result['stderr']:\n",
    "                    print(f\"        Error: {result['stderr'][:200]}\")\n",
    "    else:\n",
    "        for pass_num in [1, 2]:\n",
    "            result = run_pass(pass_num, video, output_dir, cfg, expert, gpu_assignment[pass_num])\n",
    "            results[pass_num] = result\n",
    "            status_icon = \"âœ“\" if result['success'] else \"âœ—\"\n",
    "            print(f\"    {status_icon} Pass {pass_num}: {result['elapsed']:.1f}s\")\n",
    "            if not result['success'] and result['stderr']:\n",
    "                print(f\"        Error: {result['stderr'][:200]}\")\n",
    "\n",
    "    # Merge or copy\n",
    "    if results[1]['success'] and results[2]['success']:\n",
    "        merged_output = output_dir / f\"{video.stem}.merged.whisperjav.srt\"\n",
    "        stats = merge_srt(results[1]['output'], results[2]['output'], merged_output, cfg['merge_strategy'])\n",
    "        print(f\"    âœ“ Merged: {stats['pass1_count']} + {stats['pass2_count']} â†’ {stats['merged_count']} subtitles\")\n",
    "        merged_outputs.append(merged_output)\n",
    "    else:\n",
    "        for p in [1, 2]:\n",
    "            if results[p]['success']:\n",
    "                final_output = output_dir / f\"{video.stem}.whisperjav.srt\"\n",
    "                shutil.copy2(results[p]['output'], final_output)\n",
    "                merged_outputs.append(final_output)\n",
    "                print(f\"    âš  Using Pass {p} only (other pass failed)\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"    âœ— Both passes failed!\")\n",
    "\n",
    "    all_results.append(results)\n",
    "\n",
    "# Store context for Step 3\n",
    "WHISPERJAV_NEW_SRTS = merged_outputs\n",
    "WHISPERJAV_OUTPUT_DIR = output_dir \n",
    "\n",
    "status(f\"\\\\nCreated {len(merged_outputs)} merged subtitle file(s) in {output_dir}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ADD CREDITS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"ADDING CREDITS\")\n",
    "\n",
    "if cfg['opening_credit'] or cfg['closing_credit'] and merged_outputs:\n",
    "    credits_count = 0\n",
    "    for srt_file in merged_outputs:\n",
    "        try:\n",
    "            content = srt_file.read_text(encoding='utf-8')\n",
    "            if cfg['opening_credit']:\n",
    "                content = f\"0\\\\n00:00:00,000 --> 00:00:00,500\\\\n{cfg['opening_credit']}\\\\n\\\\n\" + content\n",
    "            if cfg['closing_credit']:\n",
    "                content += f\"\\\\n9999\\\\n23:59:58,000 --> 23:59:59,000\\\\n{cfg['closing_credit']}\\\\n\"\n",
    "            srt_file.write_text(content, encoding='utf-8')\n",
    "            credits_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not add credits to {srt_file.name}: {e}\")\n",
    "    status(f\"Credits added to {credits_count} file(s)\")\n",
    "else:\n",
    "    status(\"No credits configured or no files generated\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMPLETE & PERSIST\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"TWO-PASS TRANSCRIPTION COMPLETE\")\n",
    "\n",
    "mode_text = \"parallel\" if PARALLEL_MODE else \"sequential\"\n",
    "msg = f\"<b>âœ“ Done ({mode_text})!</b> {len(merged_outputs)} subtitle(s).\"\n",
    "\n",
    "# Create a handy ZIP bundle\n",
    "zip_path = output_dir / f\"{cfg['folder_name']}_transcriptions.zip\"\n",
    "try:\n",
    "    if merged_outputs:\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for srt in merged_outputs:\n",
    "                zipf.write(srt, srt.name)\n",
    "        status(f\"Bundled results into: {zip_path.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create zip: {e}\")\n",
    "\n",
    "if PLATFORM == 'kaggle':\n",
    "    msg += f\"<br>ğŸ“‚ <b>Kaggle Output:</b> Check the right sidebar 'Output' tab â†’ <code>{cfg['folder_name']}/</code>.<br>âš  <b>Important:</b> Download files manually NOW or use 'Save Version' to persist them!\"\n",
    "    if zip_path.exists():\n",
    "        from IPython.display import FileLink\n",
    "        # FileLink automatically serves relative to the working directory.\n",
    "        # Check if output_dir is relative or absolute under /kaggle/working\n",
    "        try:\n",
    "             # Calculate path relative to CWD (/kaggle/working)\n",
    "             rel_path = zip_path.relative_to(Path.cwd())\n",
    "             display(FileLink(str(rel_path), result_html_prefix=\"<b>â¬‡ Click to download ZIP: </b>\", result_html_suffix=\" (Kaggle)\"))\n",
    "        except ValueError:\n",
    "             # Fallback if path parsing fails\n",
    "             display(FileLink(zip_path.name, result_html_prefix=\"<b>â¬‡ Click to download ZIP: </b>\", result_html_suffix=\" (Kaggle)\"))\n",
    "\n",
    "else:\n",
    "    msg += f\" saved to Google Drive/...\"\n",
    "    if zip_path.exists():\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(str(zip_path)) \n",
    "        except: pass\n",
    "\n",
    "display(HTML(f'<div style=\"padding:8px 10px;background:#f0fdf4;border-radius:4px;border-left:2px solid #16a34a;font-size:10px\">{msg}</div>'))\n",
    "\n",
    "if cfg['subtitle_language'] == 'llm' and not cfg['api_key']:\n",
    "    print(\"Note: AI translation skipped (no API key provided)\")\n",
    "\n",
    "if cfg['auto_disconnect']:\n",
    "    print(\"\\\\nAuto-disconnecting logic triggered...\")\n",
    "    time.sleep(10)\n",
    "    if PLATFORM == 'colab':\n",
    "        try:\n",
    "            from google.colab import runtime\n",
    "            runtime.unassign()\n",
    "        except: pass\n",
    "    elif PLATFORM == 'kaggle':\n",
    "        # Kaggle specific exit/cleanup if needed? \n",
    "        # Usually script ending is enough for Save Version interaction\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 3: AI Translation (if selected) { display-mode: \"form\" }\n",
    "#@markdown Translate each subtitle file using AI (only runs if \"English (AI translate)\" selected)\n",
    "\n",
    "import os, sys, subprocess, shlex, time\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    icon = \"âœ“\" if ok else \"âœ—\"\n",
    "    print(f\"{icon} {msg}\")\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'â”€'*40}\\n{title}\\n{'â”€'*40}\")\n",
    "\n",
    "# Check prerequisites\n",
    "if 'WHISPERJAV_CONFIG' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 1 first</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "if 'WHISPERJAV_NEW_SRTS' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 2 first</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "new_srts = WHISPERJAV_NEW_SRTS\n",
    "output_dir = WHISPERJAV_OUTPUT_DIR if 'WHISPERJAV_OUTPUT_DIR' in dir() else Path(os.getcwd())\n",
    "\n",
    "# Re-detect platform just in case\n",
    "if 'google.colab' in sys.modules: PLATFORM = 'colab'\n",
    "elif os.path.exists('/kaggle'): PLATFORM = 'kaggle'\n",
    "else: PLATFORM = 'local'\n",
    "\n",
    "# Check if AI translation is needed\n",
    "if cfg['subtitle_language'] != 'llm':\n",
    "    display(HTML('<div style=\"padding:8px 10px;background:#f0f9ff;border-radius:4px;border-left:2px solid #3b82f6;font-size:10px\"><b>â„¹ Skipped:</b> AI translation not selected</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# API KEY RESOLUTION (SECRETS MANAGER)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def retrieve_key(service_name, config_key):\n",
    "    \"\"\"Try to get key from config, Kaggle secrets, or env.\"\"\"\n",
    "    if config_key and config_key.strip():\n",
    "        return config_key.strip()\n",
    "    \n",
    "    # Try Kaggle Secrets\n",
    "    if PLATFORM == 'kaggle':\n",
    "        try:\n",
    "            from kaggle_secrets import UserSecretsClient\n",
    "            secrets = UserSecretsClient()\n",
    "            candidates = [\n",
    "                f\"{service_name.upper()}_API_KEY\",\n",
    "                \"API_KEY\",\n",
    "                \"LLM_API_KEY\",\n",
    "                service_name.lower()\n",
    "            ]\n",
    "            for c in candidates:\n",
    "                try:\n",
    "                    k = secrets.get_secret(c)\n",
    "                    if k: return k\n",
    "                except: pass\n",
    "        except: pass\n",
    "        \n",
    "    return \"\"\n",
    "\n",
    "final_api_key = retrieve_key(cfg['translation_service'], cfg.get('api_key'))\n",
    "\n",
    "if not final_api_key:\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> No API key provided (checked Config and Kaggle Secrets)</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "if not new_srts:\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> No subtitle files to translate</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "# Set up API key\n",
    "env_map = {\n",
    "    \"deepseek\": \"DEEPSEEK_API_KEY\",\n",
    "    \"openrouter\": \"OPENROUTER_API_KEY\",\n",
    "    \"gemini\": \"GEMINI_API_KEY\",\n",
    "    \"claude\": \"ANTHROPIC_API_KEY\",\n",
    "    \"gpt\": \"OPENAI_API_KEY\"\n",
    "}\n",
    "os.environ[env_map.get(cfg['translation_service'], \"API_KEY\")] = final_api_key\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TRANSLATION LOOP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"AI TRANSLATION\")\n",
    "print(f\"Provider: {cfg['translation_service']}\")\n",
    "print(f\"Style: {cfg['_translation_style']}\")\n",
    "print(f\"Files to translate: {len(new_srts)}\\n\")\n",
    "\n",
    "translated_files = []\n",
    "failed_files = []\n",
    "\n",
    "for i, srt_file in enumerate(new_srts, 1):\n",
    "    print(f\"[{i}/{len(new_srts)}] Translating: {srt_file.name}\")\n",
    "\n",
    "    translate_cmd = [\n",
    "        'whisperjav-translate',\n",
    "        '-i', str(srt_file),\n",
    "        '--provider', cfg['translation_service'],\n",
    "        '-t', 'english',\n",
    "        '--tone', cfg['translation_style'],\n",
    "        '--stream'\n",
    "    ]\n",
    "\n",
    "    full_cmd = shlex.join(translate_cmd)\n",
    "\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            full_cmd,\n",
    "            shell=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "\n",
    "        for line in process.stderr:\n",
    "            print(f\"    {line}\", end='')\n",
    "\n",
    "        stdout_output, _ = process.communicate()\n",
    "\n",
    "        if process.returncode == 0:\n",
    "            output_path = stdout_output.strip()\n",
    "            if output_path:\n",
    "                translated_files.append(Path(output_path))\n",
    "            status(f\"Completed: {srt_file.name}\")\n",
    "        else:\n",
    "            status(f\"Failed: {srt_file.name}\", False)\n",
    "            failed_files.append(srt_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        status(f\"Error translating {srt_file.name}: {e}\", False)\n",
    "        failed_files.append(srt_file)\n",
    "\n",
    "    print()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMPLETE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"COMPLETE\")\n",
    "\n",
    "# Create ZIP of translations\n",
    "if translated_files:\n",
    "    trans_zip_path = output_dir / f\"{cfg['folder_name']}_translations_{cfg['translation_service']}.zip\"\n",
    "    try:\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(trans_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for srt in translated_files:\n",
    "                zipf.write(srt, srt.name)\n",
    "        status(f\"Bundled translations into: {trans_zip_path.name}\")\n",
    "        \n",
    "        # Download triggers\n",
    "        if PLATFORM == 'kaggle':\n",
    "            try:\n",
    "                from IPython.display import FileLink\n",
    "                rel_path = trans_zip_path.relative_to(Path.cwd())\n",
    "                display(FileLink(str(rel_path), result_html_prefix=\"<b>â¬‡ Click to download Translations ZIP: </b>\", result_html_suffix=\" (Kaggle)\"))\n",
    "            except:\n",
    "                display(HTML(f'<b>â¬‡ <a href=\"{trans_zip_path.name}\" target=\"_blank\">Click here to download Translations ZIP</a></b> (Kaggle)'))\n",
    "\n",
    "        elif PLATFORM == 'colab':\n",
    "            try:\n",
    "                from google.colab import files\n",
    "                files.download(str(trans_zip_path))\n",
    "            except: pass\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create zip: {e}\")\n",
    "\n",
    "if failed_files:\n",
    "    display(HTML(f'<div style=\"padding:8px 10px;background:#fef9c3;border-radius:4px;border-left:2px solid #ca8a04;font-size:10px\"><b>âš  Partially done!</b> {len(translated_files)}/{len(new_srts)} translated. {len(failed_files)} failed.</div>'))\n",
    "else:\n",
    "    if PLATFORM == 'kaggle':\n",
    "        loc_msg = f\"<br>ğŸ“‚ <b>files in 'Output' tab â†’ <code>{cfg['folder_name']}/</code></b>. <br>âš  <b>Download now</b> or they will be lost when session ends!\"\n",
    "    else:\n",
    "        loc_msg = f\"in {output_dir}\"\n",
    "\n",
    "    display(HTML(f'<div style=\"padding:8px 10px;background:#f0fdf4;border-radius:4px;border-left:2px solid #16a34a;font-size:10px\"><b>âœ“ All done!</b> {len(new_srts)} Japanese + {len(translated_files)} English subtitle(s) {loc_msg}</div>'))\n",
    "\n",
    "# Auto-disconnect\n",
    "if cfg['auto_disconnect']:\n",
    "    print(\"\\nAuto-disconnecting in 10s...\")\n",
    "    time.sleep(10)\n",
    "    if PLATFORM == 'colab':\n",
    "        try:\n",
    "            from google.colab import runtime\n",
    "            runtime.unassign()\n",
    "        except: pass\n",
    "else:\n",
    "    print(\"\\nRemember to disconnect manually.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
