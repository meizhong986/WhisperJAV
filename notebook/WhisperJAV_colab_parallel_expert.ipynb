{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>\n",
    "\n",
    "# WhisperJAV Ensemble Dual-GPU Edition (v1.8.0)\n",
    "\n",
    "**Universal Parallel Workflow**\n",
    "\n",
    "| Platform | Logic | Storage |\n",
    "|----------|-------|---------|\n",
    "| **Kaggle** | **Parallel** (2x T4) | **Input**: `/kaggle/input` (Dataset) <br> **Output**: `/kaggle/working` (Artifacts) |\n",
    "| **Colab** | **Sequential** (1x GPU) | **Input/Output**: Google Drive |\n",
    "\n",
    "---\n",
    "### **Workflow**\n",
    "1. **Configure**: Select your settings, models, and audio preferences.\n",
    "2. **Setup**: Installs dependencies and prepares the environment (**Run Once**).\n",
    "3. **Transcribe**: Processes your video files using the configured settings.\n",
    "4. **Translate**: (Optional) Uses AI to translate subtitles to English.\n",
    "\n",
    "<small><i>Tip: Select your Dataset in Kaggle, then use \"Run All\". The notebook is designed to Fail Fast if resources are missing.</i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 1: Expert Configuration { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ## ğŸ“ Files & Output\n",
    "folder_name = \"WhisperJAV\" #@param {type:\"string\"}\n",
    "subtitle_language = \"Japanese\" #@param [\"Japanese\", \"English (auto-translate)\", \"English (AI translate)\"]\n",
    "spoken_language = \"Japanese\" #@param [\"Japanese\", \"Chinese\", \"English\", \"Korean\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 1ï¸âƒ£ Pass 1 Configuration (GPU 0)\n",
    "pass1_quality = \"balanced\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass1_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass1_model = \"large-v2\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 1)**\n",
    "pass1_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass1_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass1_speech_enhancer = \"none\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "#@markdown <font size=\"1\">auditok=energy (fast), silero=VAD, semantic=texture (complex audio) | enhancer: ffmpeg-dsp(no GPU), clearvoice(48k), bs-roformer(vocal)</font>\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 1)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass1_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 2ï¸âƒ£ Pass 2 Configuration (GPU 1)\n",
    "pass2_quality = \"fidelity\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass2_sensitivity = \"balanced\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass2_model = \"turbo\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 2)**\n",
    "pass2_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass2_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass2_speech_enhancer = \"ffmpeg-dsp\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 2)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass2_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ”— Merge Strategy\n",
    "merge_method = \"prefer first pass\" #@param [\"automatic\", \"keep all\", \"prefer first pass\", \"prefer second pass\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ¤– AI Translation *(if selected)*\n",
    "translation_service = \"local\" #@param [\"local\", \"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\"]\n",
    "#@markdown â˜ï¸ **local** = Free, runs on Colab GPU. Others need API key.\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "#@markdown â˜ï¸ Leave empty for **local** provider\n",
    "translation_style = \"standard\" #@param [\"standard\", \"explicit\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## âš™ï¸ Session\n",
    "opening_credit = \"\" #@param {type:\"string\"}\n",
    "closing_credit = \"Subs by WhisperJAV\" #@param {type:\"string\"}\n",
    "auto_disconnect = True #@param {type:\"boolean\"}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION LOGIC\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Mapping dictionaries\n",
    "combine_map = {\"automatic\": \"smart_merge\", \"keep all\": \"full_merge\",\n",
    "               \"prefer first pass\": \"pass1_primary\", \"prefer second pass\": \"pass2_primary\"}\n",
    "language_map = {\"Japanese\": \"native\", \"English (auto-translate)\": \"direct-to-english\",\n",
    "                \"English (AI translate)\": \"llm\"}\n",
    "tone_map = {\"standard\": \"standard\", \"explicit\": \"pornify\"}\n",
    "spoken_language_map = {\"Japanese\": \"japanese\", \"Chinese\": \"chinese\", \"English\": \"english\", \"Korean\": \"korean\"}\n",
    "\n",
    "# Model mapping (None = use pipeline default)\n",
    "model_map = {\n",
    "    \"automatic\": None,\n",
    "    \"large-v2\": \"large-v2\",\n",
    "    \"large-v3\": \"large-v3\",\n",
    "    \"turbo\": \"turbo\",\n",
    "    \"kotoba-bilingual\": \"kotoba-tech/kotoba-whisper-bilingual-v1.0\",\n",
    "    \"kotoba-v2.0\": \"kotoba-tech/kotoba-whisper-v2.0\",\n",
    "    \"kotoba-v2.1\": \"kotoba-tech/kotoba-whisper-v2.1\",\n",
    "    \"kotoba-v2.2\": \"kotoba-tech/kotoba-whisper-v2.2\"\n",
    "}\n",
    "\n",
    "# Define model compatibility:\n",
    "KOTOBA_MODELS = {\"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"}\n",
    "LEGACY_PIPELINES = {\"faster\", \"fast\", \"balanced\", \"fidelity\"}\n",
    "\n",
    "# Auto-correct incompatible model-pipeline combinations\n",
    "warnings_list = []\n",
    "\n",
    "# Check Pass 1 compatibility\n",
    "if pass1_model in KOTOBA_MODELS and pass1_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 1: {pass1_model} requires 'transformers' pipeline. Auto-correcting from '{pass1_quality}' to 'transformers'.\")\n",
    "    pass1_quality = \"transformers\"\n",
    "\n",
    "# Check Pass 2 compatibility\n",
    "if pass2_model in KOTOBA_MODELS and pass2_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 2: {pass2_model} requires 'transformers' pipeline. Auto-correcting from '{pass2_quality}' to 'transformers'.\")\n",
    "    pass2_quality = \"transformers\"\n",
    "\n",
    "# Memory warning\n",
    "heavy_enhancers = {'clearvoice', 'bs-roformer', 'zipenhancer'}\n",
    "if pass1_speech_enhancer in heavy_enhancers and pass2_speech_enhancer in heavy_enhancers:\n",
    "    warnings_list.append(\"Using GPU-based enhancement on both passes may cause OOM on T4 GPU (Sequential Mode). Suggest using ffmpeg-dsp for one pass.\")\n",
    "\n",
    "# Helpers\n",
    "def build_ffmpeg_filters(amplify, loudnorm, compress, highpass):\n",
    "    \"\"\"Combine selected FFmpeg filters into comma-separated string.\"\"\"\n",
    "    filters = []\n",
    "    if amplify: filters.append(\"amplify\")\n",
    "    if loudnorm: filters.append(\"loudnorm\")\n",
    "    if compress: filters.append(\"compress\")\n",
    "    if highpass: filters.append(\"highpass\")\n",
    "    return \",\".join(filters) if filters else None\n",
    "\n",
    "def map_value(val):\n",
    "    return None if val == \"automatic\" else val\n",
    "\n",
    "def map_segmenter(val):\n",
    "    return \"none\" if val == \"none\" else map_value(val)\n",
    "\n",
    "# Unified Config Construction\n",
    "WHISPERJAV_CONFIG = {\n",
    "    'pass1_pipeline': pass1_quality,\n",
    "    'pass1_sensitivity': pass1_sensitivity,\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter),\n",
    "    'pass1_model': model_map[pass1_model],\n",
    "    'pass2_pipeline': pass2_quality,\n",
    "    'pass2_sensitivity': pass2_sensitivity,\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter),\n",
    "    'pass2_model': model_map[pass2_model],\n",
    "    'merge_strategy': combine_map[merge_method],\n",
    "    'folder_name': folder_name,\n",
    "    'subtitle_language': language_map[subtitle_language],\n",
    "    'language': spoken_language_map[spoken_language],\n",
    "    'translation_service': translation_service,\n",
    "    'api_key': api_key,\n",
    "    'translation_style': tone_map[translation_style],\n",
    "    'opening_credit': opening_credit,\n",
    "    'closing_credit': closing_credit,\n",
    "    'auto_disconnect': auto_disconnect,\n",
    "    # Compatibility checks for Step 2\n",
    "    '_pass1_quality': pass1_quality,\n",
    "    '_pass1_sensitivity': pass1_sensitivity,\n",
    "    '_pass1_speech_segmenter': pass1_speech_segmenter,\n",
    "    '_pass1_model': pass1_model,\n",
    "    '_pass2_quality': pass2_quality,\n",
    "    '_pass2_sensitivity': pass2_sensitivity,\n",
    "    '_pass2_speech_segmenter': pass2_speech_segmenter,\n",
    "    '_pass2_model': pass2_model,\n",
    "    '_merge_method': merge_method,\n",
    "    '_subtitle_language': subtitle_language,\n",
    "    '_translation_style': translation_style,\n",
    "}\n",
    "\n",
    "WHISPERJAV_EXPERT_CONFIG = {\n",
    "    # Pass 1 Expert\n",
    "    'pass1_scene_detector': map_value(pass1_scene_detector),\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter), # Now unified\n",
    "    'pass1_speech_enhancer': None if pass1_speech_enhancer == \"none\" else pass1_speech_enhancer,\n",
    "    'pass1_ffmpeg_filters': build_ffmpeg_filters(pass1_ffmpeg_amplify, pass1_ffmpeg_loudnorm, pass1_ffmpeg_compress, pass1_ffmpeg_highpass) if pass1_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    # Pass 2 Expert\n",
    "    'pass2_scene_detector': map_value(pass2_scene_detector),\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter), # Now unified\n",
    "    'pass2_speech_enhancer': None if pass2_speech_enhancer == \"none\" else pass2_speech_enhancer,\n",
    "    'pass2_ffmpeg_filters': build_ffmpeg_filters(pass2_ffmpeg_amplify, pass2_ffmpeg_loudnorm, pass2_ffmpeg_compress, pass2_ffmpeg_highpass) if pass2_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    # Display helpers\n",
    "    '_pass1_scene_detector': pass1_scene_detector,\n",
    "    '_pass1_speech_enhancer': pass1_speech_enhancer,\n",
    "    '_pass2_scene_detector': pass2_scene_detector,\n",
    "    '_pass2_speech_enhancer': pass2_speech_enhancer,\n",
    "}\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display warnings\n",
    "for warning in warnings_list:\n",
    "    display(HTML(f'<div style=\"padding:6px 10px;background:#fef9c3;border-radius:4px;font-size:10px;margin-bottom:4px\"><b>âš ï¸ Auto-corrected:</b> {warning}</div>'))\n",
    "\n",
    "# Build status display\n",
    "p1_info = f\"{pass1_quality}\"\n",
    "if pass1_speech_segmenter != \"automatic\":\n",
    "    p1_info += f\"/{pass1_speech_segmenter}\"\n",
    "if pass1_model != \"automatic\":\n",
    "    p1_info += f\"/{pass1_model}\"\n",
    "\n",
    "p2_info = f\"{pass2_quality}\"\n",
    "if pass2_speech_segmenter != \"automatic\":\n",
    "    p2_info += f\"/{pass2_speech_segmenter}\"\n",
    "if pass2_model != \"automatic\":\n",
    "    p2_info += f\"/{pass2_model}\"\n",
    "\n",
    "display(HTML(f'<div style=\"padding:10px;background:#e0f2fe;border-radius:4px;font-size:11px\">'\n",
    "             f'<b>Parallel Configuration Loaded</b><br>'\n",
    "             f'Pass 1: {p1_info} | Pass 2: {p2_info}<br>'\n",
    "             f'Merge: {merge_method} | Folder: {folder_name} | Language: {spoken_language}'\n",
    "             f'</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbcce2",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#@title Step 2: Setup & Environment (Run Once) { display-mode: \"form\" }\n",
    "#@markdown - **Fails Fast** if GPU or Internet is missing.\n",
    "#@markdown - Installs **System Tools** (FFmpeg, libc++) and **Python Libraries** (WhisperJAV, VADs).\n",
    "#@markdown - Prepares the environment for all subsequent steps.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import socket\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'â”€'*40}\\n{title}\\n{'â”€'*40}\")\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n",
    "\n",
    "def must(condition, msg):\n",
    "    if not condition:\n",
    "        raise RuntimeError(f\"SETUP FAILED: {msg}\")\n",
    "\n",
    "def run_shell(name, cmd):\n",
    "    \"\"\"Run a shell command (apt, etc) with timeout.\"\"\"\n",
    "    print(f\"... installing {name}\")\n",
    "    try:\n",
    "        r = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=600)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        raise RuntimeError(f\"Install timed out (10m): {name}\")\n",
    "    \n",
    "    if r.returncode != 0:\n",
    "        print((r.stderr or r.stdout or \"\")[-2000:])\n",
    "        raise RuntimeError(f\"Install failed: {name}\")\n",
    "    status(f\"Installed {name}\")\n",
    "\n",
    "def run_pip(name, packages, no_deps=False):\n",
    "    \"\"\"Run pip install safely (avoiding shell injection) with timeout.\"\"\"\n",
    "    print(f\"... installing {name}\")\n",
    "    # cmd: python -m pip install -q [packages...]\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"]\n",
    "    if no_deps:\n",
    "        cmd.append(\"--no-deps\")\n",
    "    cmd.extend(packages)\n",
    "    \n",
    "    try:\n",
    "        r = subprocess.run(cmd, check=False, text=True, capture_output=True, timeout=600)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        raise RuntimeError(f\"Pip Install timed out (10m): {name}\")\n",
    "\n",
    "    if r.returncode != 0:\n",
    "        print(f\"--- pip stderr for {name} ---\")\n",
    "        print((r.stderr or r.stdout or \"\")[-2000:])\n",
    "        raise RuntimeError(f\"Pip Install failed: {name}\")\n",
    "    status(f\"Installed {name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. PRE-FLIGHT CHECKS (Fail Fast)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"PRE-FLIGHT CHECKS\")\n",
    "\n",
    "# Detect Platform\n",
    "if \"google.colab\" in sys.modules:\n",
    "    PLATFORM = \"colab\"\n",
    "elif os.path.exists(\"/kaggle\"):\n",
    "    PLATFORM = \"kaggle\"\n",
    "else:\n",
    "    PLATFORM = \"local\"\n",
    "print(f\"Platform: {PLATFORM.upper()}\")\n",
    "print(f\"Python:   {sys.executable} ({sys.version.split()[0]})\")\n",
    "\n",
    "# Check GPU\n",
    "gpu_check = subprocess.run(\"nvidia-smi --query-gpu=name --format=csv,noheader\", shell=True, capture_output=True, text=True)\n",
    "must(gpu_check.returncode == 0 and bool(gpu_check.stdout.strip()), \"No GPU detected. Switch runtime to GPU.\")\n",
    "gpus = [line.strip() for line in gpu_check.stdout.splitlines() if line.strip()]\n",
    "status(f\"GPU(s) Detected: {len(gpus)} ({', '.join(gpus)})\")\n",
    "\n",
    "# Check Internet (China-compatible)\n",
    "def check_internet():\n",
    "    endpoints = [\n",
    "        (\"www.baidu.com\", 80),      # China\n",
    "        (\"www.google.com\", 80),      # Global\n",
    "        (\"1.1.1.1\", 53),             # Cloudflare DNS\n",
    "    ]\n",
    "    for host, port in endpoints:\n",
    "        try:\n",
    "            socket.create_connection((host, port), timeout=3.0).close()\n",
    "            return True\n",
    "        except OSError:\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "must(check_internet(), \"Internet disabled/unreachable. Cannot install dependencies.\")\n",
    "status(\"Internet reachable\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. INSTALLATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"INSTALLING DEPENDENCIES (3-5 min)\")\n",
    "install_start = time.time()\n",
    "\n",
    "# Determine sudo usage\n",
    "prefix = \"\"\n",
    "if shutil.which(\"sudo\") and not (hasattr(os, \"geteuid\") and os.geteuid() == 0):\n",
    "    prefix = \"sudo \"\n",
    "\n",
    "# A. System Layer (APT)\n",
    "# Unconditional: libraries for Audio (portaudio), Video (ffmpeg), and VAD (libc++)\n",
    "sys_pkgs = \"ffmpeg portaudio19-dev libc++1 libc++abi1\"\n",
    "run_shell(\"System Tools (apt)\", f\"{prefix}apt-get update -qq && {prefix}apt-get install -y -qq {sys_pkgs}\")\n",
    "must(shutil.which(\"ffmpeg\"), \"FFmpeg installation verified\")\n",
    "\n",
    "# B. Core Acceleration Layer (Pip)\n",
    "# Upgrade pip first\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\"], check=False)\n",
    "\n",
    "# Essential Dependencies (Pre-installed to ensure GPU-accelerated versions are used)\n",
    "# NumPy 1.26.x for pyvideotrans compatibility (v1.8.0)\n",
    "core_libs = [\n",
    "    # Utilities\n",
    "    \"tqdm\", \"numba>=0.58.0\", \"tiktoken\", \"soundfile\", \"auditok\", \"requests\", \"colorama\", \"regex\",\n",
    "    \"numpy>=1.26.0,<2.0\", \"scipy>=1.10.1\", \"librosa>=0.10.0\",\n",
    "    \"pysrt\", \"srt\", \"aiofiles\", \"jsonschema\", \"Pillow\", \"pyloudnorm\", \"pydantic>=2,<3\",\n",
    "    # ML Stack\n",
    "    \"faster-whisper>=1.1.0\", \"transformers\", \"optimum\", \"accelerate\", \"huggingface-hub>=0.25.0\",\n",
    "    # VADs\n",
    "    \"ten-vad\", \"silero-vad>=6.0\", \"pydub\",\n",
    "    # Enhancers Dependencies\n",
    "    \"modelscope>=1.20\", \"onnxruntime>=1.16.0\", \"addict\", \"simplejson\", \"sortedcontainers\", \"packaging\"\n",
    "]\n",
    "run_pip(\"Core Acceleration Libs\", core_libs)\n",
    "\n",
    "# C. Application Layer (Git)\n",
    "# We allow dependencies here (no_deps=False) to ensure deep dependencies\n",
    "git_pkgs = [\n",
    "    (\"ffmpeg-python\", \"git+https://github.com/kkroening/ffmpeg-python.git\"), # Fixes PyPI setup.py issue\n",
    "    (\"Whisper\", \"git+https://github.com/openai/whisper.git@main\"),\n",
    "    (\"Stable-TS\", \"git+https://github.com/meizhong986/stable-ts-fix-setup.git@main\"),\n",
    "    (\"ClearVoice\", \"git+https://github.com/meizhong986/ClearerVoice-Studio.git#subdirectory=clearvoice\"),\n",
    "    (\"WhisperJAV\", \"git+https://github.com/meizhong986/WhisperJAV.git@main\"),\n",
    "]\n",
    "\n",
    "for name, url in git_pkgs:\n",
    "    run_pip(name, [url], no_deps=False)\n",
    "\n",
    "# Conflict Resolution: Attempt to remove existing versions (System/Pre-installed)\n",
    "# This is crucial for Kaggle/Colab where system packages often shadow user installs\n",
    "print(\"... Purging conflicting libraries to force clean state\")\n",
    "# We use a direct subprocess call to allow failure (best effort)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"-q\", \"numpy\", \"scipy\", \"librosa\", \"numba\", \"scikit-learn\"], check=False)\n",
    "\n",
    "# Re-pin Core Libs to ensure version consistency (fix Scipy/Numpy conflict)\n",
    "# This prevents git packages (like Whisper) from downgrading Scipy/Librosa to incompatible versions\n",
    "# FORCE REINSTALL: Mandatory to overwrite persistent/system packages in Kaggle/Colab\n",
    "# NumPy 1.26.x for pyvideotrans compatibility (v1.8.0)\n",
    "run_pip(\"Ensure Core Consistency\", [\"--force-reinstall\", \"--upgrade\", \"numpy>=1.26.0,<2.0\", \"scipy>=1.10.1\", \"librosa>=0.10.0\", \"numba>=0.58.0\", \"scikit-learn>=1.3.0\"], no_deps=True)\n",
    "\n",
    "status(f\"Installation Complete ({time.time() - install_start:.0f}s)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. VERIFICATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"VERIFICATION\")\n",
    "\n",
    "# Verify Import\n",
    "try:\n",
    "    import whisperjav\n",
    "    status(f\"WhisperJAV {whisperjav.__version__} Ready\")\n",
    "except ImportError as e:\n",
    "    raise RuntimeError(f\"Installation successful but import failed: {e}\")\n",
    "\n",
    "# Verify TEN/Libc++ (Common Failure Point)\n",
    "try:\n",
    "    import ten_vad\n",
    "    status(\"TEN VAD Ready\")\n",
    "except ImportError:\n",
    "    status(\"TEN VAD Warning (Import failed - Silero fallback)\", False)\n",
    "\n",
    "# Stamp Success - Used by Step 3\n",
    "WHISPERJAV_SETUP_COMPLETE = {\n",
    "    \"timestamp\": time.time(),\n",
    "    \"platform\": PLATFORM,\n",
    "    \"gpu_count\": len(gpus)\n",
    "}\n",
    "print(\"\\nâœ“ Environment Ready. Go to Step 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 3: Execution (Transcribe) { display-mode: \"form\" }\n",
    "#@markdown - Auto-detects **Files** (Kaggle Dataset or Colab Drive).\n",
    "#@markdown - Auto-detects **Parallel** (2x GPU) or **Sequential** mode.\n",
    "#@markdown - Runs the configured WhisperJAV pipeline.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import HTML, FileLink, display\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CHECKS & PREP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if \"WHISPERJAV_SETUP_COMPLETE\" not in globals():\n",
    "    display(HTML('<div style=\"background:#fee2e2;color:#991b1b;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Setup Incomplete</b><br>Please run <b>Step 2: Setup</b> first.</div>'))\n",
    "    raise RuntimeError(\"Step 2 required\")\n",
    "\n",
    "if \"WHISPERJAV_CONFIG\" not in globals():\n",
    "    display(HTML('<div style=\"background:#fee2e2;color:#991b1b;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Config Missing</b><br>Please run <b>Step 1: Configuration</b> first.</div>'))\n",
    "    raise RuntimeError(\"Step 1 required\")\n",
    "\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "expert = globals().get(\"WHISPERJAV_EXPERT_CONFIG\", {})\n",
    "PLATFORM = WHISPERJAV_SETUP_COMPLETE[\"platform\"]\n",
    "PARALLEL_MODE = WHISPERJAV_SETUP_COMPLETE[\"gpu_count\"] >= 2\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n",
    "\n",
    "def check_progress(targets):\n",
    "    \"\"\"Prints tail of logs for active processes.\"\"\"\n",
    "    print(f\"\\n--- Status {time.strftime('%H:%M:%S')} ---\")\n",
    "    for path, label in targets:\n",
    "        if not path.exists(): continue\n",
    "        try:\n",
    "            with open(path, \"r\", errors=\"ignore\") as f:\n",
    "                f.seek(0, 2) # Go to end\n",
    "                size = f.tell()\n",
    "                # Read last 2KB to ensure we get 4 lines\n",
    "                f.seek(max(0, size - 2048), 0)\n",
    "                lines = f.readlines()\n",
    "                # If we seeked, drop the first partial line\n",
    "                if size > 2048 and len(lines) > 1:\n",
    "                    lines = lines[1:]\n",
    "                \n",
    "                valid_lines = [l.strip() for l in lines if l.strip()]\n",
    "                if valid_lines:\n",
    "                    print(f\"[{label}]:\")\n",
    "                    for l in valid_lines[-4:]:\n",
    "                        print(f\"  {l}\")\n",
    "        except Exception: \n",
    "            pass\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# I/O SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"Mode: {'PARALLEL (2x GPU)' if PARALLEL_MODE else 'SEQUENTIAL (Ensemble)'}\")\n",
    "\n",
    "if PLATFORM == \"colab\":\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=False)\n",
    "    input_dir = Path(\"/content/drive/MyDrive\") / cfg[\"folder_name\"]\n",
    "    output_dir = input_dir\n",
    "    input_dir.mkdir(parents=True, exist_ok=True)\n",
    "elif PLATFORM == \"kaggle\":\n",
    "    # Search for video inputs\n",
    "    video_types = {\".mp4\", \".mkv\", \".avi\", \".mov\", \".wmv\", \".webm\"}\n",
    "    input_dir = None\n",
    "    for p in [Path(f\"/kaggle/input/{cfg['folder_name']}\"), Path(\"/kaggle/input\")]:\n",
    "        if p.exists() and any(f.suffix.lower() in video_types for f in p.rglob(\"*\")):\n",
    "            input_dir = p\n",
    "            break\n",
    "    if not input_dir:\n",
    "        input_dir = Path(\"/kaggle/input\")\n",
    "        print(\"WARN: No specific input folder found. Scanning root /kaggle/input.\")\n",
    "    \n",
    "    output_dir = Path(f\"/kaggle/working/{cfg['folder_name']}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    os.environ[\"TMPDIR\"] = \"/kaggle/working/temp\" # Avoid RAM disk overflow\n",
    "else:\n",
    "    input_dir = Path(cfg[\"folder_name\"]).absolute()\n",
    "    output_dir = Path(f\"{cfg['folder_name']}_output\").absolute()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "status(f\"Input: {input_dir}\")\n",
    "status(f\"Output: {output_dir}\")\n",
    "WHISPERJAV_OUTPUT_DIR = output_dir # Export for Step 4\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUTION LOGIC\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "media_files = sorted([p for p in input_dir.rglob(\"*\") if p.suffix.lower() in {\".mp4\", \".mkv\", \".avi\",\".mov\",\".wmv\",\".flv\",\".webm\",\".m3v\",\".mp3\",\".wav\",\".flac\"}])\n",
    "if not media_files:\n",
    "    raise RuntimeError(f\"No media files found in {input_dir}\")\n",
    "\n",
    "logs_dir = output_dir / \"logs\"\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "final_outputs = []\n",
    "\n",
    "def build_cmd(video_path, out_path, pass_cfg_num=None):\n",
    "    \"\"\"Builds the CLI command. If pass_cfg_num is set, builds a single-pass command (for parallel).\"\"\"\n",
    "    cmd = [sys.executable, \"-m\", \"whisperjav.main\", str(video_path), \"--output-dir\", str(out_path)]\n",
    "    cmd += [\"--subs-language\", \"direct-to-english\" if cfg[\"subtitle_language\"] == \"direct-to-english\" else \"native\"]\n",
    "    if cfg.get(\"language\"): cmd += [\"--language\", cfg[\"language\"]]\n",
    "    \n",
    "    # Helper to clean args\n",
    "    def add_arg(name, val):\n",
    "        if val and val != \"none\": cmd.extend([name, str(val)])\n",
    "\n",
    "    if pass_cfg_num:\n",
    "        # Single Pass Mode (Parallel Worker)\n",
    "        p = f\"pass{pass_cfg_num}\"\n",
    "        cmd += [\"--mode\", cfg[f\"{p}_pipeline\"], \"--sensitivity\", cfg[f\"{p}_sensitivity\"]]\n",
    "        add_arg(\"--model\", cfg.get(f\"{p}_model\"))\n",
    "        add_arg(\"--speech-segmenter\", cfg.get(f\"{p}_speech_segmenter\"))\n",
    "        # Single pass expert args (enhancers/scene) would be mapped here if supported by main CLI in single mode\n",
    "    else:\n",
    "        # Ensemble Mode (Sequential/Full)\n",
    "        cmd += [\"--ensemble\", \"--merge-strategy\", cfg[\"merge_strategy\"]]\n",
    "        for p in [\"pass1\", \"pass2\"]:\n",
    "            cmd += [f\"--{p}-pipeline\", cfg[f\"{p}_pipeline\"], f\"--{p}-sensitivity\", cfg[f\"{p}_sensitivity\"]]\n",
    "            add_arg(f\"--{p}-model\", cfg.get(f\"{p}_model\"))\n",
    "            add_arg(f\"--{p}-speech-segmenter\", cfg.get(f\"{p}_speech_segmenter\"))\n",
    "            # Expert\n",
    "            add_arg(f\"--{p}-scene-detector\", expert.get(f\"{p}_scene_detector\"))\n",
    "            enh = expert.get(f\"{p}_speech_enhancer\")\n",
    "            if enh == \"ffmpeg-dsp\": enh = f\"ffmpeg-dsp:{expert.get(f'{p}_ffmpeg_filters', 'amplify')}\"\n",
    "            add_arg(f\"--{p}-speech-enhancer\", enh)\n",
    "            \n",
    "    return cmd\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"\\nProcessing {len(media_files)} files...\")\n",
    "\n",
    "if PARALLEL_MODE:\n",
    "    # 2-GPU Parallel Execution: Split Passes, Then Merge\n",
    "    from whisperjav.ensemble.merge import MergeEngine\n",
    "    merger = MergeEngine()\n",
    "    \n",
    "    for vid in media_files:\n",
    "        print(f\"\\n[Parallel] Processing: {vid.name}\")\n",
    "        base = output_dir / vid.stem\n",
    "        p1_dir, p2_dir = base / \"pass1\", base / \"pass2\"\n",
    "        p1_dir.mkdir(parents=True, exist_ok=True)\n",
    "        p2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        log1 = logs_dir / f\"{vid.stem}_pass1.log\"\n",
    "        log2 = logs_dir / f\"{vid.stem}_pass2.log\"\n",
    "\n",
    "        def run_pass(num, gpu, out, log_file):\n",
    "            env = os.environ.copy()\n",
    "            env[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "            with log_file.open(\"w\") as f:\n",
    "                c = build_cmd(vid, out, pass_cfg_num=num)\n",
    "                r = subprocess.run(c, env=env, stdout=f, stderr=subprocess.STDOUT, text=True)\n",
    "            return r.returncode == 0, list(out.glob(\"*.srt\"))[0] if list(out.glob(\"*.srt\")) else None\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=2) as exc:\n",
    "            f1 = exc.submit(run_pass, 1, 0, p1_dir, log1)\n",
    "            f2 = exc.submit(run_pass, 2, 1, p2_dir, log2)\n",
    "            \n",
    "            # Monitoring Loop\n",
    "            while not (f1.done() and f2.done()):\n",
    "                time.sleep(8)\n",
    "                check_progress([(log1, \"GPU 0 (Pass 1)\"), (log2, \"GPU 1 (Pass 2)\")])\n",
    "            \n",
    "            ok1, srt1 = f1.result()\n",
    "            ok2, srt2 = f2.result()\n",
    "\n",
    "        if ok1 and srt1 and ok2 and srt2:\n",
    "            merged = output_dir / srt1.name\n",
    "            merger.merge(srt1, srt2, merged, strategy=cfg[\"merge_strategy\"])\n",
    "            status(f\"Merged: {merged.name}\")\n",
    "            final_outputs.append(merged)\n",
    "        elif (ok1 and srt1) or (ok2 and srt2):\n",
    "            winner = srt1 if (ok1 and srt1) else srt2\n",
    "            dest = output_dir / winner.name\n",
    "            shutil.copy(winner, dest)\n",
    "            status(f\"Partial Success (One pass failed): {dest.name}\")\n",
    "            final_outputs.append(dest)\n",
    "        else:\n",
    "            status(f\"Failed: {vid.name}\", False)\n",
    "\n",
    "else:\n",
    "    # Sequential Execution (Colab/Single-GPU)\n",
    "    # Uses Popen to allow monitoring loop\n",
    "    cmd = build_cmd(input_dir, output_dir)\n",
    "    log_path = logs_dir / \"whisperjav_exec.log\"\n",
    "    print(\"Running sequential ensemble...\")\n",
    "    \n",
    "    with log_path.open(\"w\") as f:\n",
    "        process = subprocess.Popen(cmd, stdout=f, stderr=subprocess.STDOUT)\n",
    "        \n",
    "        while process.poll() is None:\n",
    "            time.sleep(8)\n",
    "            check_progress([(log_path, \"Sequential\")])\n",
    "            \n",
    "    if process.returncode == 0:\n",
    "        new_srts = list(output_dir.glob(\"*.srt\"))\n",
    "        if new_srts:\n",
    "            status(f\"Processed {len(new_srts)} files\")\n",
    "            final_outputs = new_srts\n",
    "        else:\n",
    "            status(\"No SRTs generated. Check logs.\", False)\n",
    "    else:\n",
    "        status(\"Execution failed. See logs.\", False)\n",
    "\n",
    "WHISPERJAV_NEW_SRTS = final_outputs\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PACKAGING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if final_outputs:\n",
    "    zip_path = output_dir / f\"{cfg['folder_name']}_results.zip\"\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for f in output_dir.rglob(\"*\"):\n",
    "            if f.suffix in {\".srt\", \".json\", \".log\"}:\n",
    "                zf.write(f, f.relative_to(output_dir))\n",
    "    \n",
    "    print(f\"\\nğŸ“¦ Bundle created: {zip_path.name}\")\n",
    "    if PLATFORM == \"kaggle\":\n",
    "        display(FileLink(str(zip_path.relative_to(Path.cwd())), result_html_prefix=\"<b>â¬‡ Download Results: </b>\"))\n",
    "    elif PLATFORM == \"colab\":\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(str(zip_path))\n",
    "        except: pass\n",
    "\n",
    "print(f\"\\nTime: {(time.time()-start_time)/60:.1f} min\")\n",
    "print(\"Done. Run Step 4 for Translation if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 4: AI Translation (Optional) { display-mode: \"form\" }\n",
    "#@markdown ## ğŸ¤– Provider Settings\n",
    "translation_provider = \"local\" #@param [\"local\", \"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\", \"glm\", \"groq\"]\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "model_override = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ## ğŸ¯ Translation Settings\n",
    "target_language = \"english\" #@param [\"english\", \"chinese\", \"spanish\", \"indonesian\"]\n",
    "source_language = \"japanese\" #@param [\"japanese\", \"korean\", \"chinese\"]\n",
    "tone = \"pornify\" #@param [\"standard\", \"pornify\"]\n",
    "\n",
    "#@markdown ## ğŸ¬ Context (Optional)\n",
    "#@markdown *Leave blank for batch processing of different movies.*\n",
    "movie_title = \"\" #@param {type:\"string\"}\n",
    "actress = \"\" #@param {type:\"string\"}\n",
    "movie_plot = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ## âš™ï¸ Advanced\n",
    "scene_threshold = 60 #@param {type:\"integer\"}\n",
    "batch_size = 30 #@param {type:\"integer\"}\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display, FileLink\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. INPUT VALIDATION & DISCOVERY\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Reconstruct Output Dir if missing (Support for Session Restart/CPU Mode)\n",
    "if \"WHISPERJAV_OUTPUT_DIR\" not in globals():\n",
    "    if \"WHISPERJAV_CONFIG\" in globals():\n",
    "        fname = WHISPERJAV_CONFIG[\"folder_name\"]\n",
    "        if \"google.colab\" in sys.modules:\n",
    "            from google.colab import drive\n",
    "            drive.mount(\"/content/drive\", force_remount=False)\n",
    "            WHISPERJAV_OUTPUT_DIR = Path(f\"/content/drive/MyDrive/{fname}\")\n",
    "        elif os.path.exists(\"/kaggle\"):\n",
    "            # Note: Kaggle non-persistent unless same session\n",
    "            WHISPERJAV_OUTPUT_DIR = Path(f\"/kaggle/working/{fname}\")\n",
    "        else:\n",
    "            WHISPERJAV_OUTPUT_DIR = Path(f\"{fname}_output\").absolute()\n",
    "    else:\n",
    "        # Fallback for manual run without Step 1\n",
    "        WHISPERJAV_OUTPUT_DIR = Path(\".\").resolve()\n",
    "\n",
    "# Recover SRTS\n",
    "targets = []\n",
    "if \"WHISPERJAV_NEW_SRTS\" in globals() and WHISPERJAV_NEW_SRTS:\n",
    "    targets = WHISPERJAV_NEW_SRTS\n",
    "elif WHISPERJAV_OUTPUT_DIR.exists():\n",
    "    print(f\"Scanning for SRTs in: {WHISPERJAV_OUTPUT_DIR}\")\n",
    "    # Find all source SRTs (excluding existing translations)\n",
    "    candidates = sorted(list(WHISPERJAV_OUTPUT_DIR.glob(\"*.srt\")))\n",
    "    targets = [t for t in candidates if not t.name.endswith(f\".{target_language}.srt\")]\n",
    "\n",
    "if not targets:\n",
    "    display(HTML('<div style=\"background:#fee2e2;padding:10px;border-radius:4px;\"><b>âš ï¸ No Subtitles Found</b><br>Run Step 3, or ensure Output directory has SRTs.</div>'))\n",
    "    raise RuntimeError(\"No inputs\")\n",
    "\n",
    "# Check Metadata safety\n",
    "if len(targets) > 1 and (movie_title or actress or movie_plot):\n",
    "    display(HTML(f'<div style=\"background:#fff7ed;padding:10px;border-radius:4px;border:1px solid #fdba74\"><b>âš ï¸ Metadata Warning</b><br>'\n",
    "                 f'You are applying the same Movie Title/Plot/Actress to <b>{len(targets)} different files</b>.<br>'\n",
    "                 f'If these are different movies, please clear the Context fields above.</div>'))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. CREDENTIALS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "final_key = api_key\n",
    "is_local = translation_provider == \"local\"\n",
    "if not final_key:\n",
    "    # Try Step 1 Config (if matches provider)\n",
    "    if \"WHISPERJAV_CONFIG\" in globals() and WHISPERJAV_CONFIG.get(\"api_key\") and WHISPERJAV_CONFIG.get(\"translation_service\") == translation_provider:\n",
    "        final_key = WHISPERJAV_CONFIG[\"api_key\"]\n",
    "    # Try Kaggle Secrets\n",
    "    elif os.path.exists(\"/kaggle\"):\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        try:\n",
    "            final_key = UserSecretsClient().get_secret(f\"{translation_provider.upper()}_API_KEY\")\n",
    "        except: pass\n",
    "\n",
    "if not is_local and not final_key:\n",
    "    raise RuntimeError(f\"Missing API Key for {translation_provider}. Enter it in the form or Kaggle Secrets.\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. INTERACTIVE CONFIRMATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"Ready to translate {len(targets)} files.\")\n",
    "print(f\"Provider: {translation_provider} | Target: {target_language} | Tone: {tone}\")\n",
    "if model_override:\n",
    "    print(f\"Model: {model_override}\")\n",
    "\n",
    "if not os.path.exists(\"/kaggle\"): # Kaggle batch mode cannot accept input\n",
    "    try:\n",
    "        input(\"\\nPress [Enter] to start translation (or Stop cell to cancel)...\")\n",
    "    except (EOFError, KeyboardInterrupt):\n",
    "        print(\"Cancelled by user.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 4. EXECUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸš€ Starting Translation Service...\")\n",
    "translated_files = []\n",
    "start_time = time.time()\n",
    "\n",
    "for srt in targets:\n",
    "    print(f\"\\nProcessing: {srt.name}\")\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"whisperjav.translate.cli\",\n",
    "        \"-i\", str(srt),\n",
    "        \"--provider\", translation_provider,\n",
    "        \"--api-key\", final_key,\n",
    "        \"--source\", source_language,\n",
    "        \"--target\", target_language,\n",
    "        \"--tone\", tone,\n",
    "        \"--scene-threshold\", str(scene_threshold),\n",
    "        \"--max-batch-size\", str(batch_size),\n",
    "        \"--stream\" # Stream progress to stderr\n",
    "    ]\n",
    "    if is_local:\n",
    "        cmd.append(\"--expose-server\")\n",
    "    \n",
    "    # Optional Args\n",
    "    if model_override: cmd.extend([\"--model\", model_override])\n",
    "    if movie_title: cmd.extend([\"--movie-title\", movie_title])\n",
    "    if actress: cmd.extend([\"--actress\", actress])\n",
    "    if movie_plot: cmd.extend([\"--movie-plot\", movie_plot])\n",
    "    \n",
    "    # Run with real-time streaming\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            bufsize=1, # Line buffered\n",
    "            encoding='utf-8',\n",
    "            errors='replace' # Prevent decoding errors\n",
    "        )\n",
    "        \n",
    "        # Read stderr (progress) and stdout (result path)\n",
    "        output_path = None\n",
    "        while True:\n",
    "            # Check stderr for progress updates\n",
    "            err_line = process.stderr.readline()\n",
    "            if err_line:\n",
    "                print(err_line.strip(), file=sys.stderr) # Print to notebook stderr\n",
    "            \n",
    "            # Check stdout for final filename\n",
    "            out_line = process.stdout.readline()\n",
    "            if out_line:\n",
    "                line = out_line.strip()\n",
    "                if line and line.endswith('.srt'):\n",
    "                    output_path = line\n",
    "                # Also print purely informational stdout\n",
    "                print(line)\n",
    "\n",
    "            # Break safely\n",
    "            if not err_line and not out_line and process.poll() is not None:\n",
    "                break\n",
    "                \n",
    "        if process.returncode == 0 and output_path:\n",
    "            out_file = Path(output_path)\n",
    "            if out_file.exists():\n",
    "                status(f\"Completed: {out_file.name}\")\n",
    "                translated_files.append(out_file)\n",
    "            else:\n",
    "                 status(f\"Error: Output file not found: {output_path}\", False)\n",
    "        else:\n",
    "            status(\"Translation failed (check logs above)\", False)\n",
    "\n",
    "    except Exception as e:\n",
    "        status(f\"Exception: {e}\", False)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 5. PACKAGING & DOWNLOAD\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if translated_files:\n",
    "    # Use output dir from Step 3 if available, else srt parent\n",
    "    base_out = WHISPERJAV_OUTPUT_DIR if \"WHISPERJAV_OUTPUT_DIR\" in globals() else translated_files[0].parent\n",
    "    zip_path = base_out / f\"translated_{translation_provider}_{int(time.time())}.zip\"\n",
    "    \n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for t in translated_files:\n",
    "            zf.write(t, t.name)\n",
    "            \n",
    "    print(f\"\\nğŸ“¦ Translations Bundle: {zip_path.name}\")\n",
    "    \n",
    "    if os.path.exists(\"/kaggle\"):\n",
    "         display(FileLink(str(zip_path.relative_to(Path.cwd())), result_html_prefix=\"<b>â¬‡ Download Translations: </b>\"))\n",
    "    elif \"google.colab\" in sys.modules:\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(str(zip_path))\n",
    "        except: pass\n",
    "else:\n",
    "    print(\"\\nNo translations produced.\")\n",
    "\n",
    "print(f\"\\nTotal Time: {(time.time() - start_time)/60:.1f} min\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
