{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>\n",
    "\n",
    "# WhisperJAV Ensemble Dual-GPU Edition (v1.8.0)\n",
    "\n",
    "**Universal Parallel Workflow**\n",
    "\n",
    "| Platform | Logic | Storage |\n",
    "|----------|-------|---------|\n",
    "| **Kaggle** | **Parallel** (2x T4) | **Input**: `/kaggle/input` (Dataset) <br> **Output**: `/kaggle/working` (Artifacts) |\n",
    "| **Colab** | **Sequential** (1x GPU) | **Input/Output**: Google Drive |\n",
    "\n",
    "---\n",
    "### **Workflow**\n",
    "1. **Configure**: Select your settings, models, and audio preferences.\n",
    "2. **Setup**: Installs dependencies and prepares the environment (**Run Once**).\n",
    "3. **Transcribe**: Processes your video files using the configured settings.\n",
    "4. **Translate**: (Optional) Uses AI to translate subtitles to English.\n",
    "\n",
    "<small><i>Tip: Select your Dataset in Kaggle, then use \"Run All\". The notebook is designed to Fail Fast if resources are missing.</i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 1: Expert Configuration { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ## ğŸ“ Files & Output\n",
    "folder_name = \"WhisperJAV\" #@param {type:\"string\"}\n",
    "subtitle_language = \"Japanese\" #@param [\"Japanese\", \"English (auto-translate)\", \"English (AI translate)\"]\n",
    "spoken_language = \"Japanese\" #@param [\"Japanese\", \"Chinese\", \"English\", \"Korean\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 1ï¸âƒ£ Pass 1 Configuration (GPU 0)\n",
    "pass1_quality = \"balanced\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass1_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass1_model = \"large-v2\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 1)**\n",
    "pass1_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass1_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass1_speech_enhancer = \"none\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "#@markdown <font size=\"1\">auditok=energy (fast), silero=VAD, semantic=texture (complex audio) | enhancer: ffmpeg-dsp(no GPU), clearvoice(48k), bs-roformer(vocal)</font>\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 1)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass1_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 2ï¸âƒ£ Pass 2 Configuration (GPU 1)\n",
    "pass2_quality = \"fidelity\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass2_sensitivity = \"balanced\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass2_model = \"turbo\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 2)**\n",
    "pass2_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass2_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass2_speech_enhancer = \"ffmpeg-dsp\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 2)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass2_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ”— Merge Strategy\n",
    "merge_method = \"prefer first pass\" #@param [\"automatic\", \"keep all\", \"prefer first pass\", \"prefer second pass\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ¤– AI Translation *(if selected)*\n",
    "translation_service = \"deepseek\" #@param [\"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\"]\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "translation_style = \"standard\" #@param [\"standard\", \"explicit\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## âš™ï¸ Session\n",
    "opening_credit = \"\" #@param {type:\"string\"}\n",
    "closing_credit = \"Subs by WhisperJAV\" #@param {type:\"string\"}\n",
    "auto_disconnect = True #@param {type:\"boolean\"}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION LOGIC\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Mapping dictionaries\n",
    "combine_map = {\"automatic\": \"smart_merge\", \"keep all\": \"full_merge\",\n",
    "               \"prefer first pass\": \"pass1_primary\", \"prefer second pass\": \"pass2_primary\"}\n",
    "language_map = {\"Japanese\": \"native\", \"English (auto-translate)\": \"direct-to-english\",\n",
    "                \"English (AI translate)\": \"llm\"}\n",
    "tone_map = {\"standard\": \"standard\", \"explicit\": \"pornify\"}\n",
    "spoken_language_map = {\"Japanese\": \"japanese\", \"Chinese\": \"chinese\", \"English\": \"english\", \"Korean\": \"korean\"}\n",
    "\n",
    "# Model mapping (None = use pipeline default)\n",
    "model_map = {\n",
    "    \"automatic\": None,\n",
    "    \"large-v2\": \"large-v2\",\n",
    "    \"large-v3\": \"large-v3\",\n",
    "    \"turbo\": \"turbo\",\n",
    "    \"kotoba-bilingual\": \"kotoba-tech/kotoba-whisper-bilingual-v1.0\",\n",
    "    \"kotoba-v2.0\": \"kotoba-tech/kotoba-whisper-v2.0\",\n",
    "    \"kotoba-v2.1\": \"kotoba-tech/kotoba-whisper-v2.1\",\n",
    "    \"kotoba-v2.2\": \"kotoba-tech/kotoba-whisper-v2.2\"\n",
    "}\n",
    "\n",
    "# Define model compatibility:\n",
    "KOTOBA_MODELS = {\"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"}\n",
    "LEGACY_PIPELINES = {\"faster\", \"fast\", \"balanced\", \"fidelity\"}\n",
    "\n",
    "# Auto-correct incompatible model-pipeline combinations\n",
    "warnings_list = []\n",
    "\n",
    "# Check Pass 1 compatibility\n",
    "if pass1_model in KOTOBA_MODELS and pass1_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 1: {pass1_model} requires 'transformers' pipeline. Auto-correcting from '{pass1_quality}' to 'transformers'.\")\n",
    "    pass1_quality = \"transformers\"\n",
    "\n",
    "# Check Pass 2 compatibility\n",
    "if pass2_model in KOTOBA_MODELS and pass2_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 2: {pass2_model} requires 'transformers' pipeline. Auto-correcting from '{pass2_quality}' to 'transformers'.\")\n",
    "    pass2_quality = \"transformers\"\n",
    "\n",
    "# Memory warning\n",
    "heavy_enhancers = {'clearvoice', 'bs-roformer', 'zipenhancer'}\n",
    "if pass1_speech_enhancer in heavy_enhancers and pass2_speech_enhancer in heavy_enhancers:\n",
    "    warnings_list.append(\"Using GPU-based enhancement on both passes may cause OOM on T4 GPU (Sequential Mode). Suggest using ffmpeg-dsp for one pass.\")\n",
    "\n",
    "# Helpers\n",
    "def build_ffmpeg_filters(amplify, loudnorm, compress, highpass):\n",
    "    \"\"\"Combine selected FFmpeg filters into comma-separated string.\"\"\"\n",
    "    filters = []\n",
    "    if amplify: filters.append(\"amplify\")\n",
    "    if loudnorm: filters.append(\"loudnorm\")\n",
    "    if compress: filters.append(\"compress\")\n",
    "    if highpass: filters.append(\"highpass\")\n",
    "    return \",\".join(filters) if filters else None\n",
    "\n",
    "def map_value(val):\n",
    "    return None if val == \"automatic\" else val\n",
    "\n",
    "def map_segmenter(val):\n",
    "    return \"none\" if val == \"none\" else map_value(val)\n",
    "\n",
    "# Unified Config Construction\n",
    "WHISPERJAV_CONFIG = {\n",
    "    'pass1_pipeline': pass1_quality,\n",
    "    'pass1_sensitivity': pass1_sensitivity,\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter),\n",
    "    'pass1_model': model_map[pass1_model],\n",
    "    'pass2_pipeline': pass2_quality,\n",
    "    'pass2_sensitivity': pass2_sensitivity,\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter),\n",
    "    'pass2_model': model_map[pass2_model],\n",
    "    'merge_strategy': combine_map[merge_method],\n",
    "    'folder_name': folder_name,\n",
    "    'subtitle_language': language_map[subtitle_language],\n",
    "    'language': spoken_language_map[spoken_language],\n",
    "    'translation_service': translation_service,\n",
    "    'api_key': api_key,\n",
    "    'translation_style': tone_map[translation_style],\n",
    "    'opening_credit': opening_credit,\n",
    "    'closing_credit': closing_credit,\n",
    "    'auto_disconnect': auto_disconnect,\n",
    "    # Compatibility checks for Step 2\n",
    "    '_pass1_quality': pass1_quality,\n",
    "    '_pass1_sensitivity': pass1_sensitivity,\n",
    "    '_pass1_speech_segmenter': pass1_speech_segmenter,\n",
    "    '_pass1_model': pass1_model,\n",
    "    '_pass2_quality': pass2_quality,\n",
    "    '_pass2_sensitivity': pass2_sensitivity,\n",
    "    '_pass2_speech_segmenter': pass2_speech_segmenter,\n",
    "    '_pass2_model': pass2_model,\n",
    "    '_merge_method': merge_method,\n",
    "    '_subtitle_language': subtitle_language,\n",
    "    '_translation_style': translation_style,\n",
    "}\n",
    "\n",
    "WHISPERJAV_EXPERT_CONFIG = {\n",
    "    # Pass 1 Expert\n",
    "    'pass1_scene_detector': map_value(pass1_scene_detector),\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter), # Now unified\n",
    "    'pass1_speech_enhancer': None if pass1_speech_enhancer == \"none\" else pass1_speech_enhancer,\n",
    "    'pass1_ffmpeg_filters': build_ffmpeg_filters(pass1_ffmpeg_amplify, pass1_ffmpeg_loudnorm, pass1_ffmpeg_compress, pass1_ffmpeg_highpass) if pass1_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    # Pass 2 Expert\n",
    "    'pass2_scene_detector': map_value(pass2_scene_detector),\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter), # Now unified\n",
    "    'pass2_speech_enhancer': None if pass2_speech_enhancer == \"none\" else pass2_speech_enhancer,\n",
    "    'pass2_ffmpeg_filters': build_ffmpeg_filters(pass2_ffmpeg_amplify, pass2_ffmpeg_loudnorm, pass2_ffmpeg_compress, pass2_ffmpeg_highpass) if pass2_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    # Display helpers\n",
    "    '_pass1_scene_detector': pass1_scene_detector,\n",
    "    '_pass1_speech_enhancer': pass1_speech_enhancer,\n",
    "    '_pass2_scene_detector': pass2_scene_detector,\n",
    "    '_pass2_speech_enhancer': pass2_speech_enhancer,\n",
    "}\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display warnings\n",
    "for warning in warnings_list:\n",
    "    display(HTML(f'<div style=\"padding:6px 10px;background:#fef9c3;border-radius:4px;font-size:10px;margin-bottom:4px\"><b>âš ï¸ Auto-corrected:</b> {warning}</div>'))\n",
    "\n",
    "# Build status display\n",
    "p1_info = f\"{pass1_quality}\"\n",
    "if pass1_speech_segmenter != \"automatic\":\n",
    "    p1_info += f\"/{pass1_speech_segmenter}\"\n",
    "if pass1_model != \"automatic\":\n",
    "    p1_info += f\"/{pass1_model}\"\n",
    "\n",
    "p2_info = f\"{pass2_quality}\"\n",
    "if pass2_speech_segmenter != \"automatic\":\n",
    "    p2_info += f\"/{pass2_speech_segmenter}\"\n",
    "if pass2_model != \"automatic\":\n",
    "    p2_info += f\"/{pass2_model}\"\n",
    "\n",
    "display(HTML(f'<div style=\"padding:10px;background:#e0f2fe;border-radius:4px;font-size:11px\">'\n",
    "             f'<b>Parallel Configuration Loaded</b><br>'\n",
    "             f'Pass 1: {p1_info} | Pass 2: {p2_info}<br>'\n",
    "             f'Merge: {merge_method} | Folder: {folder_name} | Language: {spoken_language}'\n",
    "             f'</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbcce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 2: Setup & Environment (Run Once) { display-mode: \"form\" }\n",
    "#@markdown - **Fails Fast** if GPU or Internet is missing.\n",
    "#@markdown - Installs **System Tools** (FFmpeg, libc++) and **Python Libraries** (WhisperJAV, VADs).\n",
    "#@markdown - Prepares the environment for all subsequent steps.\n",
    "\n",
    "import importlib.util\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "FAIL_FAST = True\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'â”€'*40}\\n{title}\\n{'â”€'*40}\")\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n",
    "\n",
    "def must(condition, msg):\n",
    "    if not condition:\n",
    "        if FAIL_FAST:\n",
    "            raise RuntimeError(f\"SETUP FAILED: {msg}\")\n",
    "        print(f\"WARN: {msg}\")\n",
    "\n",
    "def run_shell(name, cmd):\n",
    "    \"\"\"Run a shell command (apt, etc).\"\"\"\n",
    "    print(f\"... installing {name}\")\n",
    "    r = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if r.returncode != 0:\n",
    "        print((r.stderr or r.stdout or \"\")[-2000:])\n",
    "        raise RuntimeError(f\"Install failed: {name}\")\n",
    "    status(f\"Installed {name}\")\n",
    "\n",
    "def run_pip(name, packages):\n",
    "    \"\"\"Run pip install safely (avoiding shell injection).\"\"\"\n",
    "    print(f\"... installing {name}\")\n",
    "    # cmd: python -m pip install -q --upgrade [packages...]\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages\n",
    "    r = subprocess.run(cmd, check=False, text=True, capture_output=True)\n",
    "    if r.returncode != 0:\n",
    "        print(f\"--- pip stderr for {name} ---\")\n",
    "        print((r.stderr or r.stdout or \"\")[-2000:])\n",
    "        raise RuntimeError(f\"Pip Install failed: {name}\")\n",
    "    status(f\"Installed {name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. PRE-FLIGHT CHECKS (Fail Fast)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"PRE-FLIGHT CHECKS\")\n",
    "\n",
    "# Detect Platform\n",
    "if \"google.colab\" in sys.modules:\n",
    "    PLATFORM = \"colab\"\n",
    "elif os.path.exists(\"/kaggle\"):\n",
    "    PLATFORM = \"kaggle\"\n",
    "else:\n",
    "    PLATFORM = \"local\"\n",
    "print(f\"Platform: {PLATFORM.upper()}\")\n",
    "print(f\"Python:   {sys.executable} ({sys.version.split()[0]})\")\n",
    "\n",
    "# Check GPU\n",
    "gpu_check = subprocess.run(\"nvidia-smi --query-gpu=name --format=csv,noheader\", shell=True, capture_output=True, text=True)\n",
    "must(gpu_check.returncode == 0 and bool(gpu_check.stdout.strip()), \"No GPU detected. Switch runtime to GPU.\")\n",
    "gpus = [line.strip() for line in gpu_check.stdout.splitlines() if line.strip()]\n",
    "status(f\"GPU(s) Detected: {len(gpus)} ({', '.join(gpus)})\")\n",
    "\n",
    "# Check Internet (Required for install)\n",
    "try:\n",
    "    import socket\n",
    "    socket.create_connection((\"www.google.com\", 80), timeout=2.0).close()\n",
    "    status(\"Internet reachable\")\n",
    "except OSError:\n",
    "    must(False, \"Internet disabled/unreachable. Cannot install dependencies.\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. INSTALLATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"INSTALLING DEPENDENCIES (3-5 min)\")\n",
    "install_start = time.time()\n",
    "\n",
    "# Determine sudo usage\n",
    "prefix = \"\"\n",
    "if shutil.which(\"sudo\") and not (hasattr(os, \"geteuid\") and os.geteuid() == 0):\n",
    "    prefix = \"sudo \"\n",
    "\n",
    "# A. System Layer (APT)\n",
    "# Unconditional: libraries for Audio (portaudio), Video (ffmpeg), and VAD (libc++)\n",
    "sys_pkgs = \"ffmpeg portaudio19-dev libc++1 libc++abi1\"\n",
    "run_shell(\"System Tools (apt)\", f\"{prefix}apt-get update -qq && {prefix}apt-get install -y -qq {sys_pkgs}\")\n",
    "\n",
    "# B. Core Acceleration Layer (Pip)\n",
    "# Upgrade pip first\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\"], check=False)\n",
    "\n",
    "# Only install heavy/complex libs here. Let WhisperJAV pull the rest.\n",
    "core_libs = [\n",
    "    # Basic Utils\n",
    "    \"tqdm\", \"numba\", \"tiktoken\", \"soundfile\", \"auditok\", \"requests\", \"colorama\", \"regex\",\n",
    "    \"numpy>=2.0\", \"scipy>=1.10.1\", \"librosa>=0.11.0\",\n",
    "    # ML Stack (Pre-install to ensure GPU versions/cache hits)\n",
    "    \"faster-whisper>=1.1.0\", \"transformers\", \"optimum\", \"accelerate\", \"huggingface-hub>=0.25.0\",\n",
    "    # Specific VADs (Binary wheels)\n",
    "    \"ten-vad\", \"silero-vad>=6.0\", \"pydub\",\n",
    "    # Enhancer bases\n",
    "    \"modelscope>=1.20\", \"onnxruntime>=1.16.0\"\n",
    "]\n",
    "run_pip(\"Core Acceleration Libs\", core_libs)\n",
    "\n",
    "# C. Application Layer (Git)\n",
    "# These will auto-resolve dependencies like pydantic, pysubtrans, etc.\n",
    "git_pkgs = [\n",
    "    (\"ffmpeg-python\", \"git+https://github.com/kkroening/ffmpeg-python.git\"),\n",
    "    (\"Whisper\", \"git+https://github.com/openai/whisper.git@main\"),\n",
    "    (\"Stable-TS\", \"git+https://github.com/meizhong986/stable-ts-fix-setup.git@main\"),\n",
    "    (\"ClearVoice\", \"git+https://github.com/meizhong986/ClearerVoice-Studio.git#subdirectory=clearvoice\"),\n",
    "    (\"WhisperJAV\", \"git+https://github.com/meizhong986/WhisperJAV.git@main\"),\n",
    "]\n",
    "\n",
    "for name, url in git_pkgs:\n",
    "    run_pip(name, [\"--no-deps\", url])\n",
    "\n",
    "status(f\"Installation Complete ({time.time() - install_start:.0f}s)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. VERIFICATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"VERIFICATION\")\n",
    "\n",
    "# Verify Import\n",
    "try:\n",
    "    import whisperjav\n",
    "    status(f\"WhisperJAV {whisperjav.__version__} Ready\")\n",
    "except ImportError as e:\n",
    "    raise RuntimeError(f\"Installation successful but import failed: {e}\")\n",
    "\n",
    "# Verify TEN/Libc++ (Common Failure Point)\n",
    "try:\n",
    "    import ten_vad\n",
    "    status(\"TEN VAD Ready\")\n",
    "except ImportError:\n",
    "    status(\"TEN VAD Warning (Import failed)\", False)\n",
    "\n",
    "# Stamp Success\n",
    "WHISPERJAV_SETUP_COMPLETE = {\n",
    "    \"timestamp\": time.time(),\n",
    "    \"platform\": PLATFORM,\n",
    "    \"gpu_count\": len(gpus)\n",
    "}\n",
    "print(\"\\nâœ“ Environment Ready. Go to Step 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 3: Execution (Transcribe) { display-mode: \"form\" }\n",
    "#@markdown - Auto-detects **Files** (Kaggle Dataset or Colab Drive).\n",
    "#@markdown - Auto-detects **Parallel** (2x GPU) or **Sequential** mode.\n",
    "#@markdown - Runs the configured WhisperJAV pipeline.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import HTML, FileLink, display\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CHECKS & PREP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if \"WHISPERJAV_SETUP_COMPLETE\" not in globals():\n",
    "    display(HTML('<div style=\"background:#fee2e2;color:#991b1b;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Setup Incomplete</b><br>Please run <b>Step 2: Setup</b> first.</div>'))\n",
    "    raise RuntimeError(\"Step 2 required\")\n",
    "\n",
    "if \"WHISPERJAV_CONFIG\" not in globals():\n",
    "    display(HTML('<div style=\"background:#fee2e2;color:#991b1b;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Config Missing</b><br>Please run <b>Step 1: Configuration</b> first.</div>'))\n",
    "    raise RuntimeError(\"Step 1 required\")\n",
    "\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "expert = globals().get(\"WHISPERJAV_EXPERT_CONFIG\", {})\n",
    "PLATFORM = WHISPERJAV_SETUP_COMPLETE[\"platform\"]\n",
    "PARALLEL_MODE = WHISPERJAV_SETUP_COMPLETE[\"gpu_count\"] >= 2\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# I/O SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"Mode: {'PARALLEL (2x GPU)' if PARALLEL_MODE else 'SEQUENTIAL (Ensemble)'}\")\n",
    "\n",
    "if PLATFORM == \"colab\":\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=False)\n",
    "    input_dir = Path(\"/content/drive/MyDrive\") / cfg[\"folder_name\"]\n",
    "    output_dir = input_dir\n",
    "    input_dir.mkdir(parents=True, exist_ok=True)\n",
    "elif PLATFORM == \"kaggle\":\n",
    "    # Search for video inputs\n",
    "    video_types = {\".mp4\", \".mkv\", \".avi\", \".mov\", \".wmv\", \".webm\"}\n",
    "    input_dir = None\n",
    "    for p in [Path(f\"/kaggle/input/{cfg['folder_name']}\"), Path(\"/kaggle/input\")]:\n",
    "        if p.exists() and any(f.suffix.lower() in video_types for f in p.rglob(\"*\")):\n",
    "            input_dir = p\n",
    "            break\n",
    "    if not input_dir:\n",
    "        input_dir = Path(\"/kaggle/input\")\n",
    "        print(\"WARN: No specific input folder found. Scanning root /kaggle/input.\")\n",
    "    \n",
    "    output_dir = Path(f\"/kaggle/working/{cfg['folder_name']}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    os.environ[\"TMPDIR\"] = \"/kaggle/working/temp\" # Avoid RAM disk overflow\n",
    "else:\n",
    "    input_dir = Path(cfg[\"folder_name\"]).absolute()\n",
    "    output_dir = Path(f\"{cfg['folder_name']}_output\").absolute()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "status(f\"Input: {input_dir}\")\n",
    "status(f\"Output: {output_dir}\")\n",
    "WHISPERJAV_OUTPUT_DIR = output_dir # Export for Step 4\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUTION LOGIC\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "media_files = sorted([p for p in input_dir.rglob(\"*\") if p.suffix.lower() in {\".mp4\", \".mkv\", \".avi\",\".mov\",\".wmv\",\".flv\",\".webm\",\".m3v\",\".mp3\",\".wav\",\".flac\"}])\n",
    "if not media_files:\n",
    "    raise RuntimeError(f\"No media files found in {input_dir}\")\n",
    "\n",
    "logs_dir = output_dir / \"logs\"\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "final_outputs = []\n",
    "\n",
    "def build_cmd(video_path, out_path, pass_cfg_num=None):\n",
    "    \"\"\"Builds the CLI command. If pass_cfg_num is set, builds a single-pass command (for parallel).\"\"\"\n",
    "    cmd = [sys.executable, \"-m\", \"whisperjav.main\", str(video_path), \"--output-dir\", str(out_path)]\n",
    "    cmd += [\"--subs-language\", \"direct-to-english\" if cfg[\"subtitle_language\"] == \"direct-to-english\" else \"native\"]\n",
    "    if cfg.get(\"language\"): cmd += [\"--language\", cfg[\"language\"]]\n",
    "    \n",
    "    # Helper to clean args\n",
    "    def add_arg(name, val):\n",
    "        if val and val != \"none\": cmd.extend([name, str(val)])\n",
    "\n",
    "    if pass_cfg_num:\n",
    "        # Single Pass Mode (Parallel Worker)\n",
    "        p = f\"pass{pass_cfg_num}\"\n",
    "        cmd += [\"--mode\", cfg[f\"{p}_pipeline\"], \"--sensitivity\", cfg[f\"{p}_sensitivity\"]]\n",
    "        add_arg(\"--model\", cfg.get(f\"{p}_model\"))\n",
    "        add_arg(\"--speech-segmenter\", cfg.get(f\"{p}_speech_segmenter\"))\n",
    "        # Single pass expert args (enhancers/scene) would be mapped here if supported by main CLI in single mode\n",
    "    else:\n",
    "        # Ensemble Mode (Sequential/Full)\n",
    "        cmd += [\"--ensemble\", \"--merge-strategy\", cfg[\"merge_strategy\"]]\n",
    "        for p in [\"pass1\", \"pass2\"]:\n",
    "            cmd += [f\"--{p}-pipeline\", cfg[f\"{p}_pipeline\"], f\"--{p}-sensitivity\", cfg[f\"{p}_sensitivity\"]]\n",
    "            add_arg(f\"--{p}-model\", cfg.get(f\"{p}_model\"))\n",
    "            add_arg(f\"--{p}-speech-segmenter\", cfg.get(f\"{p}_speech_segmenter\"))\n",
    "            # Expert\n",
    "            add_arg(f\"--{p}-scene-detector\", expert.get(f\"{p}_scene_detector\"))\n",
    "            enh = expert.get(f\"{p}_speech_enhancer\")\n",
    "            if enh == \"ffmpeg-dsp\": enh = f\"ffmpeg-dsp:{expert.get(f'{p}_ffmpeg_filters', 'amplify')}\"\n",
    "            add_arg(f\"--{p}-speech-enhancer\", enh)\n",
    "            \n",
    "    return cmd\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"\\nProcessing {len(media_files)} files...\")\n",
    "\n",
    "if PARALLEL_MODE:\n",
    "    # 2-GPU Parallel Execution: Split Passes, Then Merge\n",
    "    from whisperjav.ensemble.merge import MergeEngine\n",
    "    merger = MergeEngine()\n",
    "    \n",
    "    for vid in media_files:\n",
    "        print(f\"\\n[Parallel] Processing: {vid.name}\")\n",
    "        base = output_dir / vid.stem\n",
    "        p1_dir, p2_dir = base / \"pass1\", base / \"pass2\"\n",
    "        p1_dir.mkdir(parents=True, exist_ok=True)\n",
    "        p2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        def run_pass(num, gpu, out):\n",
    "            env = os.environ.copy()\n",
    "            env[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "            log = logs_dir / f\"{vid.stem}_pass{num}.log\"\n",
    "            with log.open(\"w\") as f:\n",
    "                c = build_cmd(vid, out, pass_cfg_num=num)\n",
    "                r = subprocess.run(c, env=env, stdout=f, stderr=subprocess.STDOUT, text=True)\n",
    "            return r.returncode == 0, list(out.glob(\"*.srt\"))[0] if list(out.glob(\"*.srt\")) else None\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=2) as exc:\n",
    "            f1 = exc.submit(run_pass, 1, 0, p1_dir)\n",
    "            f2 = exc.submit(run_pass, 2, 1, p2_dir)\n",
    "            ok1, srt1 = f1.result()\n",
    "            ok2, srt2 = f2.result()\n",
    "\n",
    "        if ok1 and srt1 and ok2 and srt2:\n",
    "            merged = output_dir / srt1.name\n",
    "            merger.merge(srt1, srt2, merged, strategy=cfg[\"merge_strategy\"])\n",
    "            status(f\"Merged: {merged.name}\")\n",
    "            final_outputs.append(merged)\n",
    "        elif (ok1 and srt1) or (ok2 and srt2):\n",
    "            winner = srt1 if (ok1 and srt1) else srt2\n",
    "            dest = output_dir / winner.name\n",
    "            shutil.copy(winner, dest)\n",
    "            status(f\"Partial Success (One pass failed): {dest.name}\")\n",
    "            final_outputs.append(dest)\n",
    "        else:\n",
    "            status(f\"Failed: {vid.name}\", False)\n",
    "\n",
    "else:\n",
    "    # Sequential Execution (Colab/Single-GPU)\n",
    "    # Run bulk command on directory\n",
    "    cmd = build_cmd(input_dir, output_dir)\n",
    "    log_path = logs_dir / \"whisperjav_exec.log\"\n",
    "    print(\"Running sequential ensemble...\")\n",
    "    with log_path.open(\"w\") as f:\n",
    "        rc = subprocess.run(cmd, stdout=f, stderr=subprocess.STDOUT)\n",
    "    \n",
    "    new_srts = list(output_dir.glob(\"*.srt\")) # Logic simplification: grab all SRTs in output\n",
    "    if rc.returncode == 0 and new_srts:\n",
    "        status(f\"Processed {len(new_srts)} files\")\n",
    "        final_outputs = new_srts\n",
    "    else:\n",
    "        status(\"Execution failed or no SRTs generated. See logs.\", False)\n",
    "\n",
    "WHISPERJAV_NEW_SRTS = final_outputs\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PACKAGING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if final_outputs:\n",
    "    zip_path = output_dir / f\"{cfg['folder_name']}_results.zip\"\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for f in output_dir.rglob(\"*\"):\n",
    "            if f.suffix in {\".srt\", \".json\", \".log\"}:\n",
    "                zf.write(f, f.relative_to(output_dir))\n",
    "    \n",
    "    print(f\"\\nğŸ“¦ Bundle created: {zip_path.name}\")\n",
    "    if PLATFORM == \"kaggle\":\n",
    "        display(FileLink(str(zip_path.relative_to(Path.cwd())), result_html_prefix=\"<b>â¬‡ Download Results: </b>\"))\n",
    "    elif PLATFORM == \"colab\":\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(str(zip_path))\n",
    "        except: pass\n",
    "\n",
    "print(f\"\\nTime: {(time.time()-start_time)/60:.1f} min\")\n",
    "print(\"Done. Run Step 4 for Translation if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 4: AI Translation (Optional) { display-mode: \"form\" }\n",
    "#@markdown - Translates result SRTs to English using LLMs (GPT, Claude, DeepSeek, etc.).\n",
    "#@markdown - Requires an API key (or Kaggle Secret).\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display, FileLink\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n",
    "\n",
    "# 1. Validation\n",
    "if \"WHISPERJAV_NEW_SRTS\" not in globals() or not WHISPERJAV_NEW_SRTS:\n",
    "    display(HTML('<div style=\"background:#f0f9ff;padding:10px;\"><b>â„¹ No Inputs</b><br>No new subtitles found from Step 3 to translate.</div>'))\n",
    "    raise RuntimeError(\"No input files\")\n",
    "\n",
    "if WHISPERJAV_CONFIG[\"subtitle_language\"] != \"llm\":\n",
    "    display(HTML('<div style=\"background:#f0f9ff;padding:10px;\"><b>â„¹ Translation Skipped</b><br>Select \"English (AI translate)\" in Step 1 to enable this.</div>'))\n",
    "    raise RuntimeError(\"Skipped by config\")\n",
    "\n",
    "# 2. API Key Setup\n",
    "service = WHISPERJAV_CONFIG[\"translation_service\"]\n",
    "user_key = WHISPERJAV_CONFIG.get(\"api_key\")\n",
    "final_key = None\n",
    "\n",
    "if user_key:\n",
    "    final_key = user_key\n",
    "elif os.path.exists(\"/kaggle\"):\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    try:\n",
    "        final_key = UserSecretsClient().get_secret(f\"{service.upper()}_API_KEY\")\n",
    "    except: pass\n",
    "\n",
    "if not final_key:\n",
    "    raise RuntimeError(f\"Missing API Key for {service}. Add to Config or Kaggle Secrets.\")\n",
    "\n",
    "# Set Env Var\n",
    "env_map = {\"deepseek\": \"DEEPSEEK_API_KEY\", \"openrouter\": \"OPENROUTER_API_KEY\", \"gpt\":\"OPENAI_API_KEY\", \"claude\":\"ANTHROPIC_API_KEY\", \"gemini\":\"GEMINI_API_KEY\"}\n",
    "os.environ[env_map.get(service, \"API_KEY\")] = final_key\n",
    "\n",
    "# 3. Execution\n",
    "print(f\"Translating {len(WHISPERJAV_NEW_SRTS)} files with {service}...\")\n",
    "translated = []\n",
    "\n",
    "for srt in WHISPERJAV_NEW_SRTS:\n",
    "    cmd = [sys.executable, \"-m\", \"whisperjav.translate.cli\", \"-i\", str(srt), \"--provider\", service, \"--tone\", WHISPERJAV_CONFIG[\"translation_style\"]]\n",
    "    r = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if r.returncode == 0 and r.stdout.strip():\n",
    "        out_file = Path(r.stdout.strip())\n",
    "        status(f\"Translated: {out_file.name}\")\n",
    "        translated.append(out_file)\n",
    "    else:\n",
    "        status(f\"Failed: {srt.name} ({r.stderr[:200]})\", False)\n",
    "\n",
    "# 4. Bundle\n",
    "if translated:\n",
    "    out_dir = WHISPERJAV_OUTPUT_DIR\n",
    "    zip_path = out_dir / f\"translated_{service}.zip\"\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for t in translated: zf.write(t, t.name)\n",
    "        \n",
    "    print(f\"\\nğŸ“¦ Translations Bundle: {zip_path.name}\")\n",
    "    if os.path.exists(\"/kaggle\"):\n",
    "         display(FileLink(str(zip_path.relative_to(Path.cwd())), result_html_prefix=\"<b>â¬‡ Download Translations: </b>\"))\n",
    "    elif \"google.colab\" in sys.modules:\n",
    "        from google.colab import files\n",
    "        files.download(str(zip_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
