{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>\n",
    "\n",
    "# WhisperJAV Ensemble Dual-GPU Edition (v1.8.2)\n",
    "\n",
    "**Universal Parallel Workflow**\n",
    "\n",
    "| Platform | Logic | Storage |\n",
    "|----------|-------|---------|\n",
    "| **Kaggle** | **Parallel** (2x T4) | **Input**: `/kaggle/input` (Dataset) <br> **Output**: `/kaggle/working` (Artifacts) |\n",
    "| **Colab** | **Sequential** (1x GPU) | **Input/Output**: Google Drive |\n",
    "\n",
    "---\n",
    "### **Workflow**\n",
    "1. **Configure**: Select your settings, models, and audio preferences.\n",
    "2. **Setup**: Installs dependencies and prepares the environment (**Run Once**).\n",
    "3. **Transcribe**: Processes your video files using the configured settings.\n",
    "4. **Translate**: (Optional) Uses AI to translate subtitles to English.\n",
    "\n",
    "<small><i>Tip: Select your Dataset in Kaggle, then use \"Run All\". The notebook is designed to Fail Fast if resources are missing.</i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 1: Expert Configuration { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ## ğŸ“ Files & Output\n",
    "folder_name = \"WhisperJAV\" #@param {type:\"string\"}\n",
    "subtitle_language = \"Japanese\" #@param [\"Japanese\", \"English (auto-translate)\", \"English (AI translate)\"]\n",
    "spoken_language = \"Japanese\" #@param [\"Japanese\", \"Chinese\", \"English\", \"Korean\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 1ï¸âƒ£ Pass 1 Configuration (GPU 0)\n",
    "pass1_quality = \"balanced\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass1_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass1_model = \"large-v2\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 1)**\n",
    "pass1_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass1_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass1_speech_enhancer = \"none\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "#@markdown <font size=\"1\">auditok=energy (fast), silero=VAD, semantic=texture (complex audio) | enhancer: ffmpeg-dsp(no GPU), clearvoice(48k), bs-roformer(vocal)</font>\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 1)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass1_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 2ï¸âƒ£ Pass 2 Configuration (GPU 1)\n",
    "pass2_quality = \"fidelity\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass2_sensitivity = \"balanced\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass2_model = \"turbo\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 2)**\n",
    "pass2_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass2_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass2_speech_enhancer = \"ffmpeg-dsp\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 2)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass2_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ”— Merge Strategy\n",
    "merge_method = \"prefer first pass\" #@param [\"automatic\", \"keep all\", \"prefer first pass\", \"prefer second pass\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ¤– AI Translation *(if selected)*\n",
    "translation_service = \"local\" #@param [\"local\", \"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\", \"glm\", \"groq\"]\n",
    "local_model = \"gemma-9b\" #@param [\"gemma-9b\", \"llama-8b\", \"llama-3b\", \"auto\"]\n",
    "#@markdown <font size=\"1\">local: Free, runs on GPU. gemma-9b (8GB+ VRAM), llama-8b (6GB+), llama-3b (3GB+). Cloud providers require API key.</font>\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "translation_style = \"standard\" #@param [\"standard\", \"explicit\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## âš™ï¸ Session\n",
    "opening_credit = \"\" #@param {type:\"string\"}\n",
    "closing_credit = \"Subs by WhisperJAV\" #@param {type:\"string\"}\n",
    "auto_disconnect = True #@param {type:\"boolean\"}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION LOGIC\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Detect Platform Early (needed for venv paths)\n",
    "if \"google.colab\" in sys.modules:\n",
    "    PLATFORM = \"colab\"\n",
    "elif os.path.exists(\"/kaggle\"):\n",
    "    PLATFORM = \"kaggle\"\n",
    "else:\n",
    "    PLATFORM = \"local\"\n",
    "\n",
    "# Venv paths for Colab (isolated environment to avoid numpy conflicts)\n",
    "# Kaggle uses direct installation (no venv needed - cleaner base environment)\n",
    "if PLATFORM == \"colab\":\n",
    "    VENV_PATH = \"/content/whisperjav_env\"\n",
    "    WHISPERJAV_CMD = f\"{VENV_PATH}/bin/whisperjav\"\n",
    "    WHISPERJAV_TRANSLATE_CMD = f\"{VENV_PATH}/bin/whisperjav-translate\"\n",
    "    VENV_PYTHON = f\"{VENV_PATH}/bin/python\"\n",
    "else:\n",
    "    VENV_PATH = None\n",
    "    WHISPERJAV_CMD = None  # Will use sys.executable -m whisperjav.main\n",
    "    WHISPERJAV_TRANSLATE_CMD = None  # Will use sys.executable -m whisperjav.translate.cli\n",
    "    VENV_PYTHON = None\n",
    "\n",
    "# Mapping dictionaries\n",
    "combine_map = {\"automatic\": \"smart_merge\", \"keep all\": \"full_merge\",\n",
    "               \"prefer first pass\": \"pass1_primary\", \"prefer second pass\": \"pass2_primary\"}\n",
    "language_map = {\"Japanese\": \"native\", \"English (auto-translate)\": \"direct-to-english\",\n",
    "                \"English (AI translate)\": \"llm\"}\n",
    "tone_map = {\"standard\": \"standard\", \"explicit\": \"pornify\"}\n",
    "spoken_language_map = {\"Japanese\": \"japanese\", \"Chinese\": \"chinese\", \"English\": \"english\", \"Korean\": \"korean\"}\n",
    "\n",
    "# Model mapping (None = use pipeline default)\n",
    "model_map = {\n",
    "    \"automatic\": None,\n",
    "    \"large-v2\": \"large-v2\",\n",
    "    \"large-v3\": \"large-v3\",\n",
    "    \"turbo\": \"turbo\",\n",
    "    \"kotoba-bilingual\": \"kotoba-tech/kotoba-whisper-bilingual-v1.0\",\n",
    "    \"kotoba-v2.0\": \"kotoba-tech/kotoba-whisper-v2.0\",\n",
    "    \"kotoba-v2.1\": \"kotoba-tech/kotoba-whisper-v2.1\",\n",
    "    \"kotoba-v2.2\": \"kotoba-tech/kotoba-whisper-v2.2\"\n",
    "}\n",
    "\n",
    "# Define model compatibility:\n",
    "KOTOBA_MODELS = {\"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"}\n",
    "LEGACY_PIPELINES = {\"faster\", \"fast\", \"balanced\", \"fidelity\"}\n",
    "\n",
    "# Auto-correct incompatible model-pipeline combinations\n",
    "warnings_list = []\n",
    "\n",
    "# Check Pass 1 compatibility\n",
    "if pass1_model in KOTOBA_MODELS and pass1_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 1: {pass1_model} requires 'transformers' pipeline. Auto-correcting from '{pass1_quality}' to 'transformers'.\")\n",
    "    pass1_quality = \"transformers\"\n",
    "\n",
    "# Check Pass 2 compatibility\n",
    "if pass2_model in KOTOBA_MODELS and pass2_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 2: {pass2_model} requires 'transformers' pipeline. Auto-correcting from '{pass2_quality}' to 'transformers'.\")\n",
    "    pass2_quality = \"transformers\"\n",
    "\n",
    "# Memory warning\n",
    "heavy_enhancers = {'clearvoice', 'bs-roformer', 'zipenhancer'}\n",
    "if pass1_speech_enhancer in heavy_enhancers and pass2_speech_enhancer in heavy_enhancers:\n",
    "    warnings_list.append(\"Using GPU-based enhancement on both passes may cause OOM on T4 GPU (Sequential Mode). Suggest using ffmpeg-dsp for one pass.\")\n",
    "\n",
    "# Helpers\n",
    "def build_ffmpeg_filters(amplify, loudnorm, compress, highpass):\n",
    "    \"\"\"Combine selected FFmpeg filters into comma-separated string.\"\"\"\n",
    "    filters = []\n",
    "    if amplify: filters.append(\"amplify\")\n",
    "    if loudnorm: filters.append(\"loudnorm\")\n",
    "    if compress: filters.append(\"compress\")\n",
    "    if highpass: filters.append(\"highpass\")\n",
    "    return \",\".join(filters) if filters else None\n",
    "\n",
    "def map_value(val):\n",
    "    return None if val == \"automatic\" else val\n",
    "\n",
    "def map_segmenter(val):\n",
    "    return \"none\" if val == \"none\" else map_value(val)\n",
    "\n",
    "# Unified Config Construction\n",
    "WHISPERJAV_CONFIG = {\n",
    "    'pass1_pipeline': pass1_quality,\n",
    "    'pass1_sensitivity': pass1_sensitivity,\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter),\n",
    "    'pass1_model': model_map[pass1_model],\n",
    "    # Expert fields merged directly\n",
    "    'pass1_scene_detector': map_value(pass1_scene_detector),\n",
    "    'pass1_speech_enhancer': None if pass1_speech_enhancer == \"none\" else pass1_speech_enhancer,\n",
    "    'pass1_ffmpeg_filters': build_ffmpeg_filters(pass1_ffmpeg_amplify, pass1_ffmpeg_loudnorm, pass1_ffmpeg_compress, pass1_ffmpeg_highpass) if pass1_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    \n",
    "    'pass2_pipeline': pass2_quality,\n",
    "    'pass2_sensitivity': pass2_sensitivity,\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter),\n",
    "    'pass2_model': model_map[pass2_model],\n",
    "    # Expert fields merged directly\n",
    "    'pass2_scene_detector': map_value(pass2_scene_detector),\n",
    "    'pass2_speech_enhancer': None if pass2_speech_enhancer == \"none\" else pass2_speech_enhancer,\n",
    "    'pass2_ffmpeg_filters': build_ffmpeg_filters(pass2_ffmpeg_amplify, pass2_ffmpeg_loudnorm, pass2_ffmpeg_compress, pass2_ffmpeg_highpass) if pass2_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    \n",
    "    'merge_strategy': combine_map[merge_method],\n",
    "    'folder_name': folder_name,\n",
    "    'subtitle_language': language_map[subtitle_language],\n",
    "    'language': spoken_language_map[spoken_language],\n",
    "    'translation_service': translation_service,\n",
    "    'local_model': local_model,\n",
    "    'api_key': api_key,\n",
    "    'translation_style': tone_map[translation_style],\n",
    "    'opening_credit': opening_credit,\n",
    "    'closing_credit': closing_credit,\n",
    "    'auto_disconnect': auto_disconnect,\n",
    "    # Platform and venv info\n",
    "    'platform': PLATFORM,\n",
    "    'venv_path': VENV_PATH,\n",
    "    'whisperjav_cmd': WHISPERJAV_CMD,\n",
    "    'whisperjav_translate_cmd': WHISPERJAV_TRANSLATE_CMD,\n",
    "    'venv_python': VENV_PYTHON,\n",
    "    # Compatibility checks for Step 2\n",
    "    '_pass1_quality': pass1_quality,\n",
    "    '_pass1_sensitivity': pass1_sensitivity,\n",
    "    '_pass1_speech_segmenter': pass1_speech_segmenter,\n",
    "    '_pass1_model': pass1_model,\n",
    "    '_pass2_quality': pass2_quality,\n",
    "    '_pass2_sensitivity': pass2_sensitivity,\n",
    "    '_pass2_speech_segmenter': pass2_speech_segmenter,\n",
    "    '_pass2_model': pass2_model,\n",
    "    '_merge_method': merge_method,\n",
    "    '_subtitle_language': subtitle_language,\n",
    "    '_translation_style': translation_style,\n",
    "}\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display warnings\n",
    "for warning in warnings_list:\n",
    "    display(HTML(f'<div style=\"padding:6px 10px;background:#fef9c3;border-radius:4px;font-size:10px;margin-bottom:4px\"><b>âš ï¸ Auto-corrected:</b> {warning}</div>'))\n",
    "\n",
    "# Build status display\n",
    "p1_info = f\"{pass1_quality}\"\n",
    "if pass1_speech_segmenter != \"automatic\":\n",
    "    p1_info += f\"/{pass1_speech_segmenter}\"\n",
    "if pass1_model != \"automatic\":\n",
    "    p1_info += f\"/{pass1_model}\"\n",
    "if pass1_scene_detector != \"automatic\":\n",
    "    p1_info += f\"/{pass1_scene_detector}\"\n",
    "\n",
    "p2_info = f\"{pass2_quality}\"\n",
    "if pass2_speech_segmenter != \"automatic\":\n",
    "    p2_info += f\"/{pass2_speech_segmenter}\"\n",
    "if pass2_model != \"automatic\":\n",
    "    p2_info += f\"/{pass2_model}\"\n",
    "if pass2_scene_detector != \"automatic\":\n",
    "    p2_info += f\"/{pass2_scene_detector}\"\n",
    "\n",
    "display(HTML(f'<div style=\"padding:10px;background:#e0f2fe;border-radius:4px;font-size:11px\">'\n",
    "             f'<b>Parallel Configuration Loaded</b><br>'\n",
    "             f'Platform: {PLATFORM.upper()} | Pass 1: {p1_info} | Pass 2: {p2_info}<br>'\n",
    "             f'Merge: {merge_method} | Folder: {folder_name} | Language: {spoken_language}'\n",
    "             f'</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbcce2",
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#@title Step 2: Setup & Environment (Run Once) { display-mode: \"form\" }\n",
    "#@markdown - **Fails Fast** if GPU or Internet is missing.\n",
    "#@markdown - **Colab**: Uses isolated venv via `install_colab.sh` (avoids numpy conflicts)\n",
    "#@markdown - **Kaggle**: Direct pip install with pinned versions (auto-fixes numpy 2.x conflict)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import socket\n",
    "from pathlib import Path\n",
    "\n",
    "# Fix matplotlib backend conflict\n",
    "os.environ['MPLBACKEND'] = 'Agg'\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'â”€'*40}\\n{title}\\n{'â”€'*40}\")\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n",
    "\n",
    "def must(condition, msg):\n",
    "    if not condition:\n",
    "        raise RuntimeError(f\"SETUP FAILED: {msg}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. PRE-FLIGHT CHECKS (Fail Fast)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"PRE-FLIGHT CHECKS\")\n",
    "\n",
    "# Get config from Step 1\n",
    "if \"WHISPERJAV_CONFIG\" not in globals():\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML('<div style=\"background:#fee2e2;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Run Step 1 First</b></div>'))\n",
    "    raise RuntimeError(\"Step 1 required\")\n",
    "\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "PLATFORM = cfg['platform']\n",
    "print(f\"Platform: {PLATFORM.upper()}\")\n",
    "print(f\"Python:   {sys.executable} ({sys.version.split()[0]})\")\n",
    "\n",
    "# Python version check - WhisperJAV requires Python 3.10-3.12\n",
    "py_version = sys.version_info\n",
    "if py_version >= (3, 13):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML('<div style=\"background:#fee2e2;padding:10px;border-radius:4px;\"><b>ğŸ›‘ Python 3.13+ Not Supported</b><br>WhisperJAV requires Python 3.10-3.12 (openai-whisper incompatible with 3.13+)</div>'))\n",
    "    raise RuntimeError(f\"Python {sys.version.split()[0]} not supported. Requires 3.10-3.12.\")\n",
    "elif py_version < (3, 10):\n",
    "    raise RuntimeError(f\"Python {sys.version.split()[0]} too old. Requires 3.10-3.12.\")\n",
    "status(f\"Python version OK ({sys.version.split()[0]})\")\n",
    "\n",
    "# Check GPU\n",
    "gpu_check = subprocess.run(\"nvidia-smi --query-gpu=name --format=csv,noheader\", shell=True, capture_output=True, text=True)\n",
    "must(gpu_check.returncode == 0 and bool(gpu_check.stdout.strip()), \"No GPU detected. Switch runtime to GPU.\")\n",
    "gpus = [line.strip() for line in gpu_check.stdout.splitlines() if line.strip()]\n",
    "status(f\"GPU(s) Detected: {len(gpus)} ({', '.join(gpus)})\")\n",
    "\n",
    "# Check Internet\n",
    "def check_internet():\n",
    "    endpoints = [(\"www.baidu.com\", 80), (\"www.google.com\", 80), (\"1.1.1.1\", 53)]\n",
    "    for host, port in endpoints:\n",
    "        try:\n",
    "            socket.create_connection((host, port), timeout=3.0).close()\n",
    "            return True\n",
    "        except OSError:\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "must(check_internet(), \"Internet disabled/unreachable. Cannot install dependencies.\")\n",
    "status(\"Internet reachable\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. INSTALLATION (Platform-specific)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"INSTALLING DEPENDENCIES\")\n",
    "install_start = time.time()\n",
    "\n",
    "if PLATFORM == \"colab\":\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # COLAB: Use install_colab.sh for isolated venv\n",
    "    # This avoids numpy 2.x conflicts with Colab's base environment\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    REPO_URL = \"https://github.com/meizhong986/WhisperJAV.git\"\n",
    "    REPO_PATH = \"/content/WhisperJAV\"\n",
    "    SCRIPT_PATH = f\"{REPO_PATH}/installer/install_colab.sh\"\n",
    "    VENV_PATH = cfg['venv_path']\n",
    "    \n",
    "    def run_installer():\n",
    "        \"\"\"Run install script with real-time output streaming.\"\"\"\n",
    "        env = {**os.environ, \"PATH\": f\"{os.environ.get('PATH', '')}:{os.path.expanduser('~/.local/bin')}\"}\n",
    "        process = subprocess.Popen(\n",
    "            [\"bash\", SCRIPT_PATH],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            bufsize=1,\n",
    "            text=True,\n",
    "            env=env\n",
    "        )\n",
    "        for line in iter(process.stdout.readline, ''):\n",
    "            print(line, end='', flush=True)\n",
    "        process.wait()\n",
    "        return process.returncode\n",
    "    \n",
    "    # Check if already installed\n",
    "    venv_python = cfg['venv_python']\n",
    "    if os.path.exists(venv_python):\n",
    "        check = subprocess.run([venv_python, \"-c\", \"import whisperjav\"], capture_output=True)\n",
    "        if check.returncode == 0:\n",
    "            status(\"WhisperJAV already installed (skipping)\")\n",
    "        else:\n",
    "            status(\"Existing venv corrupt, reinstalling...\")\n",
    "            subprocess.run([\"rm\", \"-rf\", VENV_PATH], capture_output=True)\n",
    "            if not os.path.exists(REPO_PATH):\n",
    "                subprocess.run([\"git\", \"clone\", REPO_URL, REPO_PATH], capture_output=True)\n",
    "            returncode = run_installer()\n",
    "            must(returncode == 0, \"Installation failed\")\n",
    "    else:\n",
    "        # Fresh install\n",
    "        print(\"Installing WhisperJAV (uv-accelerated)...\\n\")\n",
    "        sys.stdout.flush()\n",
    "        if not os.path.exists(REPO_PATH):\n",
    "            print(f\"Cloning {REPO_URL}...\")\n",
    "            result = subprocess.run([\"git\", \"clone\", REPO_URL, REPO_PATH], capture_output=True, text=True)\n",
    "            must(result.returncode == 0, f\"Clone failed: {result.stderr}\")\n",
    "\n",
    "        must(os.path.exists(SCRIPT_PATH), f\"Install script not found at {SCRIPT_PATH}\")\n",
    "        returncode = run_installer()\n",
    "        must(returncode == 0, \"Installation failed\")\n",
    "    \n",
    "    status(f\"Installation Complete ({time.time() - install_start:.0f}s)\")\n",
    "\n",
    "else:\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # KAGGLE: Direct pip install with fixed versions\n",
    "    # Kaggle has a cleaner base environment, so direct install works\n",
    "    # BUT: Kaggle pre-loads numpy 2.x into memory, requiring special handling\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # KAGGLE ENVIRONMENT SETUP\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Set up cache directories to avoid RAM disk overflow\n",
    "    kaggle_cache = Path(\"/kaggle/working/.cache\")\n",
    "    kaggle_cache.mkdir(parents=True, exist_ok=True)\n",
    "    kaggle_temp = Path(\"/kaggle/working/temp\")\n",
    "    kaggle_temp.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Set environment variables for HuggingFace and temp files\n",
    "    os.environ[\"HF_HOME\"] = str(kaggle_cache)\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = str(kaggle_cache / \"transformers\")\n",
    "    os.environ[\"TORCH_HOME\"] = str(kaggle_cache / \"torch\")\n",
    "    os.environ[\"TMPDIR\"] = str(kaggle_temp)\n",
    "    os.environ[\"TEMP\"] = str(kaggle_temp)\n",
    "    os.environ[\"TMP\"] = str(kaggle_temp)\n",
    "    status(f\"Cache directories configured: {kaggle_cache}\")\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # KAGGLE NUMPY 2.X CONFLICT DETECTION & FIX\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Kaggle pre-loads numpy 2.x into memory at kernel start.\n",
    "    # Even if we pip install numpy<2.0, the OLD version stays in memory.\n",
    "    # Solution: Detect, fix packages, then require kernel restart.\n",
    "    \n",
    "    import numpy as np\n",
    "    NUMPY_MAJOR = int(np.__version__.split('.')[0])\n",
    "    \n",
    "    if NUMPY_MAJOR >= 2:\n",
    "        from IPython.display import display, HTML\n",
    "        \n",
    "        print(\"âš ï¸  Kaggle has numpy 2.x pre-loaded in memory.\")\n",
    "        print(\"    This conflicts with numba which requires numpy<2.0.\")\n",
    "        print(\"\")\n",
    "        print(\"Fixing package versions...\")\n",
    "        \n",
    "        # Uninstall conflicting packages (they'll be reinstalled with correct versions)\n",
    "        conflict_pkgs = [\"numpy\", \"numba\", \"llvmlite\", \"scipy\"]\n",
    "        for pkg in conflict_pkgs:\n",
    "            subprocess.run(\n",
    "                [sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg],\n",
    "                capture_output=True\n",
    "            )\n",
    "        print(\"  âœ“ Removed conflicting packages\")\n",
    "        \n",
    "        # Install correct versions with --no-deps to avoid pulling in numpy 2.x\n",
    "        # These versions match our setup.py constraints\n",
    "        subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\",\n",
    "            \"numpy>=1.26.0,<2.0\",\n",
    "            \"numba>=0.58.0,<0.60.0\",\n",
    "            \"llvmlite>=0.41.0,<0.43.0\",\n",
    "            \"scipy>=1.10.1,<1.14\",\n",
    "            \"--no-deps\", \"--force-reinstall\", \"-q\"\n",
    "        ], check=True)\n",
    "        print(\"  âœ“ Installed compatible versions\")\n",
    "        \n",
    "        # Display restart instructions\n",
    "        print(\"\")\n",
    "        display(HTML('''\n",
    "        <div style=\"background:#fef3c7;border:2px solid #f59e0b;border-radius:8px;padding:16px;margin:10px 0;\">\n",
    "            <h3 style=\"margin:0 0 10px 0;color:#92400e;\">ğŸ”„ Kernel Restart Required</h3>\n",
    "            <p style=\"margin:0 0 10px 0;\">Package versions have been fixed on disk, but the old numpy 2.x is still loaded in memory.</p>\n",
    "            <p style=\"margin:0 0 10px 0;\"><b>To complete the fix:</b></p>\n",
    "            <ol style=\"margin:0 0 10px 0;\">\n",
    "                <li>Right-click this cell â†’ <b>\"Restart Session\"</b> (or use Session menu)</li>\n",
    "                <li>After restart, run <b>Step 1</b> again, then <b>Step 2</b></li>\n",
    "                <li>Step 2 will detect numpy 1.x and proceed normally</li>\n",
    "            </ol>\n",
    "            <p style=\"margin:0;color:#92400e;\"><b>This is a one-time fix. After restart, \"Run All\" will work.</b></p>\n",
    "        </div>\n",
    "        '''))\n",
    "        \n",
    "        raise RuntimeError(\"Kernel restart required - see instructions above\")\n",
    "    else:\n",
    "        status(f\"NumPy {np.__version__} (compatible - no restart needed)\")\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # NORMAL KAGGLE INSTALLATION (numpy 1.x)\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    def run_shell(name, cmd):\n",
    "        \"\"\"Run a shell command with timeout.\"\"\"\n",
    "        print(f\"... installing {name}\")\n",
    "        try:\n",
    "            r = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=600)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            raise RuntimeError(f\"Install timed out (10m): {name}\")\n",
    "        if r.returncode != 0:\n",
    "            print((r.stderr or r.stdout or \"\")[-2000:])\n",
    "            raise RuntimeError(f\"Install failed: {name}\")\n",
    "        status(f\"Installed {name}\")\n",
    "\n",
    "    def run_pip(name, packages, no_deps=False):\n",
    "        \"\"\"Run pip install with timeout.\"\"\"\n",
    "        print(f\"... installing {name}\")\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"]\n",
    "        if no_deps:\n",
    "            cmd.append(\"--no-deps\")\n",
    "        cmd.extend(packages)\n",
    "        try:\n",
    "            r = subprocess.run(cmd, check=False, text=True, capture_output=True, timeout=600)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            raise RuntimeError(f\"Pip Install timed out (10m): {name}\")\n",
    "        if r.returncode != 0:\n",
    "            print(f\"--- pip stderr for {name} ---\")\n",
    "            print((r.stderr or r.stdout or \"\")[-2000:])\n",
    "            raise RuntimeError(f\"Pip Install failed: {name}\")\n",
    "        status(f\"Installed {name}\")\n",
    "\n",
    "    # Determine sudo usage\n",
    "    prefix = \"\"\n",
    "    if shutil.which(\"sudo\") and not (hasattr(os, \"geteuid\") and os.geteuid() == 0):\n",
    "        prefix = \"sudo \"\n",
    "\n",
    "    # A. System Layer (APT)\n",
    "    sys_pkgs = \"ffmpeg portaudio19-dev libc++1 libc++abi1\"\n",
    "    run_shell(\"System Tools (apt)\", f\"{prefix}apt-get update -qq && {prefix}apt-get install -y -qq {sys_pkgs}\")\n",
    "    must(shutil.which(\"ffmpeg\"), \"FFmpeg installation verified\")\n",
    "\n",
    "    # B. Core Acceleration Layer (Pip)\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\"], check=False)\n",
    "\n",
    "    # CRITICAL: Pin numba<0.60 to work with numpy<2.0\n",
    "    # numba 0.60+ requires numpy 2.0, numba 0.58-0.59 requires numpy<2.0\n",
    "    core_libs = [\n",
    "        \"tqdm\", \"numba>=0.58.0,<0.60.0\", \"tiktoken\", \"soundfile\", \"auditok\", \"requests\", \"colorama\", \"regex\",\n",
    "        \"numpy>=1.26.0,<2.0\", \"scipy>=1.10.1,<1.14\", \"librosa>=0.10.0,<0.11\",\n",
    "        \"pysrt\", \"srt\", \"aiofiles\", \"jsonschema\", \"Pillow\", \"pyloudnorm\", \"pydantic>=2,<3\",\n",
    "        \"faster-whisper>=1.1.0\", \"transformers\", \"optimum\", \"accelerate\", \"huggingface-hub>=0.25.0\",\n",
    "        \"ten-vad\", \"silero-vad>=6.0\", \"pydub\",\n",
    "        \"modelscope>=1.20\", \"onnxruntime>=1.16.0\", \"addict\", \"simplejson\", \"sortedcontainers\", \"packaging\"\n",
    "    ]\n",
    "    run_pip(\"Core Acceleration Libs\", core_libs)\n",
    "\n",
    "    # C. Application Layer (Git) - Pinned to v1.8.2-rc1 for stability\n",
    "    git_pkgs = [\n",
    "        (\"ffmpeg-python\", \"git+https://github.com/kkroening/ffmpeg-python.git\"),\n",
    "        (\"Whisper\", \"git+https://github.com/openai/whisper.git@main\"),\n",
    "        (\"Stable-TS\", \"git+https://github.com/meizhong986/stable-ts-fix-setup.git@main\"),\n",
    "        (\"ClearVoice\", \"git+https://github.com/modelscope/ClearerVoice-Studio.git#subdirectory=clearvoice\"),\n",
    "        (\"WhisperJAV\", \"git+https://github.com/meizhong986/WhisperJAV.git@v1.8.2-rc1\"),\n",
    "    ]\n",
    "\n",
    "    for name, url in git_pkgs:\n",
    "        run_pip(name, [url], no_deps=False)\n",
    "\n",
    "    # D. Force reinstall pinned versions (ensure consistency after git installs)\n",
    "    run_pip(\"Ensure Core Consistency\", [\n",
    "        \"--force-reinstall\", \"--upgrade\",\n",
    "        \"numpy>=1.26.0,<2.0\", \"scipy>=1.10.1,<1.14\", \"librosa>=0.10.0,<0.11\",\n",
    "        \"numba>=0.58.0,<0.60.0\", \"scikit-learn>=1.3.0\"\n",
    "    ], no_deps=True)\n",
    "\n",
    "    status(f\"Installation Complete ({time.time() - install_start:.0f}s)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. VERIFICATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"VERIFICATION\")\n",
    "\n",
    "# Determine which python to use for verification\n",
    "if PLATFORM == \"colab\":\n",
    "    verify_python = cfg['venv_python']\n",
    "else:\n",
    "    verify_python = sys.executable\n",
    "\n",
    "# Verify Import\n",
    "result = subprocess.run([verify_python, \"-c\", \"import whisperjav; print(whisperjav.__version__)\"], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    status(f\"WhisperJAV {result.stdout.strip()} Ready\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Installation successful but import failed: {result.stderr}\")\n",
    "\n",
    "# Verify TEN VAD\n",
    "result = subprocess.run([verify_python, \"-c\", \"import ten_vad\"], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    status(\"TEN VAD Ready\")\n",
    "else:\n",
    "    status(\"TEN VAD Warning (Import failed - Silero fallback)\", False)\n",
    "\n",
    "# Verify numpy version (critical check)\n",
    "result = subprocess.run([verify_python, \"-c\", \"import numpy; print(numpy.__version__)\"], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    numpy_version = result.stdout.strip()\n",
    "    if numpy_version.startswith(\"2.\"):\n",
    "        status(f\"WARNING: NumPy {numpy_version} detected - may cause numba issues\", False)\n",
    "    else:\n",
    "        status(f\"NumPy {numpy_version} (compatible)\")\n",
    "\n",
    "# Stamp Success\n",
    "WHISPERJAV_SETUP_COMPLETE = {\n",
    "    \"timestamp\": time.time(),\n",
    "    \"platform\": PLATFORM,\n",
    "    \"gpu_count\": len(gpus)\n",
    "}\n",
    "print(\"\\nâœ“ Environment Ready. Go to Step 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 3: Execution (Transcribe) { display-mode: \"form\" }\n",
    "#@markdown - Auto-detects **Files** (Kaggle Dataset or Colab Drive).\n",
    "#@markdown - Auto-detects **Parallel** (2x GPU) or **Sequential** mode.\n",
    "#@markdown - Runs the configured WhisperJAV pipeline.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import HTML, FileLink, display\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PLATFORM SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if \"WHISPERJAV_CONFIG\" not in globals():\n",
    "    raise RuntimeError(\"Run Step 1 first!\")\n",
    "\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "PLATFORM = cfg['platform']\n",
    "\n",
    "# Define Paths based on Platform\n",
    "if PLATFORM == \"kaggle\":\n",
    "    INPUT_DIR = Path(\"/kaggle/input\")\n",
    "    OUTPUT_DIR = Path(\"/kaggle/working/output\")\n",
    "    TEMP_DIR = Path(\"/tmp/whisperjav\")\n",
    "    # Find dataset folder (usually first subdir in input)\n",
    "    try:\n",
    "        DATASET_DIR = next(d for d in INPUT_DIR.iterdir() if d.is_dir())\n",
    "    except StopIteration:\n",
    "        DATASET_DIR = INPUT_DIR\n",
    "elif PLATFORM == \"colab\":\n",
    "    INPUT_DIR = Path(f\"/content/drive/MyDrive/{cfg['folder_name']}\")\n",
    "    OUTPUT_DIR = INPUT_DIR  # Output in same folder\n",
    "    TEMP_DIR = Path(\"/content/temp\")\n",
    "    DATASET_DIR = INPUT_DIR\n",
    "else:\n",
    "    # Local fallback\n",
    "    INPUT_DIR = Path(\"./\")\n",
    "    OUTPUT_DIR = Path(\"./output\")\n",
    "    TEMP_DIR = Path(\"./temp\")\n",
    "    DATASET_DIR = INPUT_DIR\n",
    "\n",
    "# Create dirs\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FILE SCANNING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"Scanning {DATASET_DIR}...\")\n",
    "VIDEO_EXTS = {'.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.mp3', '.wav', '.flac', '.m4a'}\n",
    "videos = [f for f in DATASET_DIR.rglob(\"*\") if f.suffix.lower() in VIDEO_EXTS]\n",
    "\n",
    "if not videos:\n",
    "    print(f\"âŒ No media files found in {DATASET_DIR}\")\n",
    "    # Don't exit, just show message\n",
    "else:\n",
    "    print(f\"âœ“ Found {len(videos)} files\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GPU SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "import torch\n",
    "ngpus = torch.cuda.device_count()\n",
    "print(f\"GPUs Available: {ngpus}\")\n",
    "\n",
    "if ngpus >= 2:\n",
    "    MODE = \"PARALLEL\"\n",
    "    gpu_map = {1: \"0\", 2: \"1\"}\n",
    "else:\n",
    "    MODE = \"SEQUENTIAL\"\n",
    "    gpu_map = {1: \"0\", 2: \"0\"}\n",
    "\n",
    "print(f\"Mode: {MODE}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUTION ENGINE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def build_cmd(pass_num, video_path, output_dir):\n",
    "    \"\"\"Build CLI command with EXPERT settings.\"\"\"\n",
    "    # Issue #2 Fix: Unique temp dir for each pass to prevent race conditions\n",
    "    pass_temp = TEMP_DIR / f\"p{pass_num}_{video_path.stem}\"\n",
    "    pass_temp.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Issue #3 Fix: Pass specific output dir\n",
    "    pass_out = output_dir / f\"pass{pass_num}\"\n",
    "    pass_out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Base command\n",
    "    executable = cfg.get('whisperjav_cmd', sys.executable + \" -m whisperjav.main\")\n",
    "    # Handle direct path or python module invocation\n",
    "    if str(executable).endswith('whisperjav'):\n",
    "        cmd = [str(executable)]\n",
    "    else:\n",
    "        cmd = list(str(executable).split()) # e.g. \"python -m whisperjav.main\"\n",
    "\n",
    "    cmd += [\n",
    "        str(video_path),\n",
    "        \"--output-dir\", str(pass_out),\n",
    "        \"--temp-dir\", str(pass_temp), # Critical Fix #2\n",
    "        \"--keep-temp\", # Fix for temps getting deleted (user feedback)\n",
    "        \"--mode\", cfg[f'pass{pass_num}_pipeline'],\n",
    "        \"--sensitivity\", cfg[f'pass{pass_num}_sensitivity'],\n",
    "        \"--subs-language\", \"direct-to-english\" if cfg['subtitle_language'] == 'direct-to-english' else \"native\",\n",
    "        \"--verbose\"\n",
    "    ]\n",
    "\n",
    "    # Models\n",
    "    model = cfg[f'pass{pass_num}_model']\n",
    "    if model: cmd += [\"--model\", model]\n",
    "\n",
    "    # Expert Args (Fix Issue #3: Actually pass these to CLI)\n",
    "    seg = cfg.get(f'pass{pass_num}_speech_segmenter')\n",
    "    if seg and seg != 'none': cmd += [\"--speech-segmenter\", seg]\n",
    "\n",
    "    scene = cfg.get(f'pass{pass_num}_scene_detector')\n",
    "    if scene and scene != 'automatic': cmd += [\"--scene-detector\", scene]\n",
    "\n",
    "    enhancer = cfg.get(f'pass{pass_num}_speech_enhancer')\n",
    "    if enhancer and enhancer != 'none': \n",
    "        cmd += [\"--speech-enhancer\", enhancer]\n",
    "        filters = cfg.get(f'pass{pass_num}_ffmpeg_filters')\n",
    "        if filters: cmd += [\"--ffmpeg-filters\", filters]\n",
    "        \n",
    "    return cmd, pass_out\n",
    "\n",
    "def run_pass(pass_num, video, gpu_id):\n",
    "    \"\"\"Run a single pass.\"\"\"\n",
    "    cmd, out_dir = build_cmd(pass_num, video, OUTPUT_DIR)\n",
    "    \n",
    "    env = os.environ.copy()\n",
    "    env[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    # Adding timeout protection -> 2 hours per pass\n",
    "    try:\n",
    "        proc = subprocess.run(cmd, env=env, capture_output=True, text=True, timeout=7200)\n",
    "        success = proc.returncode == 0\n",
    "    except subprocess.TimeoutExpired:\n",
    "        proc = subprocess.CompletedProcess(cmd, 1, stdout=\"\", stderr=\"Timeout expired\")\n",
    "        success = False\n",
    "        \n",
    "    # Check output\n",
    "    # WhisperJAV 1.8+ naming: {stem}.{lang}.whisperjav.srt\n",
    "    # Search for any produced .srt\n",
    "    found_srt = list(out_dir.glob(f\"{video.stem}*.srt\"))\n",
    "    result_srt = found_srt[0] if found_srt else None\n",
    "    \n",
    "    return {\n",
    "        \"pass\": pass_num,\n",
    "        \"success\": success and (result_srt is not None),\n",
    "        \"srt\": result_srt,\n",
    "        \"time\": time.time() - t0,\n",
    "        \"log\": proc.stderr[-1000:] if proc.stderr else \"\" # Last 1000 chars\n",
    "    }\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MAIN LOOP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "try:\n",
    "    from whisperjav.ensemble.merge import MergeEngine\n",
    "    \n",
    "    def merge_srts_files(srt1, srt2, output, strategy):\n",
    "        engine = MergeEngine()\n",
    "        # Ensure paths are Path objects\n",
    "        engine.merge(Path(srt1), Path(srt2), Path(output), strategy)\n",
    "        \n",
    "    HAS_MERGE_LIB = True\n",
    "except ImportError:\n",
    "    HAS_MERGE_LIB = False\n",
    "    # Define fallback\n",
    "    def merge_simple(p1, p2, out, strategy):\n",
    "        # Dumb concat\n",
    "        with open(p1, 'r', encoding='utf-8') as f1, open(p2, 'r', encoding='utf-8') as f2, open(out, 'w', encoding='utf-8') as fo:\n",
    "            fo.write(f1.read() + \"\\n\" + f2.read())\n",
    "        return {'merged_count': -1}\n",
    "\n",
    "\n",
    "WHISPERJAV_RESULTS = []\n",
    "\n",
    "for i, video in enumerate(videos):\n",
    "    print(f\"\\nğŸ¥ [{i+1}/{len(videos)}] {video.name}\")\n",
    "    \n",
    "    # Setup Futures\n",
    "    results = {}\n",
    "    \n",
    "    if MODE == \"PARALLEL\":\n",
    "        with ThreadPoolExecutor(max_workers=2) as exc:\n",
    "            f1 = exc.submit(run_pass, 1, video, gpu_map[1])\n",
    "            f2 = exc.submit(run_pass, 2, video, gpu_map[2])\n",
    "            \n",
    "            r1 = f1.result()\n",
    "            print(f\"  Pass 1 ({r1['time']:.0f}s): {'âœ…' if r1['success'] else 'âŒ'}\")\n",
    "            if not r1['success']: print(f\"    Error: {r1['log'][:200]}...\")\n",
    "            \n",
    "            r2 = f2.result()\n",
    "            print(f\"  Pass 2 ({r2['time']:.0f}s): {'âœ…' if r2['success'] else 'âŒ'}\")\n",
    "            if not r2['success']: print(f\"    Error: {r2['log'][:200]}...\")\n",
    "            \n",
    "            results[1] = r1\n",
    "            results[2] = r2\n",
    "    else:\n",
    "        # Sequential\n",
    "        for p in [1, 2]:\n",
    "            r = run_pass(p, video, gpu_map[p])\n",
    "            print(f\"  Pass {p} ({r['time']:.0f}s): {'âœ…' if r['success'] else 'âŒ'}\")\n",
    "            if not r['success']: print(f\"    Error: {r['log'][:200]}...\")\n",
    "            results[p] = r\n",
    "\n",
    "    # Merge Logic\n",
    "    final_srt = OUTPUT_DIR / f\"{video.stem}.whisperjav.srt\"\n",
    "    \n",
    "    if results[1]['success'] and results[2]['success']:\n",
    "        print(\"  ğŸ”„ Merging...\")\n",
    "        if HAS_MERGE_LIB:\n",
    "            # We need to map config strategy to library enum/string\n",
    "            # Config has \"smart_merge\", \"full_merge\" etc.\n",
    "            # Library expects strings like \"smart_merge\".\n",
    "            try:\n",
    "                merge_srts_files(results[1]['srt'], results[2]['srt'], final_srt, cfg['merge_strategy'])\n",
    "                print(f\"  âœ¨ Saved: {final_srt.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ Merge failed: {e}. Keeping Pass 1.\")\n",
    "                shutil.copy(results[1]['srt'], final_srt)\n",
    "        else:\n",
    "            print(\"  âš ï¸ Merge lib missing, using Pass 1\")\n",
    "            shutil.copy(results[1]['srt'], final_srt)\n",
    "            \n",
    "        WHISPERJAV_RESULTS.append(final_srt)\n",
    "        \n",
    "    elif results[1]['success']:\n",
    "        print(\"  âš ï¸ Pass 2 failed, using Pass 1\")\n",
    "        shutil.copy(results[1]['srt'], final_srt)\n",
    "        WHISPERJAV_RESULTS.append(final_srt)\n",
    "    elif results[2]['success']:\n",
    "        print(\"  âš ï¸ Pass 1 failed, using Pass 2\")\n",
    "        shutil.copy(results[2]['srt'], final_srt)\n",
    "        WHISPERJAV_RESULTS.append(final_srt)\n",
    "    else:\n",
    "        print(\"  âŒ Both passes failed\")\n",
    "\n",
    "print(\"\\nDONE!\")\n",
    "if PLATFORM == \"kaggle\":\n",
    "    # Zip output for easy download\n",
    "    shutil.make_archive(\"/kaggle/working/subtitles\", 'zip', OUTPUT_DIR)\n",
    "    print(\"ğŸ“¦ Output zipped: subtitles.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 4: AI Translation (Optional) { display-mode: \"form\" }\n",
    "#@markdown ## ğŸ¤– Provider Settings\n",
    "translation_provider = \"local\" #@param [\"local\", \"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\", \"glm\", \"groq\"]\n",
    "local_model = \"gemma-9b\" #@param [\"gemma-9b\", \"llama-8b\", \"llama-3b\", \"auto\"]\n",
    "#@markdown <font size=\"1\">local: Free, runs on GPU. gemma-9b (8GB+ VRAM), llama-8b (6GB+), llama-3b (3GB+). Cloud providers require API key.</font>\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "model_override = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ## ğŸ¯ Translation Settings\n",
    "target_language = \"english\" #@param [\"english\", \"chinese\", \"spanish\", \"indonesian\"]\n",
    "source_language = \"japanese\" #@param [\"japanese\", \"korean\", \"chinese\"]\n",
    "tone = \"pornify\" #@param [\"standard\", \"pornify\"]\n",
    "\n",
    "#@markdown ## ğŸ¬ Context (Optional)\n",
    "#@markdown *Leave blank for batch processing of different movies.*\n",
    "movie_title = \"\" #@param {type:\"string\"}\n",
    "actress = \"\" #@param {type:\"string\"}\n",
    "movie_plot = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ## âš™ï¸ Advanced\n",
    "scene_threshold = 60 #@param {type:\"integer\"}\n",
    "batch_size = 30 #@param {type:\"integer\"}\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display, FileLink\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    print(f\"{'âœ“' if ok else 'âœ—'} {msg}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. INPUT VALIDATION & DISCOVERY\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Get config from Step 1 for venv paths\n",
    "cfg = globals().get(\"WHISPERJAV_CONFIG\", {})\n",
    "\n",
    "# Reconstruct Output Dir if missing (Support for Session Restart/CPU Mode)\n",
    "if \"WHISPERJAV_OUTPUT_DIR\" not in globals():\n",
    "    if cfg:\n",
    "        fname = cfg[\"folder_name\"]\n",
    "        if \"google.colab\" in sys.modules:\n",
    "            from google.colab import drive\n",
    "            drive.mount(\"/content/drive\", force_remount=False)\n",
    "            WHISPERJAV_OUTPUT_DIR = Path(f\"/content/drive/MyDrive/{fname}\")\n",
    "        elif os.path.exists(\"/kaggle\"):\n",
    "            # Note: Kaggle non-persistent unless same session\n",
    "            WHISPERJAV_OUTPUT_DIR = Path(f\"/kaggle/working/{fname}\")\n",
    "        else:\n",
    "            WHISPERJAV_OUTPUT_DIR = Path(f\"{fname}_output\").absolute()\n",
    "    else:\n",
    "        # Fallback for manual run without Step 1\n",
    "        WHISPERJAV_OUTPUT_DIR = Path(\".\").resolve()\n",
    "\n",
    "# Recover SRTS\n",
    "targets = []\n",
    "if \"WHISPERJAV_NEW_SRTS\" in globals() and WHISPERJAV_NEW_SRTS:\n",
    "    targets = WHISPERJAV_NEW_SRTS\n",
    "elif WHISPERJAV_OUTPUT_DIR.exists():\n",
    "    print(f\"Scanning for SRTs in: {WHISPERJAV_OUTPUT_DIR}\")\n",
    "    # Find all source SRTs (excluding existing translations)\n",
    "    candidates = sorted(list(WHISPERJAV_OUTPUT_DIR.glob(\"*.srt\")))\n",
    "    targets = [t for t in candidates if not t.name.endswith(f\".{target_language}.srt\")]\n",
    "\n",
    "if not targets:\n",
    "    display(HTML('<div style=\"background:#fee2e2;padding:10px;border-radius:4px;\"><b>âš ï¸ No Subtitles Found</b><br>Run Step 3, or ensure Output directory has SRTs.</div>'))\n",
    "    raise RuntimeError(\"No inputs\")\n",
    "\n",
    "# Check Metadata safety\n",
    "if len(targets) > 1 and (movie_title or actress or movie_plot):\n",
    "    display(HTML(f'<div style=\"background:#fff7ed;padding:10px;border-radius:4px;border:1px solid #fdba74\"><b>âš ï¸ Metadata Warning</b><br>'\n",
    "                 f'You are applying the same Movie Title/Plot/Actress to <b>{len(targets)} different files</b>.<br>'\n",
    "                 f'If these are different movies, please clear the Context fields above.</div>'))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. CREDENTIALS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "is_local = translation_provider == 'local'\n",
    "final_key = api_key\n",
    "\n",
    "if not is_local:\n",
    "    if not final_key:\n",
    "        # Try Step 1 Config (if matches provider)\n",
    "        if cfg.get(\"api_key\") and cfg.get(\"translation_service\") == translation_provider:\n",
    "            final_key = cfg[\"api_key\"]\n",
    "        # Try Kaggle Secrets\n",
    "        elif os.path.exists(\"/kaggle\"):\n",
    "            from kaggle_secrets import UserSecretsClient\n",
    "            try:\n",
    "                final_key = UserSecretsClient().get_secret(f\"{translation_provider.upper()}_API_KEY\")\n",
    "            except: pass\n",
    "\n",
    "    if not final_key:\n",
    "        raise RuntimeError(f\"Missing API Key for {translation_provider}. Enter it in the form or use 'local' provider for free GPU translation.\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. INTERACTIVE CONFIRMATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"Ready to translate {len(targets)} files.\")\n",
    "if is_local:\n",
    "    print(f\"Provider: local ({local_model})\")\n",
    "    print(\"Note: First run downloads model (~5GB) and llama-cpp-python (~700MB)\")\n",
    "else:\n",
    "    print(f\"Provider: {translation_provider}\")\n",
    "print(f\"Target: {target_language} | Tone: {tone}\")\n",
    "if model_override:\n",
    "    print(f\"Model: {model_override}\")\n",
    "\n",
    "if not os.path.exists(\"/kaggle\"): # Kaggle batch mode cannot accept input\n",
    "    try:\n",
    "        input(\"\\nPress [Enter] to start translation (or Stop cell to cancel)...\")\n",
    "    except (EOFError, KeyboardInterrupt):\n",
    "        print(\"Cancelled by user.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 4. EXECUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸš€ Starting Translation Service...\")\n",
    "translated_files = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Determine which command to use: venv binary for Colab, sys.executable for Kaggle/local\n",
    "translate_cmd = cfg.get('whisperjav_translate_cmd')\n",
    "\n",
    "for srt in targets:\n",
    "    print(f\"\\nProcessing: {srt.name}\")\n",
    "    \n",
    "    # Use venv binary for Colab, sys.executable for Kaggle/local\n",
    "    if translate_cmd:\n",
    "        cmd = [translate_cmd]\n",
    "    else:\n",
    "        cmd = [sys.executable, \"-m\", \"whisperjav.translate.cli\"]\n",
    "    \n",
    "    cmd.extend([\n",
    "        \"-i\", str(srt),\n",
    "        \"--provider\", translation_provider,\n",
    "        \"--source\", source_language,\n",
    "        \"--target\", target_language,\n",
    "        \"--tone\", tone,\n",
    "        \"--scene-threshold\", str(scene_threshold),\n",
    "        \"--max-batch-size\", str(batch_size),\n",
    "        \"--stream\" # Stream progress to stderr\n",
    "    ])\n",
    "    \n",
    "    # Add API key for cloud providers\n",
    "    if not is_local:\n",
    "        cmd.extend([\"--api-key\", final_key])\n",
    "    \n",
    "    # Model selection\n",
    "    if is_local:\n",
    "        cmd.extend([\"--model\", local_model])\n",
    "    elif model_override:\n",
    "        cmd.extend([\"--model\", model_override])\n",
    "    \n",
    "    # Optional Args\n",
    "    if movie_title: cmd.extend([\"--movie-title\", movie_title])\n",
    "    if actress: cmd.extend([\"--actress\", actress])\n",
    "    if movie_plot: cmd.extend([\"--movie-plot\", movie_plot])\n",
    "    \n",
    "    # Run with real-time streaming\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            bufsize=1, # Line buffered\n",
    "            encoding='utf-8',\n",
    "            errors='replace' # Prevent decoding errors\n",
    "        )\n",
    "        \n",
    "        # Read stderr (progress) and stdout (result path)\n",
    "        output_path = None\n",
    "        while True:\n",
    "            # Check stderr for progress updates\n",
    "            err_line = process.stderr.readline()\n",
    "            if err_line:\n",
    "                print(err_line.strip(), file=sys.stderr) # Print to notebook stderr\n",
    "            \n",
    "            # Check stdout for final filename\n",
    "            out_line = process.stdout.readline()\n",
    "            if out_line:\n",
    "                line = out_line.strip()\n",
    "                if line and line.endswith('.srt'):\n",
    "                    output_path = line\n",
    "                # Also print purely informational stdout\n",
    "                print(line)\n",
    "\n",
    "            # Break safely\n",
    "            if not err_line and not out_line and process.poll() is not None:\n",
    "                break\n",
    "                \n",
    "        if process.returncode == 0 and output_path:\n",
    "            out_file = Path(output_path)\n",
    "            if out_file.exists():\n",
    "                status(f\"Completed: {out_file.name}\")\n",
    "                translated_files.append(out_file)\n",
    "            else:\n",
    "                 status(f\"Error: Output file not found: {output_path}\", False)\n",
    "        else:\n",
    "            status(\"Translation failed (check logs above)\", False)\n",
    "\n",
    "    except Exception as e:\n",
    "        status(f\"Exception: {e}\", False)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 5. PACKAGING & DOWNLOAD\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if translated_files:\n",
    "    # Use output dir from Step 3 if available, else srt parent\n",
    "    base_out = WHISPERJAV_OUTPUT_DIR if \"WHISPERJAV_OUTPUT_DIR\" in globals() else translated_files[0].parent\n",
    "    zip_path = base_out / f\"translated_{translation_provider}_{int(time.time())}.zip\"\n",
    "    \n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for t in translated_files:\n",
    "            zf.write(t, t.name)\n",
    "            \n",
    "    print(f\"\\nğŸ“¦ Translations Bundle: {zip_path.name}\")\n",
    "    \n",
    "    if os.path.exists(\"/kaggle\"):\n",
    "         display(FileLink(str(zip_path.relative_to(Path.cwd())), result_html_prefix=\"<b>â¬‡ Download Translations: </b>\"))\n",
    "    elif \"google.colab\" in sys.modules:\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(str(zip_path))\n",
    "        except: pass\n",
    "else:\n",
    "    print(\"\\nNo translations produced.\")\n",
    "\n",
    "print(f\"\\nTotal Time: {(time.time() - start_time)/60:.1f} min\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4x2",
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
