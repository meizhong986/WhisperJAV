{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/meizhong986/WhisperJAV/blob/main/notebook/WhisperJAV_colab_parallel_expert.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>\n",
    "\n",
    "# WhisperJAV Ensemble Dual-GPU Edition (v1.7.5)\n",
    "\n",
    "**Universal** - Auto-detects Kaggle T4x2 for parallel processing, falls back to single-GPU on Colab\n",
    "\n",
    "| Platform | Logic | Storage |\n",
    "|----------|-------|---------|\n",
    "| **Kaggle** | **Parallel** (2x T4) | **Input**: `/kaggle/input` (Dataset) <br> **Output**: `/kaggle/working` (Artifacts) |\n",
    "| **Colab** | **Sequential** (1x GPU) | **Input/Output**: Google Drive |\n",
    "\n",
    "| Option | What it controls |\n",
    "|--------|------------------|\n",
    "| **Scene Detection** | How to split audio into chunks (auditok, silero, semantic) |\n",
    "| **Speech Segmenter** | How to detect speech in audio (silero, ten) |\n",
    "| **Speech Enhancer** | Audio cleanup for noisy sources (ffmpeg-dsp, clearvoice, etc.) |\n",
    "| **Model** | Which AI model to use (large-v2, large-v3, turbo, kotoba) |\n",
    "\n",
    "---\n",
    "<div style=\"font-size: 11px; line-height: 1.4;\">\n",
    "1. <b>Setup Files:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;â€¢ <b>Colab:</b> Upload videos to <code>Google Drive/WhisperJAV/</code><br>\n",
    "&nbsp;&nbsp;&nbsp;â€¢ <b>Kaggle:</b> Add your videos as a Dataset (recommended) or upload to Input.<br>\n",
    "2. Run <b>Step 1: Expert Configuration</b> (required)<br>\n",
    "3. Run <b>Step 2: Two-Pass Transcribe</b> (auto-detects platform)<br>\n",
    "4. Run <b>Step 3: AI Translation</b> (supports Kaggle Secrets/Env/Keys)\n",
    "</div>\n",
    "\n",
    "<small>The notebook will automatically disconnect (Colab) or finish session (Kaggle) when done.</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 1: Expert Configuration { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ## ğŸ“ Files & Output\n",
    "folder_name = \"WhisperJAV\" #@param {type:\"string\"}\n",
    "subtitle_language = \"Japanese\" #@param [\"Japanese\", \"English (auto-translate)\", \"English (AI translate)\"]\n",
    "spoken_language = \"Japanese\" #@param [\"Japanese\", \"Chinese\", \"English\", \"Korean\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 1ï¸âƒ£ Pass 1 Configuration (GPU 0)\n",
    "pass1_quality = \"balanced\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass1_sensitivity = \"aggressive\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass1_model = \"large-v2\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 1)**\n",
    "pass1_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass1_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass1_speech_enhancer = \"none\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "#@markdown <font size=\"1\">auditok=energy (fast), silero=VAD, semantic=texture (complex audio) | enhancer: ffmpeg-dsp(no GPU), clearvoice(48k), bs-roformer(vocal)</font>\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 1)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass1_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass1_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## 2ï¸âƒ£ Pass 2 Configuration (GPU 1)\n",
    "pass2_quality = \"fidelity\" #@param [\"faster\", \"fast\", \"balanced\", \"fidelity\", \"transformers\"]\n",
    "pass2_sensitivity = \"balanced\" #@param [\"conservative\", \"balanced\", \"aggressive\"]\n",
    "pass2_model = \"turbo\" #@param [\"automatic\", \"large-v2\", \"large-v3\", \"turbo\", \"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"]\n",
    "\n",
    "#@markdown **Expert Audio Setup (Pass 2)**\n",
    "pass2_scene_detector = \"semantic\" #@param [\"automatic\", \"auditok\", \"silero\", \"semantic\"]\n",
    "pass2_speech_segmenter = \"ten\" #@param [\"automatic\", \"silero\", \"ten\", \"none\"]\n",
    "pass2_speech_enhancer = \"ffmpeg-dsp\" #@param [\"none\", \"ffmpeg-dsp\", \"clearvoice\", \"zipenhancer\", \"bs-roformer\"]\n",
    "\n",
    "#@markdown **FFmpeg Filters (Pass 2)** *(only if enhancer is ffmpeg-dsp)*\n",
    "pass2_ffmpeg_amplify = True #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_loudnorm = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_compress = False #@param {type:\"boolean\"}\n",
    "pass2_ffmpeg_highpass = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ”— Merge Strategy\n",
    "merge_method = \"prefer first pass\" #@param [\"automatic\", \"keep all\", \"prefer first pass\", \"prefer second pass\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## ğŸ¤– AI Translation *(if selected)*\n",
    "translation_service = \"deepseek\" #@param [\"deepseek\", \"openrouter\", \"gemini\", \"claude\", \"gpt\"]\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "translation_style = \"standard\" #@param [\"standard\", \"explicit\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ## âš™ï¸ Session\n",
    "opening_credit = \"\" #@param {type:\"string\"}\n",
    "closing_credit = \"Subs by WhisperJAV\" #@param {type:\"string\"}\n",
    "auto_disconnect = True #@param {type:\"boolean\"}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION LOGIC\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Mapping dictionaries\n",
    "combine_map = {\"automatic\": \"smart_merge\", \"keep all\": \"full_merge\",\n",
    "               \"prefer first pass\": \"pass1_primary\", \"prefer second pass\": \"pass2_primary\"}\n",
    "language_map = {\"Japanese\": \"native\", \"English (auto-translate)\": \"direct-to-english\",\n",
    "                \"English (AI translate)\": \"llm\"}\n",
    "tone_map = {\"standard\": \"standard\", \"explicit\": \"pornify\"}\n",
    "spoken_language_map = {\"Japanese\": \"japanese\", \"Chinese\": \"chinese\", \"English\": \"english\", \"Korean\": \"korean\"}\n",
    "\n",
    "# Model mapping (None = use pipeline default)\n",
    "model_map = {\n",
    "    \"automatic\": None,\n",
    "    \"large-v2\": \"large-v2\",\n",
    "    \"large-v3\": \"large-v3\",\n",
    "    \"turbo\": \"turbo\",\n",
    "    \"kotoba-bilingual\": \"kotoba-tech/kotoba-whisper-bilingual-v1.0\",\n",
    "    \"kotoba-v2.0\": \"kotoba-tech/kotoba-whisper-v2.0\",\n",
    "    \"kotoba-v2.1\": \"kotoba-tech/kotoba-whisper-v2.1\",\n",
    "    \"kotoba-v2.2\": \"kotoba-tech/kotoba-whisper-v2.2\"\n",
    "}\n",
    "\n",
    "# Define model compatibility:\n",
    "KOTOBA_MODELS = {\"kotoba-bilingual\", \"kotoba-v2.0\", \"kotoba-v2.1\", \"kotoba-v2.2\"}\n",
    "LEGACY_PIPELINES = {\"faster\", \"fast\", \"balanced\", \"fidelity\"}\n",
    "\n",
    "# Auto-correct incompatible model-pipeline combinations\n",
    "warnings_list = []\n",
    "\n",
    "# Check Pass 1 compatibility\n",
    "if pass1_model in KOTOBA_MODELS and pass1_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 1: {pass1_model} requires 'transformers' pipeline. Auto-correcting from '{pass1_quality}' to 'transformers'.\")\n",
    "    pass1_quality = \"transformers\"\n",
    "\n",
    "# Check Pass 2 compatibility\n",
    "if pass2_model in KOTOBA_MODELS and pass2_quality in LEGACY_PIPELINES:\n",
    "    warnings_list.append(f\"Pass 2: {pass2_model} requires 'transformers' pipeline. Auto-correcting from '{pass2_quality}' to 'transformers'.\")\n",
    "    pass2_quality = \"transformers\"\n",
    "\n",
    "# Memory warning\n",
    "heavy_enhancers = {'clearvoice', 'bs-roformer', 'zipenhancer'}\n",
    "if pass1_speech_enhancer in heavy_enhancers and pass2_speech_enhancer in heavy_enhancers:\n",
    "    warnings_list.append(\"Using GPU-based enhancement on both passes may cause OOM on T4 GPU (Sequential Mode). Suggest using ffmpeg-dsp for one pass.\")\n",
    "\n",
    "# Helpers\n",
    "def build_ffmpeg_filters(amplify, loudnorm, compress, highpass):\n",
    "    \"\"\"Combine selected FFmpeg filters into comma-separated string.\"\"\"\n",
    "    filters = []\n",
    "    if amplify: filters.append(\"amplify\")\n",
    "    if loudnorm: filters.append(\"loudnorm\")\n",
    "    if compress: filters.append(\"compress\")\n",
    "    if highpass: filters.append(\"highpass\")\n",
    "    return \",\".join(filters) if filters else None\n",
    "\n",
    "def map_value(val):\n",
    "    return None if val == \"automatic\" else val\n",
    "\n",
    "def map_segmenter(val):\n",
    "    return \"none\" if val == \"none\" else map_value(val)\n",
    "\n",
    "# Unified Config Construction\n",
    "WHISPERJAV_CONFIG = {\n",
    "    'pass1_pipeline': pass1_quality,\n",
    "    'pass1_sensitivity': pass1_sensitivity,\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter),\n",
    "    'pass1_model': model_map[pass1_model],\n",
    "    'pass2_pipeline': pass2_quality,\n",
    "    'pass2_sensitivity': pass2_sensitivity,\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter),\n",
    "    'pass2_model': model_map[pass2_model],\n",
    "    'merge_strategy': combine_map[merge_method],\n",
    "    'folder_name': folder_name,\n",
    "    'subtitle_language': language_map[subtitle_language],\n",
    "    'language': spoken_language_map[spoken_language],\n",
    "    'translation_service': translation_service,\n",
    "    'api_key': api_key,\n",
    "    'translation_style': tone_map[translation_style],\n",
    "    'opening_credit': opening_credit,\n",
    "    'closing_credit': closing_credit,\n",
    "    'auto_disconnect': auto_disconnect,\n",
    "    # Compatibility checks for Step 2\n",
    "    '_pass1_quality': pass1_quality,\n",
    "    '_pass1_sensitivity': pass1_sensitivity,\n",
    "    '_pass1_speech_segmenter': pass1_speech_segmenter,\n",
    "    '_pass1_model': pass1_model,\n",
    "    '_pass2_quality': pass2_quality,\n",
    "    '_pass2_sensitivity': pass2_sensitivity,\n",
    "    '_pass2_speech_segmenter': pass2_speech_segmenter,\n",
    "    '_pass2_model': pass2_model,\n",
    "    '_merge_method': merge_method,\n",
    "    '_subtitle_language': subtitle_language,\n",
    "    '_translation_style': translation_style,\n",
    "}\n",
    "\n",
    "WHISPERJAV_EXPERT_CONFIG = {\n",
    "    # Pass 1 Expert\n",
    "    'pass1_scene_detector': map_value(pass1_scene_detector),\n",
    "    'pass1_speech_segmenter': map_segmenter(pass1_speech_segmenter), # Now unified\n",
    "    'pass1_speech_enhancer': None if pass1_speech_enhancer == \"none\" else pass1_speech_enhancer,\n",
    "    'pass1_ffmpeg_filters': build_ffmpeg_filters(pass1_ffmpeg_amplify, pass1_ffmpeg_loudnorm, pass1_ffmpeg_compress, pass1_ffmpeg_highpass) if pass1_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    # Pass 2 Expert\n",
    "    'pass2_scene_detector': map_value(pass2_scene_detector),\n",
    "    'pass2_speech_segmenter': map_segmenter(pass2_speech_segmenter), # Now unified\n",
    "    'pass2_speech_enhancer': None if pass2_speech_enhancer == \"none\" else pass2_speech_enhancer,\n",
    "    'pass2_ffmpeg_filters': build_ffmpeg_filters(pass2_ffmpeg_amplify, pass2_ffmpeg_loudnorm, pass2_ffmpeg_compress, pass2_ffmpeg_highpass) if pass2_speech_enhancer == \"ffmpeg-dsp\" else None,\n",
    "    # Display helpers\n",
    "    '_pass1_scene_detector': pass1_scene_detector,\n",
    "    '_pass1_speech_enhancer': pass1_speech_enhancer,\n",
    "    '_pass2_scene_detector': pass2_scene_detector,\n",
    "    '_pass2_speech_enhancer': pass2_speech_enhancer,\n",
    "}\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display warnings\n",
    "for warning in warnings_list:\n",
    "    display(HTML(f'<div style=\"padding:6px 10px;background:#fef9c3;border-radius:4px;font-size:10px;margin-bottom:4px\"><b>âš ï¸ Auto-corrected:</b> {warning}</div>'))\n",
    "\n",
    "# Build status display\n",
    "p1_info = f\"{pass1_quality}\"\n",
    "if pass1_speech_segmenter != \"automatic\":\n",
    "    p1_info += f\"/{pass1_speech_segmenter}\"\n",
    "if pass1_model != \"automatic\":\n",
    "    p1_info += f\"/{pass1_model}\"\n",
    "\n",
    "p2_info = f\"{pass2_quality}\"\n",
    "if pass2_speech_segmenter != \"automatic\":\n",
    "    p2_info += f\"/{pass2_speech_segmenter}\"\n",
    "if pass2_model != \"automatic\":\n",
    "    p2_info += f\"/{pass2_model}\"\n",
    "\n",
    "display(HTML(f'<div style=\"padding:10px;background:#e0f2fe;border-radius:4px;font-size:11px\">'\n",
    "             f'<b>Parallel Configuration Loaded</b><br>'\n",
    "             f'Pass 1: {p1_info} | Pass 2: {p2_info}<br>'\n",
    "             f'Merge: {merge_method} | Folder: {folder_name} | Language: {spoken_language}'\n",
    "             f'</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11687881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 1.5: TEN prerequisites + sanity check { display-mode: \"form\" }\n",
    "#@markdown Run this **before Step 2** if you use `ten` as the speech segmenter.\n",
    "\n",
    "import os, shutil, subprocess, sys, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "def _apt_prefix() -> str:\n",
    "    \"\"\"Use sudo only when needed + available.\"\"\"\n",
    "    try:\n",
    "        if hasattr(os, \"geteuid\") and os.geteuid() == 0:\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"sudo \" if shutil.which(\"sudo\") else \"\"\n",
    "\n",
    "def run(cmd: str) -> None:\n",
    "    print(f\"$ {cmd}\")\n",
    "    r = subprocess.run(cmd, shell=True, text=True, capture_output=True)\n",
    "    if r.returncode != 0:\n",
    "        print(\"--- stdout (tail) ---\")\n",
    "        print((r.stdout or \"\")[-4000:])\n",
    "        print(\"--- stderr (tail) ---\")\n",
    "        print((r.stderr or \"\")[-4000:])\n",
    "        raise RuntimeError(f\"Command failed (rc={r.returncode}): {cmd}\")\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]} | exe: {sys.executable}\")\n",
    "\n",
    "# 1) Install runtime libs required by TEN VAD (system packages)\n",
    "prefix = _apt_prefix()\n",
    "try:\n",
    "    run(prefix + \"apt-get update -qq\")\n",
    "    run(prefix + \"apt-get install -y -qq libc++1 libc++abi1\")\n",
    "except Exception:\n",
    "    print(\"\\nApt install failed. On Kaggle you may need to enable Internet, or your image may block apt.\")\n",
    "    raise\n",
    "\n",
    "# 2) Install the Python package into THIS kernel's Python environment\n",
    "#    (This fixes the common issue where `pip` points to a different Python than the notebook kernel.)\n",
    "run(f\"{sys.executable} -m pip install -q --upgrade pip\")\n",
    "run(f\"{sys.executable} -m pip install -q ten-vad\")\n",
    "\n",
    "# 3) Prove the loader can see libc++ from this runtime\n",
    "run(\"ldconfig -p | egrep 'libc\\\\+\\\\+\\\\.so\\\\.1|libc\\\\+\\\\+abi\\\\.so\\\\.1' || true\")\n",
    "\n",
    "# 4) Prove Python can load the shared libs, then import/init TEN\n",
    "code = textwrap.dedent(r\"\"\"\n",
    "    import ctypes\n",
    "    for lib in ('libc++.so.1','libc++abi.so.1'):\n",
    "        try:\n",
    "            ctypes.CDLL(lib)\n",
    "            print('OK ctypes load', lib)\n",
    "        except OSError as e:\n",
    "            print('FAIL ctypes load', lib, ':', e)\n",
    "    \n",
    "    try:\n",
    "        import ten_vad\n",
    "        print('ten_vad import OK:', ten_vad.__file__)\n",
    "        from ten_vad import TenVad\n",
    "        _ = TenVad()\n",
    "        print('TenVad() OK')\n",
    "    except Exception as e:\n",
    "        print('TEN IMPORT/INIT FAILED:', repr(e))\n",
    "\"\"\")\n",
    "r = subprocess.run([sys.executable, \"-c\", code], text=True, capture_output=True)\n",
    "print(r.stdout)\n",
    "if r.returncode != 0 and r.stderr:\n",
    "    print(r.stderr)\n",
    "\n",
    "print(\"\\nIf you still see TEN failures in Step 2 after this cell passes, copy/paste the exact 'TEN IMPORT/INIT FAILED' line here â€” it will be a different root cause than missing libc++ or missing the Python package.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbcce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 1.6: Preflight imports (FAIL FAST) { display-mode: \"form\" }\n",
    "#@markdown This cell fails immediately if critical imports/initializations are broken. Run it before Step 2.\n",
    "\n",
    "import importlib, shutil, subprocess, sys, time\n",
    "from pathlib import Path\n",
    "\n",
    "FAIL_FAST_PREFLIGHT = True\n",
    "\n",
    "def must(condition: bool, msg: str):\n",
    "    if not condition:\n",
    "        raise SystemExit(f\"Preflight failed: {msg}\")\n",
    "\n",
    "def which(cmd: str) -> str:\n",
    "    p = shutil.which(cmd)\n",
    "    return p or \"\"\n",
    "\n",
    "print(f\"Kernel Python: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# 1) Core CLI package must be importable in THIS kernel\n",
    "try:\n",
    "    import whisperjav\n",
    "    print(\"OK import whisperjav:\", whisperjav.__file__)\n",
    "except Exception as e:\n",
    "    raise SystemExit(f\"Preflight failed: cannot import whisperjav in kernel env: {e!r}\")\n",
    "\n",
    "# 2) TEN segmenter optional, but if you plan to use it, it must import + init\n",
    "try:\n",
    "    import ten_vad\n",
    "    from ten_vad import TenVad\n",
    "    _ = TenVad()\n",
    "    print(\"OK TEN: ten_vad import + TenVad()\")\n",
    "except Exception as e:\n",
    "    # If you don't use TEN, you can ignore; if you do, treat as fatal.\n",
    "    if FAIL_FAST_PREFLIGHT:\n",
    "        raise SystemExit(f\"Preflight failed: TEN not usable (import/init): {e!r}\")\n",
    "    print(\"WARN: TEN not usable:\", repr(e))\n",
    "\n",
    "# 3) GPU stack sanity (best effort)\n",
    "try:\n",
    "    import torch\n",
    "    print(\"OK torch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    # Not always fatal (CPU mode exists), but for Kaggle/Colab GPU notebooks, treat as fatal.\n",
    "    if FAIL_FAST_PREFLIGHT:\n",
    "        raise SystemExit(f\"Preflight failed: torch/CUDA stack issue: {e!r}\")\n",
    "    print(\"WARN: torch/CUDA issue:\", repr(e))\n",
    "\n",
    "# 4) System tools needed by pipeline\n",
    "ffmpeg = which(\"ffmpeg\")\n",
    "must(bool(ffmpeg), \"ffmpeg not found on PATH\")\n",
    "print(\"OK ffmpeg:\", ffmpeg)\n",
    "\n",
    "# 5) Confirm that 'whisperjav' on PATH matches the kernel env (diagnostic)\n",
    "whisperjav_bin = which(\"whisperjav\")\n",
    "print(\"whisperjav on PATH:\", whisperjav_bin or \"<not found>\")\n",
    "if whisperjav_bin:\n",
    "    try:\n",
    "        out = subprocess.run([whisperjav_bin, \"--help\"], text=True, capture_output=True, timeout=10)\n",
    "        print(\"whisperjav --help rc=\", out.returncode)\n",
    "    except Exception as e:\n",
    "        print(\"WARN: unable to run whisperjav --help:\", repr(e))\n",
    "\n",
    "# Contract for Step 2: stamp a kernel-specific preflight token\n",
    "WHISPERJAV_PREFLIGHT = {\n",
    "    \"ok\": True,\n",
    "    \"python\": sys.executable,\n",
    "    \"python_version\": sys.version.split()[0],\n",
    "    \"timestamp\": int(time.time()),\n",
    "}\n",
    "print(\"\\nPreflight OK. Token saved in WHISPERJAV_PREFLIGHT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 2: Two-Pass Transcribe { display-mode: \"form\" }\n",
    "#@markdown Connect Drive (Colab) or Setup Paths (Kaggle) â†’ Install â†’ Run passes â†’ Merge results\n",
    "\n",
    "import os, sys, subprocess, shlex, time, re, shutil\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.core.display import HTML\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    icon = \"âœ“\" if ok else \"âœ—\"\n",
    "    print(f\"{icon} {msg}\")\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'â”€'*50}\\n{title}\\n{'â”€'*50}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FAIL-FAST GUARD: Require Step 1.6 token\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if 'WHISPERJAV_PREFLIGHT' not in globals() or not isinstance(WHISPERJAV_PREFLIGHT, dict) or not WHISPERJAV_PREFLIGHT.get('ok'):\n",
    "    display(HTML('<div style=\"padding:10px;background:#fee2e2;border-radius:4px;border-left:4px solid #ef4444;color:#991b1b;\"><b>ğŸ›‘ Preflight not run</b><br>Run <b>Step 1.6: Preflight imports (FAIL FAST)</b> first. This notebook refuses to start Step 2 without it.</div>'))\n",
    "    raise SystemExit()\n",
    "if WHISPERJAV_PREFLIGHT.get('python') != sys.executable:\n",
    "    display(HTML(f'<div style=\"padding:10px;background:#fee2e2;border-radius:4px;border-left:4px solid #ef4444;color:#991b1b;\"><b>ğŸ›‘ Kernel changed</b><br>Preflight was run under:<br><code>{WHISPERJAV_PREFLIGHT.get(\"python\")}</code><br>Current kernel is:<br><code>{sys.executable}</code><br>Re-run <b>Step 1.6</b>.</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "def tail_lines(path: Optional[Path], n: int = 30, max_chars: int = 4000) -> str:\n",
    "    \"\"\"Return the last N lines of a text file (best-effort) for notebook status panels.\"\"\"\n",
    "    if not path or not path.exists():\n",
    "        return \"\"\n",
    "    try:\n",
    "        text = path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            text = path.read_text(encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "    lines = text.splitlines()\n",
    "    tail = \"\\n\".join(lines[-n:])\n",
    "    if max_chars and len(tail) > max_chars:\n",
    "        tail = tail[-max_chars:]\n",
    "    return tail\n",
    "\n",
    "def render_pass_panel(pass_states: Dict[int, Dict[str, Any]], tail_n: int = 4) -> None:\n",
    "    \"\"\"Render a compact, overwrite-in-place status panel for Kaggle/Colab notebooks.\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    section(\"EXECUTION (LIVE STATUS)\")\n",
    "\n",
    "    for pass_num in sorted(pass_states.keys()):\n",
    "        st = pass_states[pass_num]\n",
    "        status_txt = st.get(\"status\", \"?\")\n",
    "        elapsed = st.get(\"elapsed\", 0.0)\n",
    "        rc = st.get(\"returncode\")\n",
    "        log_path = st.get(\"log_path\")\n",
    "        extra = \"\"\n",
    "        if rc is not None:\n",
    "            extra = f\" | rc={rc}\"\n",
    "        print(f\"Pass {pass_num}: {status_txt} | {elapsed:.0f}s{extra}\")\n",
    "        if log_path:\n",
    "            tail = tail_lines(Path(log_path), n=tail_n)\n",
    "            if tail:\n",
    "                print(\"--- log tail ---\")\n",
    "                print(tail)\n",
    "        print()\n",
    "\n",
    "# Check config\n",
    "if 'WHISPERJAV_CONFIG' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 1 first</div>'))\n",
    "    raise SystemExit()\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "\n",
    "# Check for expert config (always present now)\n",
    "expert = WHISPERJAV_EXPERT_CONFIG if 'WHISPERJAV_EXPERT_CONFIG' in dir() else None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PLATFORM DETECTION & FILE SYSTEM SETUP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"DETECTING PLATFORM & PATHS\")\n",
    "\n",
    "def detect_platform():\n",
    "    if 'google.colab' in sys.modules:\n",
    "        return 'colab'\n",
    "    elif os.path.exists('/kaggle'):\n",
    "        return 'kaggle'\n",
    "    else:\n",
    "        return 'local'\n",
    "\n",
    "PLATFORM = detect_platform()\n",
    "print(f\"Platform: {PLATFORM.upper()}\")\n",
    "\n",
    "if PLATFORM == 'colab':\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        base_dir = Path(f\"/content/drive/MyDrive\")\n",
    "        input_dir = base_dir / cfg['folder_name']\n",
    "        output_dir = input_dir # Colab writes back to same folder\n",
    "        input_dir.mkdir(parents=True, exist_ok=True)\n",
    "        status(f\"Drive Connected: {input_dir}\")\n",
    "    except Exception as e:\n",
    "        status(f\"Failed to connect Drive: {e}\", False)\n",
    "        raise SystemExit()\n",
    "\n",
    "elif PLATFORM == 'kaggle':\n",
    "    # Kaggle: Read-only Input, specific Output\n",
    "    # Search for input dataset matching folder_name or standard locations\n",
    "    potential_inputs = [\n",
    "        Path(f\"/kaggle/input/{cfg['folder_name']}\"), # Named dataset\n",
    "        Path(f\"/kaggle/input/whisperjav-media\"),    # Common dataset name\n",
    "        Path(f\"/kaggle/input\"),                     # Root input\n",
    "        Path(f\"/kaggle/working/input\")              # Manual upload location\n",
    "    ]\n",
    "    \n",
    "    input_dir = None\n",
    "    for p in potential_inputs:\n",
    "        if p.exists() and any(f for f in p.rglob('*') if f.suffix.lower() in {'.mp4', '.mkv', '.avi', '.mp3', '.wav', '.flac'}):\n",
    "            input_dir = p\n",
    "            break\n",
    "            \n",
    "    if not input_dir:\n",
    "        input_dir = Path(f\"/kaggle/input\")\n",
    "        print(\"  âš  Could not auto-detect specific input folder. Scanning /kaggle/input root.\")\n",
    "\n",
    "    output_dir = Path(f\"/kaggle/working/{cfg['folder_name']}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # KAGGLE FIX 1: Fix Temp Storage Overflow\n",
    "    # Redirect all temp files to writable working dir to avoid /tmp (ramdisk) filling up\n",
    "    kaggle_temp = Path(f\"/kaggle/working/temp\")\n",
    "    kaggle_temp.mkdir(parents=True, exist_ok=True)\n",
    "    os.environ['TMPDIR'] = str(kaggle_temp)\n",
    "    os.environ['TEMP'] = str(kaggle_temp)\n",
    "    os.environ['TMP'] = str(kaggle_temp)\n",
    "    print(f\"  ğŸ”§ Redirected temp storage to {kaggle_temp}\")\n",
    "\n",
    "    # KAGGLE CHECK 2: Internet Access\n",
    "    try:\n",
    "        import socket\n",
    "        socket.create_connection((\"www.google.com\", 80), timeout=2)\n",
    "    except OSError:\n",
    "        display(HTML('<div style=\"padding:10px;background:#fee2e2;border-radius:4px;border-left:4px solid #ef4444;color:#991b1b;\"><b>ğŸ›‘ Internet Disabled!</b><br>You must enable \"Internet\" in the Notebook Settings (right sidebar) > Internet > On.<br>Otherwise installation will fail.</div>'))\n",
    "        time.sleep(5)\n",
    "\n",
    "    status(f\"Input: {input_dir}\")\n",
    "    status(f\"Output: {output_dir}\")\n",
    "\n",
    "else:\n",
    "    # Local fallback\n",
    "    input_dir = Path(cfg['folder_name'])\n",
    "    output_dir = Path(f\"{cfg['folder_name']}_output\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    status(f\"Local Mode: {input_dir} â†’ {output_dir}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CHECK GPUs AND DETERMINE MODE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"GPU RESOURCE CHECK\")\n",
    "\n",
    "# Fail-fast: this notebook is intended for GPU runtimes (Kaggle/Colab).\n",
    "gpu_check = subprocess.run(\n",
    "    \"nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\",\n",
    "    shell=True,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    " )\n",
    "\n",
    "if gpu_check.returncode != 0 or not gpu_check.stdout.strip():\n",
    "    status(\"No GPU detected. Switch runtime to GPU (T4 x2 or L4/A100).\", False)\n",
    "    if PLATFORM == 'kaggle':\n",
    "        print(\"  Kaggle: right sidebar â†’ Settings â†’ Accelerator â†’ GPU (T4 x2) â†’ Save.\")\n",
    "    elif PLATFORM == 'colab':\n",
    "        print(\"  Colab: Runtime â†’ Change runtime type â†’ Hardware accelerator: GPU.\")\n",
    "    else:\n",
    "        print(\"  Local: ensure NVIDIA drivers are installed and `nvidia-smi` works.\")\n",
    "    raise SystemExit()\n",
    "\n",
    "gpu_lines = [line.strip() for line in gpu_check.stdout.strip().split('\\n') if line.strip()]\n",
    "num_gpus = len(gpu_lines)\n",
    "\n",
    "for i, gpu_info in enumerate(gpu_lines):\n",
    "    status(f\"GPU {i}: {gpu_info}\")\n",
    "\n",
    "# Adaptive mode selection\n",
    "if num_gpus >= 2:\n",
    "    PARALLEL_MODE = True\n",
    "    gpu_assignment = {1: \"0\", 2: \"1\"}\n",
    "    print(f\"\\n  âš¡ Parallel Mode: Pass 1 (GPU 0) | Pass 2 (GPU 1)\")\n",
    "else:\n",
    "    PARALLEL_MODE = False\n",
    "    gpu_assignment = {1: \"0\", 2: \"0\"}\n",
    "    print(f\"\\n  ğŸ“ Sequential Mode: Pass 1 â†’ Pass 2 (Single GPU)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INSTALL WHISPERJAV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"INSTALLING (3-5 min)\")\n",
    "install_start = time.time()\n",
    "\n",
    "# NOTE: TEN VAD depends on system libc++ runtime.\n",
    "# These installs must succeed (and we verify them) or TEN will fail at runtime.\n",
    "def _apt_prefix():\n",
    "    try:\n",
    "        if hasattr(os, 'geteuid') and os.geteuid() == 0:\n",
    "            return ''\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 'sudo ' if shutil.which('sudo') else ''\n",
    "\n",
    "# Platform prereqs (Colab/Kaggle): include libc++ runtime for TEN\n",
    "pre_cmds = (\n",
    "    f\"{_apt_prefix()}apt-get update -qq && \"\n",
    "    f\"{_apt_prefix()}apt-get install -y -qq ffmpeg portaudio19-dev libc++1 libc++abi1 > /dev/null 2>&1\"\n",
    " )\n",
    "\n",
    "# ARCHITECTURE NOTE:\n",
    "# WhisperJAV requires NumPy>=2.0. Standard Kaggle/Colab environments use NumPy 1.x.\n",
    "# To satisfy the requirement without breaking the ecosystem (matplotlib/torch ABI mismatches),\n",
    "# we must perform a synchronized upgrade of the core stack (numpy, matplotlib, torch).\n",
    "# We rely on 'configure_cuda_runtime_paths()' (below) to fix any CUDA version mismatches \n",
    "# caused by replacing the system PyTorch.\n",
    "\n",
    "req_packages = [\n",
    "# Core Audio/Video\n",
    "\"ffmpeg-python\", \"auditok\", \"pysrt\", \"srt\", \"aiofiles\", \"pyloudnorm\", \"pydub\",\n",
    "# AI/ML Stack (Synchronized Upgrade)\n",
    "\"numpy\", \"matplotlib\", \"scipy\", \"torch\", \"torchaudio\", \"torchvision\",\n",
    "\"faster-whisper\", \"transformers\", \"optimum\", \"accelerate\", \"huggingface-hub\", \n",
    "\"pydantic\", \"ten-vad\", \"silero-vad\", \"modelscope\", \"addict\", \"tiktoken\"\n",
    " ]\n",
    "req_str = \" \".join(req_packages)\n",
    "\n",
    "steps = [\n",
    "    (pre_cmds, \"System tools\"),\n",
    "    # Install dependencies allowing upgrades to ensure consistency (Numpy 2.0 compatible stack)\n",
    "    (f\"pip install -q {req_str}\", \"Python packages (Core Stack)\"),\n",
    "    (\"pip install -q --no-deps git+https://github.com/openai/whisper.git@main\", \"Whisper\"),\n",
    "    (\"pip install -q --no-deps git+https://github.com/meizhong986/stable-ts-fix-setup.git@main\", \"Stable-TS\"),\n",
    "    (\"pip install -q --no-deps git+https://github.com/meizhong986/WhisperJAV.git@main\", \"WhisperJAV\")\n",
    "]\n",
    "\n",
    "for cmd, name in steps:\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        status(f\"{name} failed\", False)\n",
    "        # On Kaggle, some apt-get might fail but environment is often usable\n",
    "        if PLATFORM != 'kaggle': \n",
    "            raise SystemExit()\n",
    "    else:\n",
    "        status(name)\n",
    "\n",
    "# Conditional installation of speech enhancer dependencies\n",
    "if expert:\n",
    "    extra_packages = set()\n",
    "    for enhancer in [expert.get('pass1_speech_enhancer'), expert.get('pass2_speech_enhancer')]:\n",
    "        if enhancer == 'clearvoice':\n",
    "            extra_packages.add('clearvoice')\n",
    "        elif enhancer == 'zipenhancer':\n",
    "            # zipenhancer uses modelscope which is already installed above\n",
    "            pass\n",
    "        elif enhancer == 'bs-roformer':\n",
    "            extra_packages.add('bs-roformer-infer')\n",
    "    \n",
    "    if extra_packages:\n",
    "        pkg_list = ' '.join(extra_packages)\n",
    "        result = subprocess.run(f\"pip install -q {pkg_list}\", shell=True, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            status(f\"Speech enhancer packages failed (continuing anyway)\", False)\n",
    "        else:\n",
    "            status(f\"Speech enhancer packages ({', '.join(extra_packages)})\")\n",
    "\n",
    "status(f\"Installation complete ({time.time()-install_start:.0f}s)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RUNTIME CONFIGURATION (Fixing CUDA conflicts)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ... existing code continues unchanged ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Step 3: AI Translation (if selected) { display-mode: \"form\" }\n",
    "#@markdown Translate each subtitle file using AI (only runs if \"English (AI translate)\" selected)\n",
    "\n",
    "import os, sys, subprocess, shlex, time\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def status(msg, ok=True):\n",
    "    icon = \"âœ“\" if ok else \"âœ—\"\n",
    "    print(f\"{icon} {msg}\")\n",
    "\n",
    "def section(title):\n",
    "    print(f\"\\n{'â”€'*40}\\n{title}\\n{'â”€'*40}\")\n",
    "\n",
    "# Check prerequisites\n",
    "if 'WHISPERJAV_CONFIG' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 1 first</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "if 'WHISPERJAV_NEW_SRTS' not in dir():\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> Run Step 2 first</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "cfg = WHISPERJAV_CONFIG\n",
    "new_srts = WHISPERJAV_NEW_SRTS\n",
    "output_dir = WHISPERJAV_OUTPUT_DIR if 'WHISPERJAV_OUTPUT_DIR' in dir() else Path(os.getcwd())\n",
    "\n",
    "# Re-detect platform just in case\n",
    "if 'google.colab' in sys.modules: PLATFORM = 'colab'\n",
    "elif os.path.exists('/kaggle'): PLATFORM = 'kaggle'\n",
    "else: PLATFORM = 'local'\n",
    "\n",
    "# Check if AI translation is needed\n",
    "if cfg['subtitle_language'] != 'llm':\n",
    "    display(HTML('<div style=\"padding:8px 10px;background:#f0f9ff;border-radius:4px;border-left:2px solid #3b82f6;font-size:10px\"><b>â„¹ Skipped:</b> AI translation not selected</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# API KEY RESOLUTION (SECRETS MANAGER)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def retrieve_key(service_name, config_key):\n",
    "    \"\"\"Try to get key from config, Kaggle secrets, or env.\"\"\"\n",
    "    if config_key and config_key.strip():\n",
    "        return config_key.strip()\n",
    "    \n",
    "    # Try Kaggle Secrets\n",
    "    if PLATFORM == 'kaggle':\n",
    "        try:\n",
    "            from kaggle_secrets import UserSecretsClient\n",
    "            secrets = UserSecretsClient()\n",
    "            candidates = [\n",
    "                f\"{service_name.upper()}_API_KEY\",\n",
    "                \"API_KEY\",\n",
    "                \"LLM_API_KEY\",\n",
    "                service_name.lower()\n",
    "            ]\n",
    "            for c in candidates:\n",
    "                try:\n",
    "                    k = secrets.get_secret(c)\n",
    "                    if k: return k\n",
    "                except: pass\n",
    "        except: pass\n",
    "        \n",
    "    return \"\"\n",
    "\n",
    "final_api_key = retrieve_key(cfg['translation_service'], cfg.get('api_key'))\n",
    "\n",
    "if not final_api_key:\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> No API key provided (checked Config and Kaggle Secrets)</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "if not new_srts:\n",
    "    display(HTML('<div style=\"padding:8px;background:#fef2f2;border-radius:4px;color:#991b1b;font-size:10px\"><b>Error:</b> No subtitle files to translate</div>'))\n",
    "    raise SystemExit()\n",
    "\n",
    "# Set up API key\n",
    "env_map = {\n",
    "    \"deepseek\": \"DEEPSEEK_API_KEY\",\n",
    "    \"openrouter\": \"OPENROUTER_API_KEY\",\n",
    "    \"gemini\": \"GEMINI_API_KEY\",\n",
    "    \"claude\": \"ANTHROPIC_API_KEY\",\n",
    "    \"gpt\": \"OPENAI_API_KEY\"\n",
    "}\n",
    "os.environ[env_map.get(cfg['translation_service'], \"API_KEY\")] = final_api_key\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TRANSLATION LOOP\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"AI TRANSLATION\")\n",
    "print(f\"Provider: {cfg['translation_service']}\")\n",
    "print(f\"Style: {cfg['_translation_style']}\")\n",
    "print(f\"Files to translate: {len(new_srts)}\\n\")\n",
    "\n",
    "translated_files = []\n",
    "failed_files = []\n",
    "\n",
    "for i, srt_file in enumerate(new_srts, 1):\n",
    "    print(f\"[{i}/{len(new_srts)}] Translating: {srt_file.name}\")\n",
    "\n",
    "    translate_cmd = [\n",
    "        'whisperjav-translate',\n",
    "        '-i', str(srt_file),\n",
    "        '--provider', cfg['translation_service'],\n",
    "        '-t', 'english',\n",
    "        '--tone', cfg['translation_style'],\n",
    "        '--stream'\n",
    "    ]\n",
    "\n",
    "    full_cmd = shlex.join(translate_cmd)\n",
    "\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            full_cmd,\n",
    "            shell=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "\n",
    "        for line in process.stderr:\n",
    "            print(f\"    {line}\", end='')\n",
    "\n",
    "        stdout_output, _ = process.communicate()\n",
    "\n",
    "        if process.returncode == 0:\n",
    "            output_path = stdout_output.strip()\n",
    "            if output_path:\n",
    "                translated_files.append(Path(output_path))\n",
    "            status(f\"Completed: {srt_file.name}\")\n",
    "        else:\n",
    "            status(f\"Failed: {srt_file.name}\", False)\n",
    "            failed_files.append(srt_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        status(f\"Error translating {srt_file.name}: {e}\", False)\n",
    "        failed_files.append(srt_file)\n",
    "\n",
    "    print()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMPLETE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "section(\"COMPLETE\")\n",
    "\n",
    "# Create ZIP of translations\n",
    "if translated_files:\n",
    "    trans_zip_path = output_dir / f\"{cfg['folder_name']}_translations_{cfg['translation_service']}.zip\"\n",
    "    try:\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(trans_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for srt in translated_files:\n",
    "                zipf.write(srt, srt.name)\n",
    "        status(f\"Bundled translations into: {trans_zip_path.name}\")\n",
    "        \n",
    "        # Download triggers\n",
    "        if PLATFORM == 'kaggle':\n",
    "            try:\n",
    "                from IPython.display import FileLink\n",
    "                rel_path = trans_zip_path.relative_to(Path.cwd())\n",
    "                display(FileLink(str(rel_path), result_html_prefix=\"<b>â¬‡ Click to download Translations ZIP: </b>\", result_html_suffix=\" (Kaggle)\"))\n",
    "            except:\n",
    "                display(HTML(f'<b>â¬‡ <a href=\"{trans_zip_path.name}\" target=\"_blank\">Click here to download Translations ZIP</a></b> (Kaggle)'))\n",
    "\n",
    "        elif PLATFORM == 'colab':\n",
    "            try:\n",
    "                from google.colab import files\n",
    "                files.download(str(trans_zip_path))\n",
    "            except: pass\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create zip: {e}\")\n",
    "\n",
    "if failed_files:\n",
    "    display(HTML(f'<div style=\"padding:8px 10px;background:#fef9c3;border-radius:4px;border-left:2px solid #ca8a04;font-size:10px\"><b>âš  Partially done!</b> {len(translated_files)}/{len(new_srts)} translated. {len(failed_files)} failed.</div>'))\n",
    "else:\n",
    "    if PLATFORM == 'kaggle':\n",
    "        loc_msg = f\"<br>ğŸ“‚ <b>files in 'Output' tab â†’ <code>{cfg['folder_name']}/</code></b>. <br>âš  <b>Download now</b> or they will be lost when session ends!\"\n",
    "    else:\n",
    "        loc_msg = f\"in {output_dir}\"\n",
    "\n",
    "    display(HTML(f'<div style=\"padding:8px 10px;background:#f0fdf4;border-radius:4px;border-left:2px solid #16a34a;font-size:10px\"><b>âœ“ All done!</b> {len(new_srts)} Japanese + {len(translated_files)} English subtitle(s) {loc_msg}</div>'))\n",
    "\n",
    "# Auto-disconnect\n",
    "if cfg['auto_disconnect']:\n",
    "    print(\"\\nAuto-disconnecting in 10s...\")\n",
    "    time.sleep(10)\n",
    "    if PLATFORM == 'colab':\n",
    "        try:\n",
    "            from google.colab import runtime\n",
    "            runtime.unassign()\n",
    "        except: pass\n",
    "else:\n",
    "    print(\"\\nRemember to disconnect manually.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
