{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhisperJAV Colab Installation Diagnostic\n",
    "\n",
    "This notebook tests the `install_colab.sh` script by cloning the repo and running locally.\n",
    "\n",
    "**Instructions:**\n",
    "1. Run each cell **one at a time** (Shift+Enter)\n",
    "2. Note which cell fails and what error message you see\n",
    "3. Report findings for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Check Colab Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU, CUDA, and Python environment\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COLAB ENVIRONMENT CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# GPU Info\n",
    "result = subprocess.run(\n",
    "    [\"nvidia-smi\", \"--query-gpu=name,driver_version,memory.total\", \"--format=csv,noheader\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "if result.returncode == 0:\n",
    "    print(f\"GPU: {result.stdout.strip()}\")\n",
    "else:\n",
    "    print(\"ERROR: nvidia-smi failed - no GPU available?\")\n",
    "    print(\"Go to Runtime → Change runtime type → T4 GPU\")\n",
    "    raise SystemExit(\"No GPU detected\")\n",
    "\n",
    "print(f\"\\nPython: {sys.version}\")\n",
    "\n",
    "# Check Colab's pre-installed PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nColab PyTorch: {torch.__version__}\")\n",
    "    print(f\"Colab PyTorch CUDA: {torch.version.cuda}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "except ImportError:\n",
    "    print(\"\\nPyTorch not pre-installed (unusual for Colab)\")\n",
    "\n",
    "# Check numpy version (this is the conflict source)\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"\\nColab numpy: {np.__version__}\")\n",
    "    if np.__version__.startswith(\"2.\"):\n",
    "        print(\"⚠ numpy 2.x detected - this is why we need an isolated venv\")\n",
    "except ImportError:\n",
    "    print(\"numpy not installed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Environment check: PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Clone Repo & Run Installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone WhisperJAV repo and run installer locally\n# Uses Popen for real-time output streaming in Jupyter\n\nimport subprocess\nimport os\nimport sys\nimport time\n\nREPO_URL = \"https://github.com/meizhong986/WhisperJAV.git\"\nREPO_PATH = \"/content/WhisperJAV\"\nSCRIPT_PATH = f\"{REPO_PATH}/installer/install_colab.sh\"\n\nprint(\"=\"*60)\nprint(\"INSTALL WHISPERJAV\")\nprint(\"=\"*60)\n\n# Step 1: Clone repo (or pull if exists)\nif os.path.exists(REPO_PATH):\n    print(f\"Repo already exists at {REPO_PATH}\")\n    print(\"Pulling latest changes...\")\n    result = subprocess.run([\"git\", \"-C\", REPO_PATH, \"pull\"], capture_output=True, text=True)\n    if result.returncode != 0:\n        print(f\"Warning: git pull failed: {result.stderr}\")\n    else:\n        print(f\"✓ Pulled latest\")\nelse:\n    print(f\"Cloning {REPO_URL}...\")\n    result = subprocess.run([\"git\", \"clone\", REPO_URL, REPO_PATH], capture_output=True, text=True)\n    if result.returncode != 0:\n        print(f\"ERROR: git clone failed\")\n        print(result.stderr)\n        raise SystemExit(\"Failed to clone repository\")\n    print(f\"✓ Cloned to {REPO_PATH}\")\n\n# Step 2: Verify script exists\nif not os.path.exists(SCRIPT_PATH):\n    print(f\"\\nERROR: Install script not found at {SCRIPT_PATH}\")\n    print(\"\\nThis means the script hasn't been committed to the repo yet.\")\n    print(\"The install_colab.sh must be pushed to GitHub first.\")\n    raise SystemExit(\"Install script not found in repo\")\n\nprint(f\"✓ Script found: {SCRIPT_PATH}\")\n\n# Step 3: Run installer with real-time output streaming\nprint(\"\\n\" + \"-\"*60)\nprint(\"Running install_colab.sh...\")\nprint(\"-\"*60 + \"\\n\")\nsys.stdout.flush()\n\nstart_time = time.time()\n\n# Use Popen for real-time output streaming in Jupyter\nenv = {**os.environ, \"PATH\": f\"{os.environ.get('PATH', '')}:{os.path.expanduser('~/.local/bin')}\"}\nprocess = subprocess.Popen(\n    [\"bash\", SCRIPT_PATH],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    bufsize=1,\n    text=True,\n    env=env\n)\n\n# Stream output line by line\nfor line in iter(process.stdout.readline, ''):\n    print(line, end='', flush=True)\n\nprocess.wait()\nelapsed = time.time() - start_time\n\nprint(\"\\n\" + \"=\"*60)\nif process.returncode != 0:\n    print(f\"ERROR: Installation FAILED (exit code {process.returncode})\")\n    print(\"=\"*60)\n    raise SystemExit(f\"Installation failed with exit code {process.returncode}\")\nelse:\n    print(f\"✓ Installation SUCCEEDED ({elapsed:.0f} seconds)\")\n    print(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Verify Venv Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the venv was created correctly\n",
    "import os\n",
    "\n",
    "VENV_PATH = \"/content/whisperjav_env\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VENV STRUCTURE CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checks = [\n",
    "    (f\"{VENV_PATH}/bin/python\", \"Python interpreter\"),\n",
    "    (f\"{VENV_PATH}/bin/pip\", \"pip\"),\n",
    "    (f\"{VENV_PATH}/bin/whisperjav\", \"whisperjav CLI\"),\n",
    "    (f\"{VENV_PATH}/bin/whisperjav-translate\", \"whisperjav-translate CLI\"),\n",
    "]\n",
    "\n",
    "failed = []\n",
    "for path, name in checks:\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {name}: {path}\")\n",
    "    if not exists:\n",
    "        failed.append(name)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if failed:\n",
    "    print(f\"ERROR: Venv structure check FAILED\")\n",
    "    print(f\"Missing: {', '.join(failed)}\")\n",
    "    print(\"=\"*60)\n",
    "    raise SystemExit(\"Venv structure incomplete\")\n",
    "else:\n",
    "    print(\"✓ Venv structure: PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Verify Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify packages are installed in the venv\n",
    "import subprocess\n",
    "\n",
    "VENV_PYTHON = \"/content/whisperjav_env/bin/python\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VENV PACKAGE VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "packages_to_check = [\n",
    "    (\"torch\", \"import torch; print(f'PyTorch {torch.__version__}, CUDA {torch.version.cuda}, available={torch.cuda.is_available()}')\"),\n",
    "    (\"numpy\", \"import numpy; print(f'numpy {numpy.__version__}')\"),\n",
    "    (\"whisperjav\", \"import whisperjav; print('whisperjav OK')\"),\n",
    "    (\"whisper\", \"import whisper; print('whisper OK')\"),\n",
    "    (\"stable_whisper\", \"import stable_whisper; print('stable_whisper OK')\"),\n",
    "    (\"faster_whisper\", \"import faster_whisper; print('faster_whisper OK')\"),\n",
    "]\n",
    "\n",
    "failed = []\n",
    "for name, check_cmd in packages_to_check:\n",
    "    result = subprocess.run([VENV_PYTHON, \"-c\", check_cmd], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ {name}: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(f\"✗ {name}: FAILED\")\n",
    "        if result.stderr:\n",
    "            print(f\"  Error: {result.stderr.strip()[:200]}\")\n",
    "        failed.append(name)\n",
    "\n",
    "# Verify numpy is < 2.0 in venv\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "result = subprocess.run(\n",
    "    [VENV_PYTHON, \"-c\", \"import numpy; v=numpy.__version__; print(v); exit(0 if v.startswith('1.') else 1)\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "if result.returncode == 0:\n",
    "    print(f\"✓ numpy version: {result.stdout.strip()} (< 2.0 as required)\")\n",
    "else:\n",
    "    print(f\"✗ numpy version: {result.stdout.strip()} (expected < 2.0)\")\n",
    "    failed.append(\"numpy version\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if failed:\n",
    "    print(f\"ERROR: Package verification FAILED: {', '.join(failed)}\")\n",
    "    raise SystemExit(\"Package verification failed\")\n",
    "else:\n",
    "    print(\"✓ Package verification: PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Test CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the CLI commands\n",
    "import subprocess\n",
    "\n",
    "VENV_PATH = \"/content/whisperjav_env\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLI TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = subprocess.run([f\"{VENV_PATH}/bin/whisperjav\", \"--help\"], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(\"whisperjav --help:\")\n",
    "    print(\"\\n\".join(result.stdout.strip().split(\"\\n\")[:15]))\n",
    "    print(\"...\\n\")\n",
    "else:\n",
    "    print(f\"ERROR: whisperjav --help failed\")\n",
    "    raise SystemExit(\"CLI test failed\")\n",
    "\n",
    "result = subprocess.run([f\"{VENV_PATH}/bin/whisperjav-translate\", \"--help\"], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(\"whisperjav-translate --help:\")\n",
    "    print(\"\\n\".join(result.stdout.strip().split(\"\\n\")[:10]))\n",
    "    print(\"...\")\n",
    "else:\n",
    "    print(f\"ERROR: whisperjav-translate --help failed\")\n",
    "    raise SystemExit(\"CLI test failed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ CLI test: PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Check llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check llama-cpp-python (optional component)\n",
    "import subprocess\n",
    "\n",
    "VENV_PYTHON = \"/content/whisperjav_env/bin/python\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LLAMA-CPP-PYTHON CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = subprocess.run(\n",
    "    [VENV_PYTHON, \"-c\", \"import llama_cpp; print(f'Version: {llama_cpp.__version__}')\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"✓ llama-cpp-python: {result.stdout.strip()}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ llama-cpp-python: INSTALLED\")\n",
    "else:\n",
    "    print(\"⚠ llama-cpp-python: NOT INSTALLED\")\n",
    "    print(\"\")\n",
    "    print(\"This is expected if no prebuilt wheel was available.\")\n",
    "    print(\"Local LLM translation won't work, but cloud providers will.\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"⚠ llama-cpp-python: SKIPPED (optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "VENV_PYTHON = \"/content/whisperjav_env/bin/python\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INSTALLATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get driver info\n",
    "result = subprocess.run(\n",
    "    [\"nvidia-smi\", \"--query-gpu=driver_version,name\", \"--format=csv,noheader\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "if result.returncode == 0:\n",
    "    parts = result.stdout.strip().split(\", \")\n",
    "    print(f\"Driver: {parts[0]}\")\n",
    "    print(f\"GPU: {parts[1] if len(parts) > 1 else 'unknown'}\")\n",
    "\n",
    "print(f\"Colab Python: {sys.version.split()[0]}\")\n",
    "\n",
    "# Venv info\n",
    "venv_info = subprocess.run(\n",
    "    [VENV_PYTHON, \"-c\", \"\"\"\n",
    "import torch\n",
    "import numpy\n",
    "print(f\"Venv PyTorch: {torch.__version__}\")\n",
    "print(f\"Venv PyTorch CUDA: {torch.version.cuda}\")\n",
    "print(f\"Venv numpy: {numpy.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\"\"\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(venv_info.stdout)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✓ ALL DIAGNOSTICS COMPLETE\")\n",
    "print(\"\\nTo use WhisperJAV:\")\n",
    "print(\"  /content/whisperjav_env/bin/whisperjav <video_path>\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}